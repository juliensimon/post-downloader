<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Johnny Pi, I am your father — part 4: adding cloud-based vision</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Johnny Pi, I am your father — part 4: adding cloud-based vision</h1>
</header>
<section data-field="subtitle" class="p-summary">
In the previous post, we learned how to use Amazon Polly to let our robot speak. I hope you had fun with that :)
</section>
<section data-field="body" class="e-content">
<section name="b9d9" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="4857" id="4857" class="graf graf--h3 graf--leading graf--title">Johnny Pi, I am your father — part 4: adding cloud-based vision</h3><p name="e870" id="e870" class="graf graf--p graf-after--h3">In the <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" class="markup--anchor markup--p-anchor" target="_blank">previous post</a>, we learned how to use <a href="https://aws.amazon.com/polly/" data-href="https://aws.amazon.com/polly/" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener noopener noopener" target="_blank">Amazon Polly</a> to let our robot speak. I hope you had fun with that :)</p><p name="ddee" id="ddee" class="graf graf--p graf-after--p">In this post, I’ll show you how to take picture with the robot’s camera and how to use <a href="https://aws.amazon.com/rekognition/" data-href="https://aws.amazon.com/rekognition/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Amazon Rekognition</a> to identify faces and objects… and yeah, we’ll send some tweets.</p><p name="1cb2" id="1cb2" class="graf graf--p graf-after--p">Let’s get going.</p><figure name="68ea" id="68ea" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*J38sO_Ck60irLpgzl27LiA.png" data-width="1804" data-height="938" src="https://cdn-images-1.medium.com/max/800/1*J38sO_Ck60irLpgzl27LiA.png"></figure><h4 name="12a8" id="12a8" class="graf graf--h4 graf-after--figure">What we’ll need</h4><p name="b841" id="b841" class="graf graf--p graf-after--h4">Here’s the shopping list:</p><ul class="postList"><li name="5000" id="5000" class="graf graf--li graf-after--p">A <a href="https://www.raspberrypi.org/products/camera-module-v2/" data-href="https://www.raspberrypi.org/products/camera-module-v2/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">camera module v2</a></li><li name="4d6b" id="4d6b" class="graf graf--li graf-after--li">Optional: an extra flex ribbon (such as <a href="https://www.amazon.com/Miuzei-Extension-Ribbon-Raspberry-Camera/dp/B072N7VXPR/" data-href="https://www.amazon.com/Miuzei-Extension-Ribbon-Raspberry-Camera/dp/B072N7VXPR/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">this one</a>), as they tend to bend and break pretty easily.</li></ul><div name="e432" id="e432" class="graf graf--mixtapeEmbed graf-after--li"><a href="https://www.raspberrypi.org/products/camera-module-v2/" data-href="https://www.raspberrypi.org/products/camera-module-v2/" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.raspberrypi.org/products/camera-module-v2/"><strong class="markup--strong markup--mixtapeEmbed-strong">Camera Module V2 - Raspberry Pi</strong><br><em class="markup--em markup--mixtapeEmbed-em">The Raspberry Pi Camera Module v2 replaced the original Camera Module in April 2016. The v2 Camera Module has a Sony…</em>www.raspberrypi.org</a><a href="https://www.raspberrypi.org/products/camera-module-v2/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="4bf7b90df6de2f48a94f600704353951" data-thumbnail-img-id="0*_i0qsq8diewH_DHW." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*_i0qsq8diewH_DHW.);"></a></div><h4 name="dd38" id="dd38" class="graf graf--h4 graf-after--mixtapeEmbed">Allowing the robot to subscribe to a new MQTT topic</h4><p name="b0e6" id="b0e6" class="graf graf--p graf-after--h4">Once again, all commands will be sent through a dedicated MQTT topic, named <em class="markup--em markup--p-em">JohnnyPi/see</em>. We have to update the thing’s IAM policy to allow it to subscribe to this new topic.</p><p name="f00b" id="f00b" class="graf graf--p graf-after--p">Just go to the IAM console, locate the proper policy and add the following statement.</p><figure name="d629" id="d629" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/5d8e07f296bb3656c749f7ebcdea9400.js"></script></figure><h4 name="53f0" id="53f0" class="graf graf--h4 graf-after--figure">Allowing the robot to invoke Rekognition</h4><p name="e484" id="e484" class="graf graf--p graf-after--h4">As we did for Polly, he have to allow the robot to call the Rekognition API. Let’s use the AWS CLI again and grant the robot the appropriate IAM permissions.</p><pre name="8549" id="8549" class="graf graf--pre graf-after--p">$ aws iam attach-user-policy — user-name johnny-pi — policy-arn arn:aws:iam::aws:policy/AmazonRekognitionReadOnlyAccess</pre><h4 name="6d24" id="6d24" class="graf graf--h4 graf-after--pre">Code overview</h4><p name="1b5a" id="1b5a" class="graf graf--p graf-after--h4">OK, with IAM out of the way, let’s write some code. Here’s what should happen when we send an MQTT message to the <em class="markup--em markup--p-em">JohnnyPi/see</em> topic:</p><ul class="postList"><li name="f1d5" id="f1d5" class="graf graf--li graf-after--p">take a picture with the Pi camera,</li><li name="dbc5" id="dbc5" class="graf graf--li graf-after--li">send it to Rekognition for face and label detection,</li><li name="0fef" id="0fef" class="graf graf--li graf-after--li">draw a rectangle around each face, add a legend and save the new image,</li><li name="3d1e" id="3d1e" class="graf graf--li graf-after--li">build a text message about faces and another one about labels,</li><li name="87e1" id="87e1" class="graf graf--li graf-after--li">send both messages to Polly for speech generation,</li><li name="f9b8" id="f9b8" class="graf graf--li graf-after--li">play both sound files on the Pi,</li><li name="06d7" id="06d7" class="graf graf--li graf-after--li">last but not least, tweet the new image if the MQTT message contains ‘tweet’.</li></ul><p name="92c1" id="92c1" class="graf graf--p graf-after--li">As usual, we need to add a callback for messages posted to the topic. This is what the function looks like.</p><figure name="f13c" id="f13c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/def4245ae36938c6a3b41a4724f30aed.js"></script></figure><p name="124a" id="124a" class="graf graf--p graf-after--figure">It should be quite explanatory. Let’s look at the important steps in more detail.</p><h4 name="57d2" id="57d2" class="graf graf--h4 graf-after--p">Taking a picture</h4><p name="e973" id="e973" class="graf graf--p graf-after--h4">The Pi camera API is nice and simple. Open the camera, take a picture, close the camera. Why can’t programming be always this simple?</p><figure name="4db0" id="4db0" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/1efc95f71a4efcd191dbc6a7976f9766.js"></script></figure><h4 name="4e3a" id="4e3a" class="graf graf--h4 graf-after--figure">Detecting faces and labels with Rekognition</h4><p name="ccc9" id="ccc9" class="graf graf--p graf-after--h4">First, we have to copy the picture to S3. Make sure to use your own bucket in <em class="markup--em markup--p-em">awsUtils.py</em>.</p><figure name="2756" id="2756" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/15398bcdcf40f6b57205545e32333ae7.js"></script></figure><p name="6c59" id="6c59" class="graf graf--p graf-after--figure">Next, we invoke two Rekognition APIs:</p><ul class="postList"><li name="f950" id="f950" class="graf graf--li graf-after--p"><a href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectFaces.html" data-href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectFaces.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><em class="markup--em markup--li-em">detect_faces()</em></a> returns a list of face details: position, landmarks, age range, etc.</li><li name="86ba" id="86ba" class="graf graf--li graf-after--li"><a href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectLabels.html" data-href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectLabels.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><em class="markup--em markup--li-em">detect_labels</em>()</a> returns a list of labels and confidence scores. By default, we’re using 10 labels at most, with confidence score of 80% or higher.</li></ul><figure name="f2aa" id="f2aa" class="graf graf--figure graf--iframe graf-after--li"><script src="https://gist.github.com/juliensimon/d69e62794ec6251610715ae4e772f4cd.js"></script></figure><h4 name="fc4d" id="fc4d" class="graf graf--h4 graf-after--figure">Generating the new image</h4><p name="e075" id="e075" class="graf graf--p graf-after--h4">Thanks to the face details provided by Rekognition, we’re now able to locate the position of each face in the picture. Using the <a href="https://python-pillow.org/" data-href="https://python-pillow.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Pillow</a> library, we’re going to draw a rectangle around each face and add a legend with the face count (‘Face0’, ‘Face1’, etc.).</p><figure name="b54c" id="b54c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/047745fd932cd5914013216da3a168f6.js"></script></figure><p name="daf5" id="daf5" class="graf graf--p graf-after--figure">Drawing a rectangle around each face requires a bit more work that I’d have liked. First, Rekognition returns fractional coordinates for the bounding box, which need to be converted into absolute pixel values. Second, the Pillow API to draw rectangles doesn’t allow line width to be set: for high resolution pictures, the resulting rectangle tends to be invisible :-/ Thus, I’m drawing lines instead. If you’re curious about Pillow, all code is located in <em class="markup--em markup--p-em">RekognitionUtils.py</em>. If not, no worries, you can happily ignore this. It seems to work fine ;)</p><p name="128b" id="128b" class="graf graf--p graf-after--p">Once rectangles and legends have been added, the new image is saved locally and the number of faces is returned.</p><h4 name="fd21" id="fd21" class="graf graf--h4 graf-after--p">Generating the face and label messages</h4><p name="c979" id="c979" class="graf graf--p graf-after--h4">Using the number of faces, we build a text string that Polly will speak. In the same way, we build a text string about labels: more details in <em class="markup--em markup--p-em">generateMessages()</em>.</p><h4 name="a77d" id="a77d" class="graf graf--h4 graf-after--p">Generating and playing the sound files</h4><p name="c8b9" id="c8b9" class="graf graf--p graf-after--h4">We simply reuse the code we wrote in <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" class="markup--anchor markup--p-anchor" target="_blank">part 3</a>.</p><figure name="7a0e" id="7a0e" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/1b24474a9411ef9b032c807af1f25ac7#file-johnnypi-part3-polly-py.js"></script></figure><h4 name="a426" id="a426" class="graf graf--h4 graf-after--figure">Sending a tweet</h4><p name="ef60" id="ef60" class="graf graf--p graf-after--h4">The first step is to create a Twitter <a href="https://dev.twitter.com/" data-href="https://dev.twitter.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">developer account</a> and get API credentials. Then, we can use the super simple T<a href="http://www.tweepy.org/" data-href="http://www.tweepy.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">weepy</a> library to send a tweet.</p><figure name="16d4" id="16d4" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/cb2eeaf14334bf4e9a7ba78500b0e793.js"></script></figure><p name="deea" id="deea" class="graf graf--p graf-after--figure">That’s it, we have everything we need. Let’s test!</p><h4 name="778f" id="778f" class="graf graf--h4 graf-after--p">Testing</h4><p name="061e" id="061e" class="graf graf--p graf-after--h4">As previously, I’m using <a href="http://www.mqttfx.org/" data-href="http://www.mqttfx.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MQTT.fx</a> to publish messages to the <em class="markup--em markup--p-em">JohnnyPi/see</em> topic. Here’s the output for Rekognition only.</p><figure name="0b3e" id="0b3e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*9bSmZzgEkLuBSF-IgLBlnA.png" data-width="320" data-height="240" src="https://cdn-images-1.medium.com/max/800/1*9bSmZzgEkLuBSF-IgLBlnA.png"><figcaption class="imageCaption">Lemme guess…. LCD screens?</figcaption></figure><pre name="ab6d" id="ab6d" class="graf graf--pre graf-after--figure">Topic=JohnnyPi/see<br>Picture uploaded<br>Label People, confidence: 99.1184310913<br>Label Person, confidence: 99.1184387207<br>Label Human, confidence: 99.0959320068<br>Label Computer, confidence: 98.671875<br>Label Electronics, confidence: 98.671875<br>Label LCD Screen, confidence: 98.671875<br>Label Laptop, confidence: 98.671875<br>Label Pc, confidence: 98.671875<br>*** Face 0 detected, confidence: 99.9929733276<br>Gender: Male<br>Age: 48-68<br>HAPPY 99.4530334473<br>ANGRY 1.54959559441<br>CALM 0.563991069794<br>Face message: A single face has been detected.<br>Label message: Here are some keywords about this picture: People, Person, Human, Computer, Electronics, LCD Screen, Laptop, Pc</pre><p name="20e7" id="20e7" class="graf graf--p graf-after--pre">48–68? WTF. I should have a chat with the Product Manager about the age range. Or maybe I simply need some sleep :)</p><p name="9259" id="9259" class="graf graf--p graf-after--p">Here’s a second try with both Rekognition and Twitter.</p><figure name="6312" id="6312" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Kkujkfwlz-kb-0g7bu7U7A.png" data-width="1162" data-height="946" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*Kkujkfwlz-kb-0g7bu7U7A.png"></figure><pre name="da69" id="da69" class="graf graf--pre graf-after--figure">Topic=JohnnyPi/see<br>Picture uploaded<br>Label People, confidence: 98.8171768188<br>Label Person, confidence: 98.8172149658<br>Label Human, confidence: 98.7540512085<br>Label Computer, confidence: 98.6133422852<br>Label Electronics, confidence: 98.6133422852<br>Label LCD Screen, confidence: 98.6133422852<br>Label Laptop, confidence: 98.6133422852<br>Label Pc, confidence: 98.6133422852<br>*** Face 0 detected, confidence: 99.9958724976<br>Gender: Male<br>Age: 26-43<br>Beard<br>CONFUSED 56.1017799377<br>SAD 16.9187488556<br>ANGRY 5.65937137604<br>Face message: A single face has been detected.<br>Label message: Here are some keywords about this picture: People, Person, Human, Computer, Electronics, LCD Screen, Laptop, Pc,<br>Tweet sent</pre><p name="179b" id="179b" class="graf graf--p graf-after--pre">All right, the age range is more like it. I guess the moral of the story is: don’t smile.</p><h4 name="ee9a" id="ee9a" class="graf graf--h4 graf-after--p">What’s next</h4><p name="9578" id="9578" class="graf graf--p graf-after--h4">As usual, you’ll find the full code on <a href="https://github.com/juliensimon/johnnypi/tree/master/part4" data-href="https://github.com/juliensimon/johnnypi/tree/master/part4" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Github</a>.</p><p name="52a1" id="52a1" class="graf graf--p graf-after--p">In the next part, we’ll keep expanding our robot vision skills with a pre-trained <a href="http://mxnet.io" data-href="http://mxnet.io" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MXNet</a> model for image recognition. More silliness in sight, no doubt!</p><p name="1f31" id="1f31" class="graf graf--p graf-after--p graf--trailing">Until then, have fun and as always, thanks for reading.</p></div></div></section><section name="b118" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="5457" id="5457" class="graf graf--p graf--leading">Part 0: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-0-1eb537e5a36" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-0-1eb537e5a36" class="markup--anchor markup--p-anchor" target="_blank">a sneak preview</a></p><p name="4525" id="4525" class="graf graf--p graf-after--p">Part 1: <a href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-1-moving-around-e09fe95bbfce" data-href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-1-moving-around-e09fe95bbfce" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener" target="_blank">moving around</a></p><p name="58a9" id="58a9" class="graf graf--p graf-after--p">Part 2: <a href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-2-the-joystick-db8ac067e86" data-href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-2-the-joystick-db8ac067e86" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener" target="_blank">the joystick</a></p><p name="a175" id="a175" class="graf graf--p graf-after--p">Part 3: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" class="markup--anchor markup--p-anchor" target="_blank">cloud-based speech</a></p><p name="dd71" id="dd71" class="graf graf--p graf-after--p graf--trailing">Part 5: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-5-adding-mxnet-for-local-image-classification-bc27a5fd2c27" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-5-adding-mxnet-for-local-image-classification-bc27a5fd2c27" class="markup--anchor markup--p-anchor" target="_blank">local image classification with MXNet</a></p></div></div></section><section name="f334" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="846f" id="846f" class="graf graf--p graf--leading graf--trailing"><em class="markup--em markup--p-em">This article was written while playing way too many songs by Lynyrd Skynyrd. Must be the 68-year old redneck in me.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/8830c2676113"><time class="dt-published" datetime="2017-09-11T14:12:55.365Z">September 11, 2017</time></a>.</p><p><a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
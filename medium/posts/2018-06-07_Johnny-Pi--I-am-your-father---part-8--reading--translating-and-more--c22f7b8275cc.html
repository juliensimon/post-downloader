<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Johnny Pi, I am your father — part 8: reading, translating and more!</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Johnny Pi, I am your father — part 8: reading, translating and more!</h1>
</header>
<section data-field="subtitle" class="p-summary">
It’s been a while since part 7, where we added a custom Alexa skill to interact with our robot. Plenty has happened since then, so it’s…
</section>
<section data-field="body" class="e-content">
<section name="0729" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="23bc" id="23bc" class="graf graf--h3 graf--leading graf--title">Johnny Pi, I am your father — part 8: reading, translating and more!</h3><p name="49eb" id="49eb" class="graf graf--p graf-after--h3">It’s been a while since <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-7-son-we-need-to-talk-5a910aa642d1" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-7-son-we-need-to-talk-5a910aa642d1" class="markup--anchor markup--p-anchor" target="_blank">part 7</a>, where we added a custom Alexa skill to interact with our robot. Plenty has happened since then, so it’s time to teach Johnny some new things, namely:</p><ul class="postList"><li name="c196" id="c196" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Speeding up local prediction</strong>,</li><li name="be1f" id="be1f" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Recognising celebrities</strong>,</li><li name="aa26" id="aa26" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Reading text</strong>,</li><li name="d7a0" id="d7a0" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Detecting the language of a text</strong>,</li><li name="815e" id="815e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Translating text</strong>.</li></ul><p name="f695" id="f695" class="graf graf--p graf-after--li">As usual, all code is available on <a href="https://gitlab.com/juliensimon/johnnypi" data-href="https://gitlab.com/juliensimon/johnnypi" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Gitlab</a> and you’ll see a video demo at the end of the post. Let’s get to work.</p><figure name="f7c7" id="f7c7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1gM78rvVIN7Va-WLAbxkIA.png" data-width="874" data-height="450" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*1gM78rvVIN7Va-WLAbxkIA.png"></figure><h3 name="d9f5" id="d9f5" class="graf graf--h3 graf-after--figure">Speeding up local prediction</h3><p name="91b6" id="91b6" class="graf graf--p graf-after--h3">In <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-5-adding-mxnet-for-local-image-classification-bc27a5fd2c27" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-5-adding-mxnet-for-local-image-classification-bc27a5fd2c27" class="markup--anchor markup--p-anchor" target="_blank">part 5</a>, we implemented <strong class="markup--strong markup--p-strong">local object classification</strong> thanks to <a href="https://mxnet.incubator.apache.org/" data-href="https://mxnet.incubator.apache.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Apache MXNet</a> and a pre-trained model: it worked fine, albeit a little slow due to the small CPU of the Raspberry Pi.</p><p name="b650" id="b650" class="graf graf--p graf-after--p">To speed things up, I upgraded to MXNet 1.1 and built it with <a href="https://github.com/Maratyszcza/NNPACK" data-href="https://github.com/Maratyszcza/NNPACK" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">NNPACK</a>, an <strong class="markup--strong markup--p-strong">open source acceleration library</strong> (<a href="https://medium.com/@julsimon/speeding-up-apache-mxnet-with-the-nnpack-library-raspberry-pi-edition-e444b446a180" data-href="https://medium.com/@julsimon/speeding-up-apache-mxnet-with-the-nnpack-library-raspberry-pi-edition-e444b446a180" class="markup--anchor markup--p-anchor" target="_blank">which we already discussed</a>).</p><blockquote name="4c4e" id="4c4e" class="graf graf--blockquote graf--hasDropCapModel graf-after--p">Building MXNet 1.x on a Pi takes well over an hour, but you can get it done. Unfortunately, there is not enough memory to run parallel make (‘make -j’), so stick to ‘make’… and get some more tea, coffee or beer!</blockquote><p name="06f0" id="06f0" class="graf graf--p graf-after--blockquote">Thanks to this, Johnny can now predict a single image with the Inception v3 model in about one second, which is <strong class="markup--strong markup--p-strong">3x-4x faster</strong> than before. This feels pretty instantaneous when asking for object detection.</p><figure name="f608" id="f608" class="graf graf--figure graf--startsWithDoubleQuote graf-after--p"><img class="graf-image" data-image-id="0*W6fydKlG1FvdsVu2.jpg" data-width="640" data-height="480" src="https://cdn-images-1.medium.com/max/800/0*W6fydKlG1FvdsVu2.jpg"><figcaption class="imageCaption">“I’m 19% sure that this is a desktop computer”: forward pass in 1.14 second (and yes, I live in a cave).</figcaption></figure><h3 name="3459" id="3459" class="graf graf--h3 graf-after--figure">Recognising celebrities</h3><p name="6eaa" id="6eaa" class="graf graf--p graf-after--h3">We already implemented face detection (<a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" class="markup--anchor markup--p-anchor" target="_blank">part 4</a>), so let’s now handle <strong class="markup--strong markup--p-strong">celebrities</strong>. This <a href="https://docs.aws.amazon.com/rekognition/latest/dg/celebrities.html" data-href="https://docs.aws.amazon.com/rekognition/latest/dg/celebrities.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">feature</a> was added to <a href="http://aws.amazon.com/rekognition" data-href="http://aws.amazon.com/rekognition" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon Rekognition</strong></a> a while ago — and <a href="https://www.theverge.com/2018/5/4/17318354/royal-wedding-uk-facial-recognition-sky-news-date" data-href="https://www.theverge.com/2018/5/4/17318354/royal-wedding-uk-facial-recognition-sky-news-date" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">used by Sky News at the recent royal wedding</a> :)</p><p name="a2ec" id="a2ec" class="graf graf--p graf-after--p">Let’s just use the <a href="https://docs.aws.amazon.com/rekognition/latest/dg/API_RecognizeCelebrities.html" data-href="https://docs.aws.amazon.com/rekognition/latest/dg/API_RecognizeCelebrities.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">RecognizeCelebrities</em></a> API and update the function that builds the text message spoken by Johnny.</p><figure name="e780" id="e780" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/bcdc4923889216afcabfbd764e05fae6.js"></script></figure><p name="1847" id="1847" class="graf graf--p graf-after--figure">No changes to the Alexa skill: it will still ask Johnny to look for faces by posting a message to the <em class="markup--em markup--p-em">JohnnyPi/see</em> topic. If Johnny detects celebrities, then they will be mentioned in the voice message and in the tweet.</p><p name="ee1d" id="ee1d" class="graf graf--p graf-after--p">Quick test? Sure :)</p><figure name="6fa1" id="6fa1" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ZcS2c8sTKBS7yIjw-fYVyQ.png" data-width="573" data-height="468" src="https://cdn-images-1.medium.com/max/800/1*ZcS2c8sTKBS7yIjw-fYVyQ.png"><figcaption class="imageCaption">We’ll always love you, Princess.</figcaption></figure><h3 name="583d" id="583d" class="graf graf--h3 graf-after--figure">Reading text</h3><p name="b1e0" id="b1e0" class="graf graf--p graf-after--h3">This is another <a href="https://docs.aws.amazon.com/rekognition/latest/dg/text-detecting-text-procedure.html" data-href="https://docs.aws.amazon.com/rekognition/latest/dg/text-detecting-text-procedure.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">feature</a> in Amazon Rekognition. All we need to do is to call the <a href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectText.html" data-href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectText.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">DetectText</em></a> API and extract all lines of text. We’ll also use a new topic (<em class="markup--em markup--p-em">JohnnyPi/read</em>) to receive messages from the skill.</p><figure name="a204" id="a204" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/acc6edac4bf04e5efed6d4d54e928e96.js"></script></figure><p name="135d" id="135d" class="graf graf--p graf-after--figure">Skill-side, we need a new intent (<em class="markup--em markup--p-em">ReadIntent</em>, no slot needed) and an appropriate handler in the Lambda function.</p><figure name="56c5" id="56c5" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/318e5e12da1ca78491c9fed62f0df900.js"></script></figure><p name="f59c" id="f59c" class="graf graf--p graf-after--figure">Let’s try it.</p><figure name="dc08" id="dc08" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*XGcObAGg377XDNOF19uWHw.png" data-width="576" data-height="442" src="https://cdn-images-1.medium.com/max/800/1*XGcObAGg377XDNOF19uWHw.png"></figure><h3 name="83a1" id="83a1" class="graf graf--h3 graf-after--figure"><strong class="markup--strong markup--h3-strong">Detecting the language of a text</strong></h3><p name="c158" id="c158" class="graf graf--p graf-after--h3"><a href="http://aws.amazon.com/comprehend" data-href="http://aws.amazon.com/comprehend" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon Comprehend</strong></a> is a Natural Language Processing service launched at re:Invent 2017: one of its features is the ability to <a href="https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html" data-href="https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">detect 100 different languages</a>.</p><p name="3905" id="3905" class="graf graf--p graf-after--p">Here, we’ll simply use the <a href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html" data-href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">DetectDominantLanguage</em></a> API as well as<em class="markup--em markup--p-em"> </em>the <em class="markup--em markup--p-em">JohnnyPi/read</em> topic again (with a ‘<em class="markup--em markup--p-em">language</em>’ message).</p><figure name="6d8c" id="6d8c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/51c12b032cfeb67fd2db8a67e68f901f.js"></script></figure><p name="9d14" id="9d14" class="graf graf--p graf-after--figure">Skill-side, we need to create another new intent (<em class="markup--em markup--p-em">LanguageIntent</em>, no slot needed) and implement the corresponding handler in the Lambda function.</p><figure name="a76f" id="a76f" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/4248765b6635c514887281e05c11b271.js"></script></figure><p name="3c1f" id="3c1f" class="graf graf--p graf-after--figure">Let’s try it.</p><figure name="0d5c" id="0d5c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ERBEdSkgaADCyJFxryWPKA.png" data-width="579" data-height="474" src="https://cdn-images-1.medium.com/max/800/1*ERBEdSkgaADCyJFxryWPKA.png"></figure><h3 name="360f" id="360f" class="graf graf--h3 graf-after--figure"><strong class="markup--strong markup--h3-strong">Translating text</strong></h3><p name="459d" id="459d" class="graf graf--p graf-after--h3"><a href="http://aws.amazon.com/translate" data-href="http://aws.amazon.com/translate" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon Translate</strong></a> is another service launched at re:Invent 2017. At the time of writing, it can <a href="https://docs.aws.amazon.com/translate/latest/dg/what-is.html" data-href="https://docs.aws.amazon.com/translate/latest/dg/what-is.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">translate</a> from English to French, Spanish, Portuguese, German, Chinese (simplified) and Arabic, and vice-versa. More languages are coming soon :)</p><p name="1c22" id="1c22" class="graf graf--p graf-after--p">We’ll use the <a href="https://docs.aws.amazon.com/translate/latest/dg/API_TranslateText.html" data-href="https://docs.aws.amazon.com/translate/latest/dg/API_TranslateText.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">TranslateText</em></a> API and the <em class="markup--em markup--p-em">JohnnyPi/read</em> topic again (with a ‘<em class="markup--em markup--p-em">translate DESTINATION LANGUAGE</em>’ message). We’ll support translation for any of these language pairs: English, French, Spanish, Portuguese and German. We’ll use English as a pivot language when needed.</p><blockquote name="f21e" id="f21e" class="graf graf--blockquote graf-after--p">Polly doesn’t yet support Arabic and Chinese, which is why I’ve left them out.</blockquote><p name="86fc" id="86fc" class="graf graf--p graf-after--blockquote">Translate supports <strong class="markup--strong markup--p-strong">source language detection</strong> (you just use ‘auto’ as the source language), but we can’t use it here: we need to know what the source language is — Comprehend will tell us — in order to decide if we need to pivot or not.</p><figure name="cc59" id="cc59" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/e48233cd912ba24dc7332e11bea88bf0.js"></script></figure><p name="6fc2" id="6fc2" class="graf graf--p graf-after--figure">Skill-side, there’s a little more work this time:</p><ul class="postList"><li name="5cbe" id="5cbe" class="graf graf--li graf-after--p">We need a <strong class="markup--strong markup--li-strong">slot</strong> for the target language. There is a convenient pre-defined <strong class="markup--strong markup--li-strong">slot type</strong> named <em class="markup--em markup--li-em">AMAZON.Language</em>, which is exactly what we need!</li><li name="131d" id="131d" class="graf graf--li graf-after--li">We need to <strong class="markup--strong markup--li-strong">validate</strong> the slot against the list of supported languages.</li></ul><figure name="c3ad" id="c3ad" class="graf graf--figure graf--iframe graf-after--li"><script src="https://gist.github.com/juliensimon/199164b305d2912dc6bc211e4515e2eb.js"></script></figure><p name="628f" id="628f" class="graf graf--p graf-after--figure">Let’s try English to German.</p><figure name="b6e9" id="b6e9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*aYOP2vOxcydTyOPiaCDdMA.png" data-width="573" data-height="467" src="https://cdn-images-1.medium.com/max/800/1*aYOP2vOxcydTyOPiaCDdMA.png"></figure><p name="c614" id="c614" class="graf graf--p graf-after--figure">Now what about German to Spanish?</p><figure name="e193" id="e193" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*-_KSJ58W1rHjCX3y7Ljlfw.png" data-width="580" data-height="439" src="https://cdn-images-1.medium.com/max/800/1*-_KSJ58W1rHjCX3y7Ljlfw.png"></figure><h3 name="9a56" id="9a56" class="graf graf--h3 graf-after--figure">Live testing</h3><p name="9bcc" id="9bcc" class="graf graf--p graf-after--h3">OK, now you really want to see this live, don’t you? Of course :)</p><figure name="26da" id="26da" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/L51pST6Mll0?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><p name="601b" id="601b" class="graf graf--p graf-after--figure">If you’d like to know more about all these services, please take a look at this recent <a href="https://www.youtube.com/watch?v=hs1JodCIe4s" data-href="https://www.youtube.com/watch?v=hs1JodCIe4s" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">AWS Summit talk</a>.</p><p name="1a47" id="1a47" class="graf graf--p graf-after--p graf--trailing">Happy to answer questions here or on <a href="https://twitter.com/julsimon" data-href="https://twitter.com/julsimon" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener nofollow noopener noopener" target="_blank">Twitter</a>. For more content, please feel free to check out my <a href="https://www.youtube.com/juliensimonfr" data-href="https://www.youtube.com/juliensimonfr" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener noopener nofollow noopener noopener" target="_blank">YouTube channel</a>.</p></div></div></section><section name="7096" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="fc73" id="fc73" class="graf graf--p graf--leading">Part 0: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-0-1eb537e5a36" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-0-1eb537e5a36" class="markup--anchor markup--p-anchor" target="_blank">a sneak preview</a></p><p name="4525" id="4525" class="graf graf--p graf-after--p">Part 1: <a href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-1-moving-around-e09fe95bbfce" data-href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-1-moving-around-e09fe95bbfce" class="markup--anchor markup--p-anchor" rel="noopener nofollow nofollow noopener nofollow noopener nofollow noopener nofollow noopener noopener" target="_blank">moving around</a></p><p name="58a9" id="58a9" class="graf graf--p graf-after--p">Part 2: <a href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-2-the-joystick-db8ac067e86" data-href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-2-the-joystick-db8ac067e86" class="markup--anchor markup--p-anchor" rel="nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener noopener" target="_blank">the joystick</a></p><p name="a175" id="a175" class="graf graf--p graf-after--p">Part 3: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" class="markup--anchor markup--p-anchor" target="_blank">cloud-based speech</a></p><p name="7aa6" id="7aa6" class="graf graf--p graf-after--p">Part 4: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" class="markup--anchor markup--p-anchor" target="_blank">cloud-based vision</a></p><p name="8772" id="8772" class="graf graf--p graf-after--p">Part 5: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" class="markup--anchor markup--p-anchor" target="_blank">local vision</a></p><p name="7ba1" id="7ba1" class="graf graf--p graf-after--p">Part 6: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-6-now-im-pushing-your-button-ha-7a591c46ab74" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-6-now-im-pushing-your-button-ha-7a591c46ab74" class="markup--anchor markup--p-anchor" target="_blank">the IoT button</a></p><p name="31e2" id="31e2" class="graf graf--p graf-after--p graf--trailing">Part 7: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-7-son-we-need-to-talk-5a910aa642d1" data-href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-7-son-we-need-to-talk-5a910aa642d1" class="markup--anchor markup--p-anchor" target="_blank">the Alexa skill</a></p></div></div></section><section name="26ce" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="98e9" id="98e9" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">Be good, Johnny. I’m going to need you for a few demos :)</em></p><figure name="1473" id="1473" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/yAl80RTYydQ?feature=oembed" width="640" height="480" frameborder="0" scrolling="no"></iframe></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/c22f7b8275cc"><time class="dt-published" datetime="2018-06-07T08:12:00.026Z">June 7, 2018</time></a>.</p><p><a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-8-reading-translating-and-more-c22f7b8275cc" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Apache MXNet as a backend for Keras 2</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Apache MXNet as a backend for Keras 2</h1>
</header>
<section data-field="subtitle" class="p-summary">
In a previous post, we saw how Apache MXNet could be used as backend for Keras 1.2 — and how fast it was.
</section>
<section data-field="body" class="e-content">
<section name="c880" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="06c7" id="06c7" class="graf graf--h3 graf--leading graf--title">Apache MXNet as a backend for Keras 2</h3><p name="7ba5" id="7ba5" class="graf graf--p graf-after--h3">In a previous post, we saw how <a href="https://mxnet.incubator.apache.org/" data-href="https://mxnet.incubator.apache.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Apache MXNet</strong></a> could be used as backend for <strong class="markup--strong markup--p-strong">Keras 1.2</strong> — and how fast it was.</p><div name="bcb6" id="bcb6" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0" data-href="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0"><strong class="markup--strong markup--mixtapeEmbed-strong">Keras shoot-out: TensorFlow vs MXNet</strong><br><em class="markup--em markup--mixtapeEmbed-em">A few months, we took an early look at running Keras with Apache MXNet as its backend. Things were pretty beta at the…</em>medium.com</a><a href="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="e1f3e16b2a79ed0f75ee2660509c9131" data-thumbnail-img-id="1*1VZzy-6pi_CNZpL0UfwHKQ.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*1VZzy-6pi_CNZpL0UfwHKQ.jpeg);"></a></div><p name="0f61" id="0f61" class="graf graf--p graf-after--mixtapeEmbed">Lo and behold, you can now use it with <strong class="markup--strong markup--p-strong">Keras 2</strong> (with some restrictions). This is great news both for the Keras community and for the MXNet community, so how about a collective thumbs up to <a href="https://github.com/sandeep-krishnamurthy" data-href="https://github.com/sandeep-krishnamurthy" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@sandeep-krishnamurthy</a>, <a href="https://github.com/jiajiechen" data-href="https://github.com/jiajiechen" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@jiajiechen</a>, <a href="https://github.com/karan6181" data-href="https://github.com/karan6181" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@karan6181</a>, <a href="https://github.com/roywei" data-href="https://github.com/roywei" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@roywei</a>, <a href="https://github.com/kalyc" data-href="https://github.com/kalyc" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">@kalyc</a> for their contribution.</p><p name="ed71" id="ed71" class="graf graf--p graf-after--p">This post will show how you how to install this version of Keras, tell you what is supported and what isn’t at the moment and of course how to run your trainings faster by using multiple GPUs.</p><figure name="0e0a" id="0e0a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*xtbNkSyRXyZgw21h.jpg" data-width="1200" data-height="675" src="https://cdn-images-1.medium.com/max/800/0*xtbNkSyRXyZgw21h.jpg"><figcaption class="imageCaption">Yeah, it’s a bit of an upgrade.</figcaption></figure><h3 name="b6fa" id="b6fa" class="graf graf--h3 graf-after--figure">Installation</h3><p name="683b" id="683b" class="graf graf--p graf-after--h3">Let’s fire up an EC2 instance with the <a href="https://aws.amazon.com/machine-learning/amis/" data-href="https://aws.amazon.com/machine-learning/amis/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Deep Learning AMI</a>. I’ll use the Conda version which lets us easily manage different Python environments… and avoid making a huge mess of everything ;)</p><pre name="4b7a" id="4b7a" class="graf graf--pre graf-after--p">$ conda create -n mxnet-keras<br>$ source activate mxnet-keras<br>$ pip3 install mxnet-cu90 --upgrade<br>$ pip3 install keras-mxnet --upgrade<br>$ python3<br>&gt;&gt;&gt; import mxnet, keras<br>&gt;&gt;&gt; print (&quot;%s %s&quot; % (mxnet.__version__, keras.__version__))<br>1.2.0 2.1.6</pre><p name="5a3d" id="5a3d" class="graf graf--p graf-after--pre">Good. Now let’s make sure that MXNet is actually set as the backend for Keras.</p><pre name="1126" id="1126" class="graf graf--pre graf-after--p">$ cat ~/.keras/keras.json<br>{<br>&quot;backend&quot;: &quot;mxnet&quot;,<br>&quot;image_data_format&quot;: &quot;channels_first&quot;<br>}</pre><p name="9940" id="9940" class="graf graf--p graf-after--pre">Setting ‘<em class="markup--em markup--p-em">image_data_format</em>’ to ‘<em class="markup--em markup--p-em">channels_first</em>’ will make MXNet training faster. When working with image data, the input shape can either be ‘<em class="markup--em markup--p-em">channels_first</em>’, i.e. (number of channels, height, width), or ‘<em class="markup--em markup--p-em">channels_last</em>’, i.e. (height, width, number of channels).</p><blockquote name="4548" id="4548" class="graf graf--blockquote graf-after--p">For MNIST, this would either be (1, 28, 28) or (28, 28, 1) : one channel (black and white pictures), 28 pixels by 28 pixels. For ImageNet, it would be (3, 224, 224) or (224, 224, 3): three channels (red, green and blue), 224 pixels by 224 pixels.</blockquote><p name="ccc5" id="ccc5" class="graf graf--p graf-after--blockquote">We’re ready to play!</p><h3 name="1cda" id="1cda" class="graf graf--h3 graf-after--p">Supported features</h3><p name="4c63" id="4c63" class="graf graf--p graf-after--h3">This is still work in progress. You can check the <a href="https://github.com/awslabs/keras-apache-mxnet/releases" data-href="https://github.com/awslabs/keras-apache-mxnet/releases" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">super detailed release notes</a> (great work, team) to see what’s supported and what isn’t.</p><p name="7f04" id="7f04" class="graf graf--p graf-after--p">In a nutshell (copying from the releases notes):</p><pre name="bcb0" id="bcb0" class="graf graf--pre graf-after--p">- Supports <strong class="markup--strong markup--pre-strong">Convolutional Neural Network</strong> (CNN) and <strong class="markup--strong markup--pre-strong">experimental Recurrent Neural Network</strong> (RNN) training and inference.</pre><pre name="2660" id="2660" class="graf graf--pre graf-after--pre">- Supports high performance, distributed <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/multi_gpu_training.md" data-href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/multi_gpu_training.md" class="markup--anchor markup--pre-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--pre-strong">Multi-GPU training</strong></a> of CNN and RNN networks.</pre><pre name="f5d8" id="f5d8" class="graf graf--pre graf-after--pre">- Supports <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/save_mxnet_model.md" data-href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/save_mxnet_model.md" class="markup--anchor markup--pre-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--pre-strong">exporting native MXNet Model from Keras-MXNet</strong></a> trained model. Enabling faster research with Keras interface and high performance, large scale inference in production with the native MXNet engine. You can use all language bindings of MXNet (Scala/Python/Julia/R/Perl) for inference on the exported model.</pre><pre name="955a" id="955a" class="graf graf--pre graf-after--pre">- Add <a href="https://github.com/awslabs/keras-apache-mxnet/tree/master/benchmark#setup" data-href="https://github.com/awslabs/keras-apache-mxnet/tree/master/benchmark#setup" class="markup--anchor markup--pre-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--pre-strong">Keras benchmarking utility</strong></a> for performing CNN and RNN benchmarks with standard networks and datasets. Supports benchmarking on CPU, one GPU and multi-GPU distributed training.</pre><p name="36e8" id="36e8" class="graf graf--p graf-after--pre">A few comments:</p><ul class="postList"><li name="39eb" id="39eb" class="graf graf--li graf-after--p">Of course, <strong class="markup--strong markup--li-strong">multi-GPU trainin</strong>g is extremely important. We’ll see in a second how easy it is to add it to any existing Keras script.</li><li name="c4f5" id="c4f5" class="graf graf--li graf-after--li">Using Keras with MXNet brings a <strong class="markup--strong markup--li-strong">major performance boost</strong> over other backends. <a href="https://github.com/awslabs/keras-apache-mxnet/tree/master/benchmark" data-href="https://github.com/awslabs/keras-apache-mxnet/tree/master/benchmark" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Detailed benchmarks</a> are available, they’re most definitely worth a read ;)</li><li name="f8fd" id="f8fd" class="graf graf--li graf-after--li">The third point is <strong class="markup--strong markup--li-strong">extremely</strong> important IMHO. You can use <strong class="markup--strong markup--li-strong">Keras for fast experimentation</strong>, possibly reusing or tweaking models from the vast collection that is available out there. Then, you can export it as a native MXNet model and use it in <strong class="markup--strong markup--li-strong">production with MXNet only</strong>, which will speed things up further because MXNet is implemented in <strong class="markup--strong markup--li-strong">C++</strong>. Very useful feature. You’ll find a complete example <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/save_mxnet_model.md" data-href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/save_mxnet_model.md" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">here</a>.</li></ul><h3 name="9f6a" id="9f6a" class="graf graf--h3 graf-after--li">Multi-GPU training</h3><p name="5ac8" id="5ac8" class="graf graf--p graf-after--h3">In the Keras 1.2 version, this was available by building an MXNet-style context.</p><pre name="af32" id="af32" class="graf graf--pre graf-after--p">NUM_GPU = 4<br>gpu_list = []                       <br>for i in range(NUM_GPU): <br>    gpu_list.append(&#39;gpu(%d)&#39; % i)                                               </pre><pre name="36c3" id="36c3" class="graf graf--pre graf-after--pre">model.compile(<br>   loss=&#39;categorical_crossentropy&#39;,                            <br>   optimizer=SGD(),                        <br>   metrics=[&#39;accuracy&#39;],                        <br>   context=gpu_list)</pre><p name="f2c9" id="f2c9" class="graf graf--p graf-after--pre">Now all we have to do is:</p><pre name="55bc" id="55bc" class="graf graf--pre graf-after--p">from keras.utils import multi_gpu_model<br>...<br>model = multi_gpu_model(model, gpus=4)<br>model.compile(loss=&#39;categorical_crossentropy&#39;,<br>              optimizer=SGD(),<br>              metrics=[&#39;accuracy&#39;])</pre><p name="0ec2" id="0ec2" class="graf graf--p graf-after--pre">This is definitely more convenient. Just wrap the model with <em class="markup--em markup--p-em">multi_gpu_model()</em> before compiling it and voila!</p><h3 name="5e66" id="5e66" class="graf graf--h3 graf-after--p">Example</h3><p name="8d85" id="8d85" class="graf graf--p graf-after--h3">Using a p3.16xlarge instance, let’s clone the <a href="https://github.com/awslabs/keras-apache-mxnet" data-href="https://github.com/awslabs/keras-apache-mxnet" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">keras-mxnet</strong></a> repo.</p><pre name="fe5c" id="fe5c" class="graf graf--pre graf-after--p">$ git clone https://github.com/awslabs/keras-apache-mxnet.git</pre><p name="21c2" id="21c2" class="graf graf--p graf-after--pre">First, we’re going to run the <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/cifar10_resnet.py" data-href="https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/cifar10_resnet.py" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">cifar10_resnet.py</em></a> script, which trains ResNet20v1 on the CIFAR-10 data set. Unsurprisingly, we only use a single GPU ;)</p><figure name="c967" id="c967" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*mOULUppugLIr12CHZC697A.png" data-width="402" data-height="505" src="https://cdn-images-1.medium.com/max/800/1*mOULUppugLIr12CHZC697A.png"></figure><p name="d705" id="d705" class="graf graf--p graf-after--figure">One epoch takes <strong class="markup--strong markup--p-strong">1309 seconds</strong> (almost 22 minutes).</p><pre name="7aa4" id="7aa4" class="graf graf--pre graf-after--p">1563/1563 [==============================] - 1309s 838ms/step - loss: 1.6875 - acc: 0.4412 - val_loss: 1.7708 - val_acc: 0.4323</pre><p name="bb27" id="bb27" class="graf graf--p graf-after--pre">Now, let’s run <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/cifar10_resnet_multi_gpu.py" data-href="https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/cifar10_resnet_multi_gpu.py" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">cifar10_resnet_multi_gpu.py</em></a> script on 8 GPUs :) All it takes is adding the couple of lines mentioned above.</p><figure name="009e" id="009e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*nZfWSrXYH252VmNwQFX0SQ.png" data-width="401" data-height="601" src="https://cdn-images-1.medium.com/max/800/1*nZfWSrXYH252VmNwQFX0SQ.png"><figcaption class="imageCaption">Oh yesssss. My preciousss.</figcaption></figure><p name="c75a" id="c75a" class="graf graf--p graf-after--figure">One epoch now takes <strong class="markup--strong markup--p-strong">190 seconds</strong>.</p><pre name="4c10" id="4c10" class="graf graf--pre graf-after--p">1563/1563 [==============================] - 190s 122ms/step - loss: 1.2006 - acc: 0.6315 - val_loss: 1.2958 - val_acc: 0.61</pre><p name="da87" id="da87" class="graf graf--p graf-after--pre">1309/190 = 6.88. Not quite 8x speedup, but pretty close!</p><p name="b221" id="b221" class="graf graf--p graf-after--p">That’s it for today. I’m really excited about the combination of Keras and MXNet. Flexibility and speed! <strong class="markup--strong markup--p-strong">Please give it a try.</strong></p><p name="6890" id="6890" class="graf graf--p graf-after--p graf--trailing">Happy to answer questions here or on <a href="https://twitter.com/julsimon" data-href="https://twitter.com/julsimon" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener nofollow noopener noopener noopener" target="_blank">Twitter</a>. For more content, please feel free to check out my <a href="https://www.youtube.com/juliensimonfr" data-href="https://www.youtube.com/juliensimonfr" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener noopener nofollow noopener noopener noopener" target="_blank">YouTube channel</a>.</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/9993f97843e7"><time class="dt-published" datetime="2018-06-01T08:18:56.945Z">June 1, 2018</time></a>.</p><p><a href="https://medium.com/@julsimon/apache-mxnet-as-a-backend-for-keras-2-9993f97843e7" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Keras shoot-out: TensorFlow vs MXNet</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Keras shoot-out: TensorFlow vs MXNet</h1>
</header>
<section data-field="subtitle" class="p-summary">
A few months, we took an early look at running Keras with Apache MXNet as its backend. Things were pretty beta at the time, but a lot of…
</section>
<section data-field="body" class="e-content">
<section name="b693" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="0511" id="0511" class="graf graf--h3 graf--leading graf--title">Keras shoot-out: TensorFlow vs MXNet</h3><p name="9378" id="9378" class="graf graf--p graf-after--h3">A few months, we took an <a href="https://medium.com/@julsimon/apache-mxnet-support-in-keras-83de7dec46e5" data-href="https://medium.com/@julsimon/apache-mxnet-support-in-keras-83de7dec46e5" class="markup--anchor markup--p-anchor" target="_blank">early look</a> at running <a href="http://keras.io" data-href="http://keras.io" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Keras</a> with <a href="http://mxnet.io" data-href="http://mxnet.io" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Apache MXNet</a> as its backend. Things were pretty beta at the time, but a lot of progress has since been made. It’s time to reevaluate… and benchmark MXNet against <a href="https://www.tensorflow.org/" data-href="https://www.tensorflow.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Tensorflow</a>.</p><figure name="0268" id="0268" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*1VZzy-6pi_CNZpL0UfwHKQ.jpeg" data-width="714" data-height="300" src="https://cdn-images-1.medium.com/max/800/1*1VZzy-6pi_CNZpL0UfwHKQ.jpeg"><figcaption class="imageCaption">In this world, there’s two kinds of people, my friend. Those with GPUs and those who wait for days. You wait.</figcaption></figure><h4 name="5d90" id="5d90" class="graf graf--h4 graf-after--figure">The story so far</h4><p name="c4f4" id="c4f4" class="graf graf--p graf-after--h4">The good folks at DMLC have <a href="https://github.com/dmlc/keras/" data-href="https://github.com/dmlc/keras/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">forked</a> Keras 1.2 in order to implement MXNet support, multi-GPU included. In parallel, they’ve moved the projet to the Apache Incubator and are currently putting the finishing touches to <a href="https://github.com/apache/incubator-mxnet" data-href="https://github.com/apache/incubator-mxnet" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MXNet 0.11</a>. This is pretty impressive work in such a short time frame!</p><p name="19fb" id="19fb" class="graf graf--p graf-after--p">In addition to the Keras and MXNet codebases, here’s what we’re going to use today:</p><ul class="postList"><li name="57c8" id="57c8" class="graf graf--li graf-after--p"><a href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" data-href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">The Deep Learning AMI</a> (Ubuntu version), which already includes Tensorflow 1.2.</li><li name="8e54" id="8e54" class="graf graf--li graf-after--li">A <a href="https://aws.amazon.com/blogs/aws/new-p2-instance-type-for-amazon-ec2-up-to-16-gpus/" data-href="https://aws.amazon.com/blogs/aws/new-p2-instance-type-for-amazon-ec2-up-to-16-gpus/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">p2.8xlarge</a> EC2 instance, powered by 8 K80 NVIDIA GPUs</li><li name="c4c8" id="c4c8" class="graf graf--li graf-after--li">The <a href="https://www.cs.toronto.edu/~kriz/cifar.html" data-href="https://www.cs.toronto.edu/~kriz/cifar.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">CIFAR-10</a> dataset, which we covered in detail in <a href="https://becominghuman.ai/training-mxnet-part-2-cifar-10-c7b0b729c33c" data-href="https://becominghuman.ai/training-mxnet-part-2-cifar-10-c7b0b729c33c" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">previous posts</a></li><li name="ce35" id="ce35" class="graf graf--li graf-after--li">The famous <a href="https://github.com/KaimingHe/deep-residual-networks" data-href="https://github.com/KaimingHe/deep-residual-networks" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">RESNET-50</a> network.</li></ul><p name="fdc8" id="fdc8" class="graf graf--p graf-after--li">Let’s ride.</p><h4 name="176b" id="176b" class="graf graf--h4 graf-after--p">Installing MXNet and Keras</h4><p name="5ae4" id="5ae4" class="graf graf--p graf-after--h4">Once the instance is running, we first have to update MXNet to the latest version (0.11.0-rc3 at the time of writing). Here, we’re obviously going for GPU support.</p><figure name="e1a3" id="e1a3" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/fb4b6b5f703b0e53d75f48ec8b3460a6.js"></script></figure><p name="e0b4" id="e0b4" class="graf graf--p graf-after--figure">Updating Keras is quite simple too.</p><figure name="6a70" id="6a70" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/2111c2819d170ddcbec58858904f6c9e.js"></script></figure><p name="4165" id="4165" class="graf graf--p graf-after--figure">Let’s check that we have the correct versions.</p><figure name="bcfb" id="bcfb" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/41f2c266a70b8667b6048c914d132a5f.js"></script></figure><p name="2f9a" id="2f9a" class="graf graf--p graf-after--figure">Ok, looks good. Let’s move on to training.</p><h4 name="9850" id="9850" class="graf graf--h4 graf-after--p">Keras backends</h4><p name="f1c7" id="f1c7" class="graf graf--p graf-after--h4">Keras supports multiple backends for training and it’s very easy to switch from one to the other. Here are the two file versions for Tensorflow and MXNet.</p><blockquote name="d82a" id="d82a" class="graf graf--blockquote graf-after--p">All it takes is one line in the <em class="markup--em markup--blockquote-em">~/.keras/keras.json</em> file.</blockquote><figure name="6858" id="6858" class="graf graf--figure graf--iframe graf-after--blockquote"><script src="https://gist.github.com/juliensimon/dfd25cb4317ca563c9798994b4e0f182.js"></script></figure><h4 name="c6fc" id="c6fc" class="graf graf--h4 graf-after--figure">Learning CIFAR-10 with Tensorflow</h4><p name="faf8" id="faf8" class="graf graf--p graf-after--h4">Keras provides plenty of nice examples in <em class="markup--em markup--p-em">~/keras/examples</em>. We can use <em class="markup--em markup--p-em">cifar10_resnet50.py </em>pretty much as is. Since we’re going to be using all 8 GPUs, let’s just update the batch size to 256, the number of epochs to 100 and disable data augmentation.</p><figure name="eee4" id="eee4" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/f1577bc971aa50941cb6de51b03ff235.js"></script></figure><p name="87f3" id="87f3" class="graf graf--p graf-after--figure">Time to train.</p><figure name="6333" id="6333" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/f32eb3c8c71381f2698e4f8c7813f793.js"></script></figure><p name="1ef3" id="1ef3" class="graf graf--p graf-after--figure">Here’s what memory usage looks like, as reported by <em class="markup--em markup--p-em">nvidia-smi</em>.</p><figure name="6edb" id="6edb" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/d64fd836a2270563d56acb36a34769ee.js"></script></figure><p name="cb58" id="cb58" class="graf graf--p graf-after--figure">As we can see, TensorFlow is a bit of a memory hog, pretty much eating up 100% of available GPU memory . Not really a problem here, but I’m wondering if a much more complex model would still be able to fit in memory. To be tested in a future post, I suppose :)</p><p name="f55e" id="f55e" class="graf graf--p graf-after--p">After a while, here’s the result (full log <a href="https://gist.github.com/juliensimon/0559f4fb852a630023097f881d506c61" data-href="https://gist.github.com/juliensimon/0559f4fb852a630023097f881d506c61" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>).</p><figure name="455a" id="455a" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/24b2eb46857bccb67811d69d7a547b95.js"></script></figure><p name="4140" id="4140" class="graf graf--p graf-after--figure">All right. Now let’s move on to MXNet.</p><h4 name="098f" id="098f" class="graf graf--h4 graf-after--p">Learning CIFAR-10 with MXNet</h4><p name="49e5" id="49e5" class="graf graf--p graf-after--h4">At the moment, auto-detection of GPUs is not implemented for MXNet in Keras, so we need to pass the list of available GPUs to the <em class="markup--em markup--p-em">compile</em>() API</p><blockquote name="95bc" id="95bc" class="graf graf--blockquote graf-after--p">Just replace the call to <em class="markup--em markup--blockquote-em">model.compile</em>() in <em class="markup--em markup--blockquote-em">cifar10_resnet.py</em> with this snippet.</blockquote><figure name="b0a4" id="b0a4" class="graf graf--figure graf--iframe graf-after--blockquote"><script src="https://gist.github.com/juliensimon/7906db1a7112247aecbfbf3cf22e3c1e.js"></script></figure><p name="322e" id="322e" class="graf graf--p graf-after--figure">Time to train.</p><figure name="ed01" id="ed01" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/ebecfb6e291b65e3219c2e0eb99f0916.js"></script></figure><p name="7ca6" id="7ca6" class="graf graf--p graf-after--figure">Holy moly! MXNet is <strong class="markup--strong markup--p-strong">60% faster</strong>: 25 seconds per epoch instead of 61. Very nice. In the same time frame, this would definitely allow us to try more things, like different model architectures or different hyper parameters. Definitely an advantage when you’re experimenting.</p><p name="8391" id="8391" class="graf graf--p graf-after--p">What about memory usage? As we can see, MXNet uses over <strong class="markup--strong markup--p-strong">90% less RAM</strong> and there is plenty left for other jobs.</p><figure name="8753" id="8753" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/36f5dbab924f02541792433d2e3bbf09.js"></script></figure><p name="9ab1" id="9ab1" class="graf graf--p graf-after--figure">Here’s the result after 100 epochs (full log <a href="https://gist.github.com/juliensimon/29165dc7293e2602a6203255f65264b1" data-href="https://gist.github.com/juliensimon/29165dc7293e2602a6203255f65264b1" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>): <strong class="markup--strong markup--p-strong">43 minutes</strong>, <strong class="markup--strong markup--p-strong">99.4%</strong> training accuracy, <strong class="markup--strong markup--p-strong">62%</strong> test accuracy.</p><figure name="5463" id="5463" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/55f7e3649746586f2bbec2fa2905e138.js"></script></figure><h4 name="ef82" id="ef82" class="graf graf--h4 graf-after--figure">Conclusion</h4><p name="28a5" id="28a5" class="graf graf--p graf-after--h4">Granted, this is a single example and no hasty conclusion should be drawn. Still, with 8 GPUs and a well-known data set, MXNet is <strong class="markup--strong markup--p-strong">significantly faster, much more memory-efficient </strong>and<strong class="markup--strong markup--p-strong"> more accurate </strong>than Tensorflow.</p><blockquote name="d55f" id="d55f" class="graf graf--blockquote graf-after--p">It seems to me every Deep Learning practitioner ought to check MXNet out, especially now that it’s properly integrated with Keras: changing a line of configuration is all it takes :)</blockquote><p name="c591" id="c591" class="graf graf--p graf-after--blockquote">If you’d like to dive a bit more into MXNet, may I recommend the following resources?</p><figure name="031e" id="031e" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F331248651&amp;show_artwork=true" width="700" height="145" frameborder="0" scrolling="no"></iframe></figure><div name="1089" id="1089" class="graf graf--mixtapeEmbed graf-after--figure"><a href="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab" data-href="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab"><strong class="markup--strong markup--mixtapeEmbed-strong">An introduction to the MXNet API — part 1</strong><br><em class="markup--em markup--mixtapeEmbed-em">Update August 1st, 2017: <br>this series is now available in Japanese, Chinese and Korean.</em>becominghuman.ai</a><a href="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="c6e0f983acb27726baf2816fb01f2357" data-thumbnail-img-id="1*H0-jFUWPK6TQIXeNqTnaUg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*H0-jFUWPK6TQIXeNqTnaUg.png);"></a></div><div name="7920" id="7920" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="http://mxnet.io" data-href="http://mxnet.io" class="markup--anchor markup--mixtapeEmbed-anchor" title="http://mxnet.io"><strong class="markup--strong markup--mixtapeEmbed-strong">MXNet: A Scalable Deep Learning Framework</strong><br><em class="markup--em markup--mixtapeEmbed-em">Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache…</em>mxnet.io</a><a href="http://mxnet.io" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="fa85189b90a1a8ed2814ed4435ec1942" data-thumbnail-img-id="0*oNXghWP1DvYh5Fkf." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*oNXghWP1DvYh5Fkf.);"></a></div><p name="e9fb" id="e9fb" class="graf graf--p graf-after--mixtapeEmbed"><a href="https://medium.com/@julsimon/keras-shoot-out-part-2-a-deeper-look-at-memory-usage-8a2dd997de81" data-href="https://medium.com/@julsimon/keras-shoot-out-part-2-a-deeper-look-at-memory-usage-8a2dd997de81" class="markup--anchor markup--p-anchor" target="_blank">In part 2</a>, I’m taking a deeper look at memory usage in Tensorflow and how to optimise it.</p><p name="4414" id="4414" class="graf graf--p graf-after--p"><a href="https://medium.com/@julsimon/keras-shoot-out-part-3-fine-tuning-7d1548c51a41" data-href="https://medium.com/@julsimon/keras-shoot-out-part-3-fine-tuning-7d1548c51a41" class="markup--anchor markup--p-anchor" target="_blank">In part 3</a>, we’ll learn how to fine-tune the models for improved accuracy.</p><p name="00e4" id="00e4" class="graf graf--p graf-after--p graf--trailing">Thank you for reading :)</p></div></div></section><section name="c0d0" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="03ed" id="03ed" class="graf graf--p graf--leading graf--trailing"><em class="markup--em markup--p-em">This post was written while blasting classics by Whitesnake, Rainbow and Dio. Fortunately, no neighbour was injured in the process.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/51ae2b30a9c0"><time class="dt-published" datetime="2017-09-03T16:37:08.922Z">September 3, 2017</time></a>.</p><p><a href="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

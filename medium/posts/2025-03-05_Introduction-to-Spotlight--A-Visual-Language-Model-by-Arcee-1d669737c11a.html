<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Introduction to Spotlight: A Visual Language Model by Arcee</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Introduction to Spotlight: A Visual Language Model by Arcee</h1>
</header>
<section data-field="subtitle" class="p-summary">
In the rapidly evolving landscape of artificial intelligence, the integration of vision and language has opened up new avenues for…
</section>
<section data-field="body" class="e-content">
<section name="0d38" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="a9f7" id="a9f7" class="graf graf--h3 graf--leading graf--title"><strong class="markup--strong markup--h3-strong">Introduction to Spotlight: A Visual Language Model by Arcee</strong></h3><figure name="3812" id="3812" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*_7E_OCExFLf_gZSfF_awJw.png" data-width="1500" data-height="849" src="https://cdn-images-1.medium.com/max/800/1*_7E_OCExFLf_gZSfF_awJw.png"></figure><p name="8b3a" id="8b3a" class="graf graf--p graf-after--figure">In the rapidly evolving landscape of artificial intelligence, the integration of vision and language has opened up new avenues for applications that were once the realm of science fiction. One of the most exciting developments in this domain is the emergence of visual language models (VLMs), which can understand and interact with images using natural language. These models are not only transforming how we process and interact with visual content but are also paving the way for more intuitive and accessible AI-powered tools.</p><p name="61ac" id="61ac" class="graf graf--p graf-after--p">In this blog post, we will explore <strong class="markup--strong markup--p-strong">Spotlight</strong>, a new VLM introduced by Arcee, a leading AI company. Spotlight is designed to provide robust and efficient interaction with image content, making it a valuable tool for a wide range of applications, from content creation to data management. We will delve into the features of Spotlight, demonstrate its capabilities, and discuss its potential use cases.</p><h3 name="ce2e" id="ce2e" class="graf graf--h3 graf-after--p">What is Spotlight?</h3><p name="7eea" id="7eea" class="graf graf--p graf-after--h3">Spotlight is a 7 billion-parameter visual language model developed by Arcee. It is based on the Qwen 2.5-VL architecture, which has been further refined and enhanced by Arcee’s research team. The model is hosted on Arcee’s inference platform, <strong class="markup--strong markup--p-strong">Model Engine</strong>, which is designed to be compatible with OpenAI APIs, making it easy for developers to integrate Spotlight into their existing workflows.</p><figure name="4c16" id="4c16" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/xIsIcT8L5tE?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><h3 name="9747" id="9747" class="graf graf--h3 graf-after--figure">Key Features of Spotlight</h3><p name="a922" id="a922" class="graf graf--p graf-after--h3">• <strong class="markup--strong markup--p-strong">Parameter Count</strong>: 7 billion parameters, making it a lightweight yet powerful model.</p><p name="4709" id="4709" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Context Length</strong>: 32k, allowing for rich and detailed interactions with images.</p><p name="837c" id="837c" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Pricing</strong>: 10 cents per million tokens for input and 40 cents per million tokens for output, making it cost-effective for large-scale applications.</p><p name="3b4f" id="3b4f" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">API Compatibility</strong>: Fully compatible with OpenAI APIs, ensuring a smooth integration process.</p><h3 name="b3e8" id="b3e8" class="graf graf--h3 graf-after--p">Demonstrating Spotlight</h3><h3 name="28ac" id="28ac" class="graf graf--h3 graf-after--h3">Using Model Engine</h3><p name="2c87" id="2c87" class="graf graf--p graf-after--h3">To demonstrate Spotlight, we will first use Arcee’s Model Engine, a platform that hosts various small language models, including Spotlight. Model Engine provides a user-friendly interface and API access, making it easy to test and deploy models.</p><p name="5bc0" id="5bc0" class="graf graf--p graf-after--p">Let’s start with a simple example. We have an image of the ARCEE advertisement on the NASDAQ building, which announces a 24 million series A raise led by Emergence Capital. When we input this image into Spotlight, the model generates a detailed and accurate description:</p><p name="68bc" id="68bc" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Scene</strong>: A bustling urban scene in a financial district.</p><p name="694f" id="694f" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Ad</strong>: A large advertisement for ARCEE on a building.</p><p name="864f" id="864f" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Text</strong>: The ad mentions the 24 million series A raise.</p><p name="e062" id="e062" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Environment</strong>: The area is busy with pedestrians and vehicles, including trucks and construction cones.</p><p name="9f56" id="9f56" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Weather</strong>: Clear and blue sky, suggesting a sunny day.</p><p name="567a" id="567a" class="graf graf--p graf-after--p">Spotlight’s ability to accurately pick up text and logos is particularly noteworthy, as this is a challenge for many image models.</p><h3 name="fab6" id="fab6" class="graf graf--h3 graf-after--p">Using the OpenAI API</h3><p name="3409" id="3409" class="graf graf--p graf-after--h3">For developers who prefer a programmatic approach, Spotlight can be accessed via the OpenAI API. Model Engine uses the same API structure as OpenAI, making it easy to switch between different models.</p><p name="cc97" id="cc97" class="graf graf--p graf-after--p">To demonstrate this, we will use a Python client to interact with the API. We will pass an image to Spotlight and ask it to provide a caption and context.</p><p name="ebef" id="ebef" class="graf graf--p graf-after--p">1. Passing the Image via URL:</p><p name="b442" id="b442" class="graf graf--p graf-after--p">- Prompt: “Where was this picture taken?”</p><p name="782c" id="782c" class="graf graf--p graf-after--p">- Image: A recognizable image (e.g., a famous landmark).</p><p name="a124" id="a124" class="graf graf--p graf-after--p">- Output: The model correctly identifies the location and provides context, such as the event and date (e.g., Bastille Day in Paris).</p><p name="f140" id="f140" class="graf graf--p graf-after--p">2. Passing the Image Inline:</p><p name="443d" id="443d" class="graf graf--p graf-after--p">- Method: Encode the image in base64 format and pass it inline in the API request.</p><p name="8de1" id="8de1" class="graf graf--p graf-after--p">- Use Case: This method is useful when dealing with local images or when you want to avoid HTTP requests.</p><p name="43ef" id="43ef" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Passing the Image via URL</strong>:</p><p name="15f0" id="15f0" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Prompt</strong>: “Where was this picture taken?”</p><p name="bf66" id="bf66" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Image</strong>: A recognizable image (e.g., a famous landmark).</p><p name="9eaf" id="9eaf" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Output</strong>: The model correctly identifies the location and provides context, such as the event and date (e.g., Bastille Day in Paris).</p><p name="c81f" id="c81f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Passing the Image Inline</strong>:</p><p name="723c" id="723c" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Method</strong>: Encode the image in base64 format and pass it inline in the API request.</p><p name="5344" id="5344" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Use Case</strong>: This method is useful when dealing with local images or when you want to avoid HTTP requests.</p><p name="27ea" id="27ea" class="graf graf--p graf-after--p">One of the most powerful features of Spotlight is its ability to generate structured metadata from images. This is particularly useful for content management, image search, and data storage. For example, given an image of a famous landmark, Spotlight can generate metadata in JSON format, including:</p><p name="29d9" id="29d9" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Country</strong>: France</p><p name="78e7" id="78e7" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">City</strong>: Paris</p><p name="3d71" id="3d71" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Landmark</strong>: Arc de Triomphe</p><p name="6710" id="6710" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Short Description</strong>: “Air show over the Arc de Triomphe with colorful smoke trails.”</p><p name="c1c4" id="c1c4" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Detailed Description</strong>: A more elaborate description of the scene.</p><p name="2de9" id="2de9" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Themes</strong>: “Military parade, fireworks, national holiday.”</p><p name="08c3" id="08c3" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Keywords</strong>: “Bastille Day, Paris, Arc de Triomphe, fireworks, military parade.”</p><h3 name="e9d2" id="e9d2" class="graf graf--h3 graf-after--p">Performance and Efficiency</h3><p name="3606" id="3606" class="graf graf--p graf-after--h3">Spotlight’s lightweight architecture (7B parameters) ensures that it is fast and efficient, making it suitable for real-time applications and large-scale image processing. The model’s speed is a significant advantage, especially in scenarios where low latency is crucial.</p><h3 name="bc8e" id="bc8e" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="9e37" id="9e37" class="graf graf--p graf-after--h3">Spotlight represents a significant advancement in the field of visual language models, offering a powerful and efficient tool for interacting with images using natural language. Its ability to generate accurate descriptions, captions, and structured metadata opens up a wide range of applications, from content creation to data management.</p><p name="9db9" id="9db9" class="graf graf--p graf-after--p">If you are interested in exploring Spotlight and other models by Arcee, we encourage you to:</p><p name="5b0a" id="5b0a" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Learn more about Arcee Orchestra in our launch blog post</strong> <a href="https://blog.arcee.ai/taking-the-stage-arcee-orchestra/" data-href="https://blog.arcee.ai/taking-the-stage-arcee-orchestra/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Taking the Stage: Arcee Orchestra</a></p><p name="1c03" id="1c03" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Watch more videos on our YouTube channel</strong> <a href="https://www.youtube.com/@ArceeAI" data-href="https://www.youtube.com/@ArceeAI" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Arcee AI</a></p><p name="3905" id="3905" class="graf graf--p graf-after--p">• <strong class="markup--strong markup--p-strong">Follow Arcee AI on LinkedIn</strong> <a href="https://www.linkedin.com/company/arcee-ai" data-href="https://www.linkedin.com/company/arcee-ai" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Arcee AI</a> to stay updated on the latest developments and content.</p><p name="45c5" id="45c5" class="graf graf--p graf-after--p graf--trailing">We look forward to seeing the innovative ways in which you will use Spotlight to enhance your projects and workflows. Keep rocking!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/1d669737c11a"><time class="dt-published" datetime="2025-03-05T10:11:08.936Z">March 5, 2025</time></a>.</p><p><a href="https://medium.com/@julsimon/arcee-spotlight-a-super-fast-7-billion-parameter-visual-language-model-1d669737c11a" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
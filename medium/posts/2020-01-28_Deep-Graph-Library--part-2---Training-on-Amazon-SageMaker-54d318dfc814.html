<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Deep Graph Library, part 2 — Training on Amazon SageMaker</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Deep Graph Library, part 2 — Training on Amazon SageMaker</h1>
</header>
<section data-field="subtitle" class="p-summary">
In a previous post, I showed you how to use the Deep Graph Library (DGL) to train a Graph Neural Network model on data stored in Amazon…
</section>
<section data-field="body" class="e-content">
<section name="f4f6" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="ee8d" id="ee8d" class="graf graf--h3 graf--leading graf--title">Deep Graph Library, part 2 — Training on Amazon SageMaker</h3><p name="eb91" id="eb91" class="graf graf--p graf-after--h3">In a <a href="https://medium.com/@julsimon/a-primer-on-graph-neural-networks-with-amazon-neptune-and-the-deep-graph-library-5ce64984a276" data-href="https://medium.com/@julsimon/a-primer-on-graph-neural-networks-with-amazon-neptune-and-the-deep-graph-library-5ce64984a276" class="markup--anchor markup--p-anchor" target="_blank">previous post</a>, I showed you how to use the <a href="https://www.dgl.ai/" data-href="https://www.dgl.ai/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Deep Graph Library</a> (DGL) to train a Graph Neural Network model on data stored in Amazon Neptune.</p><p name="5719" id="5719" class="graf graf--p graf-after--p">I used a vanilla Jupyter notebook, which is fine for experimentation, but what about training at scale on large datasets? Well, as DGL is available on <a href="https://aws.amazon.com/sagemaker" data-href="https://aws.amazon.com/sagemaker" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Amazon SageMaker</a>, I’ll show you in this post how to quickly and easily adapt your DGL code for SageMaker.</p><figure name="e3e4" id="e3e4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Ti5TbBkB0vxxKOC5DyESHQ.png" data-width="891" data-height="514" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*Ti5TbBkB0vxxKOC5DyESHQ.png"></figure><h3 name="493c" id="493c" class="graf graf--h3 graf-after--figure">Adapting our code</h3><p name="eb3f" id="eb3f" class="graf graf--p graf-after--h3">Let’s take a look at the notebook I used in the previous post.</p><div name="d2b7" id="d2b7" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club.ipynb" data-href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club.ipynb" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club.ipynb"><strong class="markup--strong markup--mixtapeEmbed-strong">dgl/01_karate_club/karate_club.ipynb · master · Julien Simon / dlnotebooks</strong><br><em class="markup--em markup--mixtapeEmbed-em">Machine Learning &amp;amp; Deep Learning notebooks</em>gitlab.com</a><a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club.ipynb" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="ccec443991ca578f2ec3b0c849ae079e" data-thumbnail-img-id="0*yaSDkQd3gw-i-s-_" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*yaSDkQd3gw-i-s-_);"></a></div><p name="249e" id="249e" class="graf graf--p graf-after--mixtapeEmbed">As you probably guessed, we’re going to use <a href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html" data-href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">script mode</a> to run this vanilla PyTorch code on Amazon SageMaker.</p><p name="af53" id="af53" class="graf graf--p graf-after--p">Script mode boils down to:</p><ul class="postList"><li name="a81a" id="a81a" class="graf graf--li graf-after--p">Reading hyperparameters from command line arguments,</li><li name="5c05" id="5c05" class="graf graf--li graf-after--li">Loading the dataset from a location defined by a SageMaker environment variable,</li><li name="fd16" id="fd16" class="graf graf--li graf-after--li">Saving the trained model at a location defined by another SageMaker environment variable.</li></ul><h4 name="55e3" id="55e3" class="graf graf--h4 graf-after--li">Reading Hyperparameters</h4><p name="db9f" id="db9f" class="graf graf--p graf-after--h4">In my script, I need two hyperparameters: the number of epochs to train for, and the number of nodes in the graph. SageMaker will pass them as command line arguments, which I extract with <em class="markup--em markup--p-em">argparse</em>.</p><pre name="9b3e" id="9b3e" class="graf graf--pre graf-after--p">parser = argparse.ArgumentParser()<br>parser.add_argument(‘--epochs’, type=int, default=30)<br>parser.add_argument(&#39;--node_count’, type=int)<br>args, _ = parser.parse_known_args()<br>epochs = args.epochs<br>node_count = args.node_count</pre><h4 name="9e3b" id="9e3b" class="graf graf--h4 graf-after--pre">Loading the Dataset</h4><p name="354b" id="354b" class="graf graf--p graf-after--h4">My dataset is stored in S3. As SageMaker will automatically copy it inside the training container, all I have to do is read an environment variable, and load the data.</p><pre name="c75a" id="c75a" class="graf graf--pre graf-after--p">training_dir = os.environ[‘SM_CHANNEL_TRAINING’]<br>f = open(os.path.join(training_dir, &#39;edge_list.pickle&#39;), &#39;rb&#39;)<br>edge_list = pickle.load(f)</pre><h4 name="6da5" id="6da5" class="graf graf--h4 graf-after--pre">Saving the Model</h4><p name="ba6f" id="ba6f" class="graf graf--p graf-after--h4">Same thing: read an environment variable, and save the model.</p><pre name="1516" id="1516" class="graf graf--pre graf-after--p">model_dir = os.environ[‘SM_MODEL_DIR’]<br>torch.save(net.state_dict(), <br>           os.path.join(model_dir, ‘karate_club.pt’))</pre><p name="6c82" id="6c82" class="graf graf--p graf-after--pre">We’re done. Let’s train this code on SageMaker.</p><h3 name="3299" id="3299" class="graf graf--h3 graf-after--p">Training on Amazon SageMaker</h3><p name="b390" id="b390" class="graf graf--p graf-after--h3">I start with importing the <a href="https://sagemaker.readthedocs.io/en/stable/" data-href="https://sagemaker.readthedocs.io/en/stable/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">SageMaker SDK</a>. Then, I define the S3 bucket that I’ll use to store the dataset, and the IAM role allowing SageMaker to access the bucket.</p><pre name="6351" id="6351" class="graf graf--pre graf-after--p">import sagemaker<br>from sagemaker import get_execution_role<br>from sagemaker.session import Session</pre><pre name="d0d9" id="d0d9" class="graf graf--pre graf-after--pre">sess = sagemaker.Session()<br>bucket = sess.default_bucket()<br>role = get_execution_role()</pre><p name="c637" id="c637" class="graf graf--p graf-after--pre">Next, I upload the dataset to S3.</p><pre name="c28e" id="c28e" class="graf graf--pre graf-after--p">prefix = ‘dgl-karate-club’<br>training_input_path = sess.upload_data(‘edge_list.pickle’,<br>                                      key_prefix=prefix+’/training’)</pre><p name="d531" id="d531" class="graf graf--p graf-after--pre">Now, all I have to do is to define a PyTorch estimator for this training job, pointing at my script, passing hyperparameters, and defining infrastructure requirements.</p><pre name="7419" id="7419" class="graf graf--pre graf-after--p">from sagemaker.pytorch import PyTorch</pre><pre name="abb6" id="abb6" class="graf graf--pre graf-after--pre">estimator = PyTorch(<br>   entry_point=”karate_club_sagemaker.py”,<br>   hyperparameters={‘node_count’: 34, ‘epochs’: 30},<br>   framework_version=’1.3.1&#39;,<br>   py_version=’py3&#39;,<br>   train_instance_count=1, <br>   train_instance_type=’ml.c4.xlarge’,<br>   role=role,<br>   sagemaker_session=sess<br>)</pre><p name="2470" id="2470" class="graf graf--p graf-after--pre">Finally, I launch the training job.</p><pre name="ec76" id="ec76" class="graf graf--pre graf-after--p">estimator.fit({&#39;training&#39;: training_input_path})</pre><pre name="e746" id="e746" class="graf graf--pre graf-after--pre">2020-01-28 08:57:34 Starting - Starting the training job...<br>2020-01-28 08:57:36 Starting - Launching requested ML instances....</pre><pre name="96c3" id="96c3" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">&lt;output removed&gt;</em></pre><pre name="8ce9" id="8ce9" class="graf graf--pre graf-after--pre">Invoking script with the following command:<br><br>/opt/conda/bin/python karate_club_sagemaker.py --epochs 30 --node_count 34<br><br><em class="markup--em markup--pre-em">&lt;output removed&gt;</em></pre><pre name="b24a" id="b24a" class="graf graf--pre graf-after--pre">Epoch 0 | Loss: 0.6188<br>Epoch 1 | Loss: 0.4804<br>Epoch 2 | Loss: 0.3139<br>Epoch 3 | Loss: 0.3143<br>Epoch 4 | Loss: 0.3152<br>Epoch 5 | Loss: 0.3158<br>Epoch 6 | Loss: 0.3152<br>Epoch 7 | Loss: 0.3142<br>Epoch 8 | Loss: 0.3136<br>Epoch 9 | Loss: 0.3134<br>Epoch 10 | Loss: 0.3133<br>Epoch 11 | Loss: 0.3133<br>Epoch 12 | Loss: 0.3133<br>Epoch 13 | Loss: 0.3133<br>Epoch 14 | Loss: 0.3133<br>Epoch 15 | Loss: 0.3133<br>Epoch 16 | Loss: 0.3133<br>Epoch 17 | Loss: 0.3133<br>Epoch 18 | Loss: 0.3133<br>Epoch 19 | Loss: 0.3133<br>Epoch 20 | Loss: 0.3133<br>Epoch 21 | Loss: 0.3133<br>Epoch 22 | Loss: 0.3133<br>Epoch 23 | Loss: 0.3133<br>Epoch 24 | Loss: 0.3133<br>Epoch 25 | Loss: 0.3133<br>Epoch 26 | Loss: 0.3133<br>Epoch 27 | Loss: 0.3133<br>Epoch 28 | Loss: 0.3133<br>Epoch 29 | Loss: 0.3133</pre><pre name="56e7" id="56e7" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">&lt;output removed&gt;</em></pre><pre name="9744" id="9744" class="graf graf--pre graf-after--pre">2020-01-28 09:01:19 Uploading - Uploading generated training model<br>2020-01-28 09:01:19 Completed - Training job completed<br>Training seconds: 76<br>Billable seconds: 76</pre><p name="7b40" id="7b40" class="graf graf--p graf-after--pre">There you go! Once again, script mode makes it extremely simple to run existing code on SageMaker.</p><blockquote name="fc7c" id="fc7c" class="graf graf--blockquote graf-after--p">This feature is available for all built-in frameworks: if you’re curious about it, here’s a <a href="https://www.youtube.com/watch?v=x94hpOmKtXM" data-href="https://www.youtube.com/watch?v=x94hpOmKtXM" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">very detailed video example</a> with Keras.</blockquote><p name="85e9" id="85e9" class="graf graf--p graf-after--blockquote">I hope this post was useful. You can find the training script and the notebook on <a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/" data-href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Gitlab</a>.</p><div name="dae1" id="dae1" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.py" data-href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.py" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.py"><strong class="markup--strong markup--mixtapeEmbed-strong">dgl/01_karate_club/karate_club_sagemaker.py · master · Julien Simon / dlnotebooks</strong><br><em class="markup--em markup--mixtapeEmbed-em">Machine Learning &amp;amp; Deep Learning notebooks</em>gitlab.com</a><a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.py" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="2a2c4815256b9ac2855e0a2f3caf87f6" data-thumbnail-img-id="0*n4dODktXJ9mJbYTv" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*n4dODktXJ9mJbYTv);"></a></div><div name="f522" id="f522" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.ipynb" data-href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.ipynb" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.ipynb"><strong class="markup--strong markup--mixtapeEmbed-strong">dgl/01_karate_club/karate_club_sagemaker.ipynb · master · Julien Simon / dlnotebooks</strong><br><em class="markup--em markup--mixtapeEmbed-em">Machine Learning &amp;amp; Deep Learning notebooks</em>gitlab.com</a><a href="https://gitlab.com/juliensimon/dlnotebooks/blob/master/dgl/01_karate_club/karate_club_sagemaker.ipynb" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="3a656575b7488733df97b6906648af81" data-thumbnail-img-id="0*TVqjB13tVeWIEEMX" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*TVqjB13tVeWIEEMX);"></a></div><p name="ae3c" id="ae3c" class="graf graf--p graf-after--mixtapeEmbed graf--trailing">Happy to answer questions here, or on Twitter. Don’t forget to subscribe to my <a href="https://www.youtube.com/user/juliensimonfr?sub_confirmation=1" data-href="https://www.youtube.com/user/juliensimonfr?sub_confirmation=1" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">YouTube channel</a> for more content!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/54d318dfc814"><time class="dt-published" datetime="2020-01-28T09:50:06.442Z">January 28, 2020</time></a>.</p><p><a href="https://medium.com/@julsimon/deep-graph-library-part-2-training-on-amazon-sagemaker-54d318dfc814" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
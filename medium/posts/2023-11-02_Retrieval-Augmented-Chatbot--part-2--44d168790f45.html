<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Retrieval Augmented Chatbot, part 2!</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Retrieval Augmented Chatbot, part 2!</h1>
</header>
<section data-field="subtitle" class="p-summary">
We start by deploying Mistral 7B, a cutting-edge open-source LLM, onto a SageMaker endpoint. Following this, we work with the Reutersâ€¦
</section>
<section data-field="body" class="e-content">
<section name="a01b" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="46be" id="46be" class="graf graf--h3 graf--leading graf--title">Retrieval Augmented Chatbot, part 2! LangChain, Hugging Face, Amazon SageMaker, and Amazon OpenSearch Serverless ðŸ˜€</h3><p name="bec5" id="bec5" class="graf graf--p graf-after--h3">We start by deploying Mistral 7B, a cutting-edge open-source LLM, onto a SageMaker endpoint. Following this, we work with the Reuters dataset, a Hugging Face dataset comprising 20,000 news articles. We break down these articles into smaller sections and apply bge-small, a compact open-source embedding model, to them. Next, we proceed to index these sections into an Amazon OpenSearch Serverless vector index, which we then query through LangChain. Additionally, aside from the RAG demonstration, we delve into some vital yet often overlooked steps related to authentication and security for OpenSearch Serverless.</p><figure name="1d23" id="1d23" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/x5SYNpfK4H0?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><p name="2890" id="2890" class="graf graf--p graf-after--figure graf--trailing">Part 1: <a href="https://youtu.be/7kDaMz3Xnkw" data-href="https://youtu.be/7kDaMz3Xnkw" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://youtu.be/7kDaMz3Xnkw</a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/44d168790f45"><time class="dt-published" datetime="2023-11-02T18:38:05.618Z">November 2, 2023</time></a>.</p><p><a href="https://medium.com/@julsimon/retrieval-augmented-chatbot-part-2-44d168790f45" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

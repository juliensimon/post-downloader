<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Deep Dive on TensorFlow training with Amazon SageMaker and Amazon S3</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Deep Dive on TensorFlow training with Amazon SageMaker and Amazon S3</h1>
</header>
<section data-field="subtitle" class="p-summary">
This is a guest post by Chaim Rand, Machine Learning Algorithm Developer at Mobileye.
</section>
<section data-field="body" class="e-content">
<section name="5e87" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="d857" id="d857" class="graf graf--h3 graf--leading graf--title">Deep Dive on TensorFlow training with Amazon SageMaker and Amazon S3</h3><p name="e7f2" id="e7f2" class="graf graf--p graf-after--h3"><em class="markup--em markup--p-em">This is a guest post by </em><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Chaim Rand</em></strong><em class="markup--em markup--p-em">, </em><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Machine Learning Algorithm Developer</em></strong><em class="markup--em markup--p-em"> at </em><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Mobileye</em></strong><em class="markup--em markup--p-em">. You can also read </em><a href="https://medium.com/@julsimon/making-amazon-sagemaker-and-tensorflow-work-for-you-893365184233" data-href="https://medium.com/@julsimon/making-amazon-sagemaker-and-tensorflow-work-for-you-893365184233" class="markup--anchor markup--p-anchor" target="_blank"><em class="markup--em markup--p-em">part 1</em></a><em class="markup--em markup--p-em"> and </em><a href="https://towardsdatascience.com/tensorflow-performance-analysis-314b56dceb59" data-href="https://towardsdatascience.com/tensorflow-performance-analysis-314b56dceb59" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">part 3</em></a><em class="markup--em markup--p-em"> for more!</em></p><p name="0fe8" id="0fe8" class="graf graf--p graf-after--p">In a previous post, I told you the story of how my team at <a href="https://www.mobileye.com/" data-href="https://www.mobileye.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Mobileye</a> (officially known as Mobileye, an Intel company), transitioned to using the <a href="https://aws.amazon.com/sagemaker/" data-href="https://aws.amazon.com/sagemaker/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon SageMaker</strong></a> service to train our <a href="https://www.tensorflow.org/" data-href="https://www.tensorflow.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">TensorFlow</a> neural networks in the cloud. In particular, I told you about how one could use SageMaker <a href="https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/" data-href="https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Pipe Mode</strong></a> to stream training data directly from <a href="https://aws.amazon.com/s3/" data-href="https://aws.amazon.com/s3/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Amazon S3</a> storage to training instances, and how this leads to reductions in both training time and cost.</p><p name="a968" id="a968" class="graf graf--p graf-after--p">The easiest way to adopt Pipe Mode, is to use <a href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html" data-href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">PipeModeDataset</em></a>, a SageMaker implementation of the TensorFlow <a href="https://www.tensorflow.org/datasets" data-href="https://www.tensorflow.org/datasets" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">Dataset</em></a> interface, which hides all the low level pipe management from you. Using <em class="markup--em markup--p-em">PipeModeDataset</em> requires reformatting your training data into one of the supported file formats (text records, <em class="markup--em markup--p-em">TFRecord</em> and <em class="markup--em markup--p-em">Protobuf</em>). We chose the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" data-href="https://www.tensorflow.org/tutorials/load_data/tfrecord" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">TFRecord</em></a> format. See the <a href="https://medium.com/@julsimon/making-amazon-sagemaker-and-tensorflow-work-for-you-893365184233" data-href="https://medium.com/@julsimon/making-amazon-sagemaker-and-tensorflow-work-for-you-893365184233" class="markup--anchor markup--p-anchor" target="_blank">post</a> to learn more about how we converted our data, as well as additional challenges we faced and how we overcame them.</p><p name="54d4" id="54d4" class="graf graf--p graf-after--p">In this post I want to discuss some <strong class="markup--strong markup--p-strong">alternatives to using <em class="markup--em markup--p-em">PipeModeDataset</em></strong>. Of course, if you have a small dataset (e.g. a couple of hundred MB or a dataset that can easily fit on your training instance’s default EBS storage), you have the option of using <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html" data-href="https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">File Mode</strong></a>, which downloads all your data to your local training instance one time before starting training. But recall that we are training with mountains of data, often <strong class="markup--strong markup--p-strong">more than 100 TB of data</strong>!</p><h3 name="ef70" id="ef70" class="graf graf--h3 graf-after--p">Motivation</h3><p name="c547" id="c547" class="graf graf--p graf-after--h3">You are, no doubt, wondering why would anyone need to consider alternatives to <em class="markup--em markup--p-em">PipeModeDataset</em>? Allow me to present a few scenarios.</p><h4 name="5b41" id="5b41" class="graf graf--h4 graf-after--p">Increased control</h4><p name="dc03" id="dc03" class="graf graf--p graf-after--h4">As it stands today, when you choose to use Pipe Mode, you are handing over some of the control over your training flow to SageMaker. There may be situations when you want to have complete control. You may want to control precisely what files are being fed into your pipeline and in what order. You may want to control the mechanism being used to shuffle the files before each epoch. You might be facing some issues when using Pipe Mode, and want to use a method with greater visibility into the inner workings and better ability to debug. We will describe a way to do this using the built-in TensorFlow <a href="https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset" data-href="https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">TFRecordDataset</em></a>.</p><h4 name="078c" id="078c" class="graf graf--h4 graf-after--p">Dynamic boosting</h4><p name="ea87" id="ea87" class="graf graf--p graf-after--h4">In my previous post, I shared how we use boosting in our training to artificially increase the representation of certain subclasses of data (e.g. pink cars), and how we implemented this when training with Pipe Mode. Our solution was to configure our pipes with a SageMaker manifest file, pointing at <em class="markup--em markup--p-em">TFRecord</em> files for different classes, and weighted according to our desired boosting weights.</p><p name="04c1" id="04c1" class="graf graf--p graf-after--p">In some cases, this might not be sufficient.We may need to perform <strong class="markup--strong markup--p-strong">dynamic boosting</strong>, in which we continuously update the weights of each class during training. SageMaker does not (yet?) support modifying the manifest file during training. We will show two ways to implement this.</p><h4 name="8700" id="8700" class="graf graf--h4 graf-after--p">Complex data processing</h4><p name="4f3f" id="4f3f" class="graf graf--p graf-after--h4">Suppose that you need to apply heavy processing on the input data pipeline. This processing could of course be implemented using TensorFlow operations directly on the <em class="markup--em markup--p-em">TFRecord</em> files, but there is no arguing that many operations can be implemented much more easily in Python using <em class="markup--em markup--p-em">numpy</em>, <em class="markup--em markup--p-em">Scikit-learn</em>, <em class="markup--em markup--p-em">opencv</em> and other libraries.</p><p name="efb0" id="efb0" class="graf graf--p graf-after--p">Of course, you can create Python code using <em class="markup--em markup--p-em">tensorflow.py_func</em>, but this can easily become your bottleneck due to a combination of the Python Global Interpreter Lock (GIL) and the manner in which TensorFlow parallelizes the <em class="markup--em markup--p-em">py_func</em> in the <em class="markup--em markup--p-em">dataset</em> map call. If you have not heard of the python GIL, count your lucky blessings. Suffice to say, if you are trying to optimize your input data pipeline, you should try to avoid <em class="markup--em markup--p-em">py_func</em>.</p><p name="5bee" id="5bee" class="graf graf--p graf-after--p">It would be preferable to stream your data in a Python friendly format, such as <em class="markup--em markup--p-em">pickle</em> or <em class="markup--em markup--p-em">numpy</em> files, perform the heavy processing in Python (using multiple processes to bypass the GIL limitations), and only then hand it over to TensorFlow. We will show how to do this by reading directly from the SageMaker pipe and using the <em class="markup--em markup--p-em">tf.from_generator</em> dataset.</p><h4 name="421a" id="421a" class="graf graf--h4 graf-after--p">Using other storage services</h4><p name="eb66" id="eb66" class="graf graf--p graf-after--h4">There may be reasons (though I can’t think of any good ones) why converting your data to one of the required data formats may be infeasible. Or reasons why you require random access to any of your records at any point in time. You want to be able to train as if you had all of your data stored locally, in whatever format. Such scenarios beg the use of the <a href="https://aws.amazon.com/fsx/" data-href="https://aws.amazon.com/fsx/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Amazon FSx</a>, as we describe below.</p><h3 name="76f1" id="76f1" class="graf graf--h3 graf-after--p">Measuring Throughput</h3><p name="5ce6" id="5ce6" class="graf graf--p graf-after--h3">Surely, I have convinced you that a discussion on alternatives to Pipe Mode is warranted. Before we jump into some of the options at your disposal, a few words about throughput.</p><p name="3b76" id="3b76" class="graf graf--p graf-after--p">For us, one of the primary goals is to maximize the throughput of our training, that is, the number of training steps per second. Each of the options we will present have its pros and cons, but the key indicator by which we will compare them is how they impact throughput, i.e. at what rate can we pull the data from S3 and enter it into the training pipeline. If the input pipeline is not (and will not be) your bottleneck, or if you have all the time (and money) in the world to train, this might not be of concern to you. But it most certainly is to us.</p><p name="4cca" id="4cca" class="graf graf--p graf-after--p">One easy way to isolate and test the throughput over the network is to simply iterate over your dataset without actually performing any training, as shown in the example below (written in TensorFlow 1.14). You can compare this to your training throughput to assess whether your bottleneck is IO.</p><pre name="c07c" id="c07c" class="graf graf--pre graf-after--p">iter = ds.make_one_shot_iterator()<br>n = iter.get_next()<br>count = 0<br>begin = time.time()<br>with tf.Session() as sess:<br>    stime = time.time()<br>    while count &lt; 10000:<br>        sess.run(n)<br>        count = count + 1<br>        if count % 100 == 0:<br>            etime = time.time()<br>            print(“step: “+str(count)+” step/sec:  <br>                {}”.format(float(100) / (etime — stime)))<br>            stime = time.time()</pre><p name="ec24" id="ec24" class="graf graf--p graf-after--pre">Another consideration should be the network bandwidth of your training instance. AWS has published a <a href="https://aws.amazon.com/sagemaker/pricing/instance-types/" data-href="https://aws.amazon.com/sagemaker/pricing/instance-types/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">table</a> of the maximum expected network performance per instance type. You can use this table to assess whether you are getting the most bang for your buck. For example, if you are streaming 10 gigabits of data on an <em class="markup--em markup--p-em">ml.p3.8xlarge</em>, you will know that you can’t improve on that.</p><p name="7a26" id="7a26" class="graf graf--p graf-after--p">However, there are some additional things to keep in mind. In particular, just because your instance has a certain bandwidth does not mean that you will be utilizing the full bandwidth when streaming from S3, EC2, etc. This might depend on a host of other things, such as the network bandwidth of the source, whether <a href="https://aws.amazon.com/blogs/aws/elastic-network-adapter-high-performance-network-interface-for-amazon-ec2/" data-href="https://aws.amazon.com/blogs/aws/elastic-network-adapter-high-performance-network-interface-for-amazon-ec2/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Elastic Network Adapter</a> (ENA) is enabled, and to what degree the streaming functionality has been optimized (using multi-part downloading and other black magic).</p><p name="99c0" id="99c0" class="graf graf--p graf-after--p">The advantage of Pipe Mode is that you don’t need to worry about all this. You can sleep easy knowing that Amazon SageMaker has highly optimized Pipe Mode and <em class="markup--em markup--p-em">PipeModeDataset</em>, and that you are most likely utilizing your bandwidth to its maximum. But, as you have already been convinced, there are situations where other options should be considered. We will present four alternatives:</p><ul class="postList"><li name="24dc" id="24dc" class="graf graf--li graf-after--p"><em class="markup--em markup--li-em">TFRecordDatasets</em> pointing directly to files in S3,</li><li name="9312" id="9312" class="graf graf--li graf-after--li">Parsing the raw SageMaker input pipe,</li><li name="c5ad" id="c5ad" class="graf graf--li graf-after--li">Downloading data files directly from <a href="https://aws.amazon.com/fsx/" data-href="https://aws.amazon.com/fsx/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Amazon FSx for Lustre</a>,</li><li name="e702" id="e702" class="graf graf--li graf-after--li">Downloading data files directly from S3.</li></ul><h3 name="9c84" id="9c84" class="graf graf--h3 graf-after--li">TFRecordDataset</h3><p name="e793" id="e793" class="graf graf--p graf-after--h3"><a href="https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset" data-href="https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><em class="markup--em markup--p-em">TFRecordDataset</em></a> is a dataset implemented by Tensorflow that takes a list or a dataset of <em class="markup--em markup--p-em">TFRecord</em> file paths as input, and iterates over the <em class="markup--em markup--p-em">TFRecords</em> in each of the files.</p><p name="822e" id="822e" class="graf graf--p graf-after--p">The good news is that the <strong class="markup--strong markup--p-strong">files paths can be S3 paths</strong>. Furthermore, the <em class="markup--em markup--p-em">TFRecordDataset</em> constructor has two control parameters, <em class="markup--em markup--p-em">buffer_size</em> and <em class="markup--em markup--p-em">num_parallel_reads</em> that can be used to optimize the IO throughput when reading from a remote location. Here is a simple example of how one can initialize a <em class="markup--em markup--p-em">TFRecordDataset</em> with the list of files from a SageMaker manifest file.</p><pre name="ad1f" id="ad1f" class="graf graf--pre graf-after--p">def get_list_from_manifest(manifest_file):<br>    with open(manifest_file) as f:<br>        manifest = json.load(f)<br>        prefix = manifest[0][‘prefix’]<br>        return [path_join(prefix, tf) for tf in manifest[1:]]</pre><pre name="b60f" id="b60f" class="graf graf--pre graf-after--pre">tf_record_filepaths = get_list_from_manifest(manifest_file)</pre><pre name="1b67" id="1b67" class="graf graf--pre graf-after--pre">ds = tf.data.TFRecordDataset(tf_record_filepaths,  <br>                             num_parallel_reads=10,    <br>                             buffer_size=100000000)</pre><p name="4e7f" id="4e7f" class="graf graf--p graf-after--pre">Note the settings for <em class="markup--em markup--p-em">buffer_size</em> and <em class="markup--em markup--p-em">num_parallel_reads</em>. With this example, <strong class="markup--strong markup--p-strong">we were able to reach comparable throughput performance to that of <em class="markup--em markup--p-em">PipeModeDatase</em></strong><em class="markup--em markup--p-em">t</em> on an <em class="markup--em markup--p-em">ml.p3.8xlarge</em> instance (see evaluation below.)</p><p name="2301" id="2301" class="graf graf--p graf-after--p">There are a number of significant advantages to this method compared to <em class="markup--em markup--p-em">PipeModeDataset.</em></p><h4 name="2457" id="2457" class="graf graf--h4 graf-after--p">Greater control</h4><p name="ad4b" id="ad4b" class="graf graf--p graf-after--h4">As mentioned above, <em class="markup--em markup--p-em">PipeModeDataset</em> is a bit of a black box. You provide a list of files, and rely on SageMaker to shuffle and stream these with little visibility (to date) into the internal workings, including what file is being streamed at any given moment. You are not able to change the list of files during training, and you cannot implement dynamic boosting.</p><p name="32b1" id="32b1" class="graf graf--p graf-after--p">With <em class="markup--em markup--p-em">PipeModeDataset</em>, you can have greater control and greater visibility. This is demonstrated in the following pseudo-example showing how to implement dynamic boosting with two classes, while implementing our own shuffling and printing each file being streamed. This can be further optimized, and extended to a greater number of classes.</p><pre name="747c" id="747c" class="graf graf--pre graf-after--p">import random, numpy as np, tensorflow as tf</pre><pre name="4131" id="4131" class="graf graf--pre graf-after--pre">class MyIter(object):<br>    def __init__(self,class1_list, class2_list)<br>        self.class1_list = class1_list<br>        self.class1_list_len = len(class1_list)<br>        self.class1_index = 0<br>        self.class2_list = class2_list<br>        self.class2_list_len = len(class2_list)<br>        self.class2_index = 0<br>        self.boost_weight = 0.5<br>        self.cont = True</pre><pre name="b550" id="b550" class="graf graf--pre graf-after--pre"># this can be used to update weight mid-training<br>def update_boost_weight(self, weight):<br>    self.boost_weight = weight</pre><pre name="eb6b" id="eb6b" class="graf graf--pre graf-after--pre">def hault(self):<br>    self.cont = False</pre><pre name="3aed" id="3aed" class="graf graf--pre graf-after--pre">def from_class1(self):<br>    if self.class1_index == 0:<br>        random.shuffle(self.class1_list)<br>    file_path = self.class1_list[self.class1_index]<br>    self.class1_index = (self.class1_index+1)%self.class1_list_len<br>    return file_path</pre><pre name="b68c" id="b68c" class="graf graf--pre graf-after--pre">def from_class2(self):<br>    if self.class2_index == 0:<br>    random.shuffle(self.class2_list)<br>    file_path = self.class2_list[self.class2_index]<br>    self.class2_index = (self.class2_index+1)%self.class2_list_len<br>    return file_path</pre><pre name="0586" id="0586" class="graf graf--pre graf-after--pre">def generator(self):<br>    while self.cont:<br>        class_type = np.random.choice(2, 1, <br>            p=[self.boost_weight,1-self.boost_weight])[0]<br>        next_file = self.from_class1() if class_type == 1 <br>                   else self.from_class2()<br>        print(“feeding file “+next_file)<br>        yield next_file</pre><pre name="6b84" id="6b84" class="graf graf--pre graf-after--pre">myiter = MyIter(list1,list2)<br>filepaths = tf.data.Dataset.from_generator(<br>               myiter.generator,<br>               output_types=tf.string,<br>               output_shapes=())</pre><pre name="5268" id="5268" class="graf graf--pre graf-after--pre">ds = tf.data.TFRecordDataset(<br>               filepaths, <br>               num_parallel_reads=10, <br>               buffer_size=100000000)</pre><h4 name="5d30" id="5d30" class="graf graf--h4 graf-after--pre">Debugging</h4><p name="ec3d" id="ec3d" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">TFRecordDataset</em> offers advantages over <em class="markup--em markup--p-em">PipeModeDataset</em> when it comes to debugging. Other than the obvious advantages of debugging when you have greater visibility (e.g. identifying a corrupted <em class="markup--em markup--p-em">TFRecord</em> file), <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">TFRecordDataset</em> also supports local mode </strong>unlike <em class="markup--em markup--p-em">PipeModeDataset</em>. This means that you can test your full pipeline, including the input pipeline, locally before uploading to a SageMaker instance.</p><h4 name="7578" id="7578" class="graf graf--h4 graf-after--p">Channel limit</h4><p name="e92e" id="e92e" class="graf graf--p graf-after--h4">Contrary to SageMaker Pipe Mode which has a 20 channels per device limit, there is no (documented) limitation to the number of <em class="markup--em markup--p-em">TFRecordDataset</em> you can create. Of course, each dataset requires system resources, so eventually, you will inevitably run up on some limit. To be honest, I did not check whether this is greater than 20, it probably depends on the system you are running on.</p><h4 name="29b3" id="29b3" class="graf graf--h4 graf-after--p"><em class="markup--em markup--h4-em">TFRecordDataset or PipeModeDataset?</em></h4><p name="9ada" id="9ada" class="graf graf--p graf-after--h4">As discussed,<em class="markup--em markup--p-em"> TFRecordDataset</em> is very flexible. Still<em class="markup--em markup--p-em">, PipeModeDataset</em> has a number of advantages<em class="markup--em markup--p-em">.</em></p><ol class="postList"><li name="e1f2" id="e1f2" class="graf graf--li graf-after--p">When you use <em class="markup--em markup--li-em">TFRecordDataset,</em> you are inevitably using system resources (memory and CPU) to download and buffer your data. If you are CPU or memory bound, that will hurt. When you use Pipe Mode, Sagemaker provides these resources for this.</li><li name="54bb" id="54bb" class="graf graf--li graf-after--li">Reaching comparable throughput performance with <em class="markup--em markup--li-em">TFRecordDataset</em> to that of pipe mode is no piece of cake. You will need to find the optimal control settings (e.g. <em class="markup--em markup--li-em">buffer_size</em> and <em class="markup--em markup--li-em">num_parallel_reads</em>) and even then there are no guarantees, as we explained above.</li><li name="96be" id="96be" class="graf graf--li graf-after--li"><em class="markup--em markup--li-em">PipeModeDataset</em> includes an API for distributing (sharding) the data across multiple instances. If you use <em class="markup--em markup--li-em">TFRecordDataset</em> you would need to program this explicitly.</li></ol><h3 name="cc6e" id="cc6e" class="graf graf--h3 graf-after--li">Parsing the Raw Pipe</h3><p name="bfeb" id="bfeb" class="graf graf--p graf-after--h3">While <em class="markup--em markup--p-em">TFRecordDataset</em> supports a limited set of formats, you can stream anything you want over SageMaker pipes. For example, you could stream Python pickle files. Now, you probably won’t want to stream small pickle files, as this will have a negative impact on the pipe throughput, but rather you will want to concatenate many pickle files together into files, roughly of size 100MB. You can adopt the format of <em class="markup--em markup--p-em">TFRecord</em> files which is a concatenation of records of the format:</p><ul class="postList"><li name="fbbd" id="fbbd" class="graf graf--li graf-after--p">Length — 8 bytes</li><li name="eac3" id="eac3" class="graf graf--li graf-after--li">Length CRC — 4 bytes</li><li name="1c94" id="1c94" class="graf graf--li graf-after--li">Data — ‘Length’ bytes</li><li name="0633" id="0633" class="graf graf--li graf-after--li">Data CRC — 4 bytes</li></ul><p name="889a" id="889a" class="graf graf--p graf-after--li">In the example below, we are using this technique to create a dataset from a generator that manually parses our <em class="markup--em markup--p-em">TFRecord</em> files. This code snippet can be easily modified to parse files with concatenated <em class="markup--em markup--p-em">pickle</em> files, which you can follow up with your heavy python processing (using multiprocess to work around the GIL).</p><pre name="f66a" id="f66a" class="graf graf--pre graf-after--p">def get_pipe_generator(channel_name, num_epochs=1):<br>    import struct<br>    def generator():<br>        for epoch in range(num_epochs):<br>            fifo_path = ‘{0}/{1}_{2}’.format(data_dir, <br>                                            channel_name, epoch)</pre><pre name="9f00" id="9f00" class="graf graf--pre graf-after--pre">with open(fifo_path, ‘rb’, buffering=0) as fifo:<br>    cont = True<br>    while cont:<br>        try:<br>            recordLen = fifo.read(8)<br>            recordLen = struct.unpack(‘Q’, recordLen)[0]<br>            # TODO: don’t be lazy!! Check the crc<br>            crcCheck = struct.unpack(‘I’, fifo.read(4))[0]<br>            # TODO: verify that you read recordLen bytes<br>            rec = fifo.read(recordLen)<br>            # TODO: don’t be lazy!! Check the crc<br>            crcCheck = struct.unpack(‘I’, fifo.read(4))[0]<br>            yield rec<br>       except:<br>            cont = False<br>    return generator</pre><pre name="4dcb" id="4dcb" class="graf graf--pre graf-after--pre">ds = tf.data.Dataset.from_generator(<br>         get_pipe_generator(‘train’),<br>         output_types=tf.string,<br>         output_shapes=())</pre><p name="c63f" id="c63f" class="graf graf--p graf-after--pre">Working with raw pipes also offers you added flexibility. For example, suppose your data is divided into two separate classes streaming over two separate pipes. You could control the rate at which you sample data from each pipe. You can probably see where I am going with this… <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">dynamic boosting!!</em></strong></p><h3 name="bb8d" id="bb8d" class="graf graf--h3 graf-after--p">Downloading and Parsing Data Files</h3><p name="184e" id="184e" class="graf graf--p graf-after--h3">If you want both the visibility granted by working directly with S3 (as with the <em class="markup--em markup--p-em">TFRecordDataset</em> option), as well as the flexibility of working with a Python format such as <em class="markup--em markup--p-em">pickle</em> files, you will probably want to download and parse your data files on your own.</p><p name="3ff7" id="3ff7" class="graf graf--p graf-after--p">Here, we show an example in which we use multiple parallel threads to download and parse our <em class="markup--em markup--p-em">TFRecord</em> files. The records are fed into a shared queue, which can be fed into data processor threads, or directly into a dataset (using <em class="markup--em markup--p-em">tf.data.Dataset.from_generator</em>). Once again, this can easily be modified to work with other formats.</p><pre name="afe5" id="afe5" class="graf graf--pre graf-after--p">import struct, boto3, io<br>from threading import Thread<br>from queue import Queue as Q</pre><pre name="81d3" id="81d3" class="graf graf--pre graf-after--pre">def file_parser(index, file_list, batch_queue):<br>    session = boto3.session.Session()<br>    s3 = session.resource(‘s3’)<br>    for s3_path in file_list:<br>        bucket, key = s3_path.replace(‘s3://’,’’).split(‘/’, 1)<br>        tc = boto3.s3.transfer.TransferConfig(<br>            max_concurrency=10,<br>            multipart_chunksize=8388608, <br>            num_download_attempts=5,<br>            max_io_queue=100, <br>            io_chunksize=262144)<br>    ioStream = io.BytesIO()<br>    s3.meta.client.download_fileobj(bucket, key, ioStream, Config=tc)<br>    ioStream.seek(0)<br>    recordLen = ioStream.read(8)</pre><pre name="ade7" id="ade7" class="graf graf--pre graf-after--pre">    while recordLen:<br>        recordLen = struct.unpack(‘Q’, recordLen)[0]<br>        # TODO: don’t be lazy!! Check the crc<br>        crcCheck = struct.unpack(‘I’, fifo.read(4))[0]<br>        # TODO: verify that you read recordLen bytes<br>        rec = fifo.read(recordLen)<br>        # TODO: don’t be lazy!! Check the crc<br>        crcCheck = struct.unpack(‘I’, fifo.read(4))[0]<br>        batch_queue.put(rec,block=True)<br>        recordLen = ioStream.read(8)<br>        <br>q = Q(maxsize=10)<br>num_threads = 40</pre><pre name="bea2" id="bea2" class="graf graf--pre graf-after--pre">for i in range(num_threads):<br>    w = Thread(target=file_parser, args=[files[i::num_threads], q])<br>    w.start()</pre><p name="4c9a" id="4c9a" class="graf graf--p graf-after--pre">The implementation above is somewhat naive. Reaching comparable throughput to that of <em class="markup--em markup--p-em">PipeModeDataset </em>will likely be very challenging. There are a number of controls you can use for tuning, including <em class="markup--em markup--p-em">num_threads, max_concurrency, multipart_chunksize,</em> and more.</p><h3 name="9aa8" id="9aa8" class="graf graf--h3 graf-after--p">Using Amazon FSx for Lustre</h3><p name="c6d9" id="c6d9" class="graf graf--p graf-after--h3">Training on SageMaker using <a href="https://aws.amazon.com/fsx/" data-href="https://aws.amazon.com/fsx/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Amazon FSx</a> is a good solution for people who want to have traditional, file-system style access to their data, but cannot, or don’t want to, download their datasets to local EBS storage. Using FSx requires appropriate configuration as described <a href="https://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/" data-href="https://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><p name="fc02" id="fc02" class="graf graf--p graf-after--p">When you choose the storage capacity of your file system, make note of the throughput capacity, as this will impact the speed at which you will be able to access your data. Typically, the larger the storage capacity, the larger the throughput capacity. Unfortunately, the larger the storage capacity, the higher the cost of FSx. One advantage, however, is that the same file system can be used across multiple SageMaker jobs, which can reduce the cost per-session if you have many training sessions that access the same data.</p><p name="69d7" id="69d7" class="graf graf--p graf-after--p">One thing to keep in mind is that according to the <a href="https://aws.amazon.com/about-aws/whats-new/2019/08/amazon-sagemaker-works-with-amazon-fsx-lustre-amazon-efs-model-training/" data-href="https://aws.amazon.com/about-aws/whats-new/2019/08/amazon-sagemaker-works-with-amazon-fsx-lustre-amazon-efs-model-training/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">documentation</a>, the files are only copied from S3 to FSx the first time they are accessed. This means that the throughput measured on your first epoch might be measurably lower that the throughput on subsequent epochs. Also, there is an option to <a href="https://docs.aws.amazon.com/fsx/latest/LustreGuide/import-data-repository.html" data-href="https://docs.aws.amazon.com/fsx/latest/LustreGuide/import-data-repository.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">preload</strong></a> data.</p><p name="a024" id="a024" class="graf graf--p graf-after--p">Bottom line, whether or not FSx is the right solution for you depends on a number of factors, including dataset size, FSx cost, the number of training sessions, and how badly you need file-system style access to your data.</p><h3 name="1e8e" id="1e8e" class="graf graf--h3 graf-after--p">Evaluation</h3><p name="e9d0" id="e9d0" class="graf graf--p graf-after--h3">In the chart below we compare the throughput, measured in batches per second, for five different methods of pulling the training data from S3:</p><p name="a965" id="a965" class="graf graf--p graf-after--p">1. Using <em class="markup--em markup--p-em">PipeModeDataset</em> (‘<em class="markup--em markup--p-em">pipe</em>’)</p><p name="de9a" id="de9a" class="graf graf--p graf-after--p">2. Using <em class="markup--em markup--p-em">TFRecordDataset</em> pointing to file objects in S3 (‘<em class="markup--em markup--p-em">tfr</em>’)</p><p name="9301" id="9301" class="graf graf--p graf-after--p">3. Reading and parsing the <em class="markup--em markup--p-em">TFRecord</em> files from raw SageMaker pipe, and wrapping these with <em class="markup--em markup--p-em">tf.data.Dataset.from_generator</em> (‘<em class="markup--em markup--p-em">pipe gen</em>’)</p><p name="7a00" id="7a00" class="graf graf--p graf-after--p">4. Downloading the <em class="markup--em markup--p-em">TFRecord</em> files directly from S3, reading and parsing the them and wrapping them with <em class="markup--em markup--p-em">tf.data.Dataset.from_generator</em> (‘<em class="markup--em markup--p-em">file gen</em>’)</p><p name="39dc" id="39dc" class="graf graf--p graf-after--p">5. Using <em class="markup--em markup--p-em">TFRecordDataset</em> pointing to the files in FSx (‘<em class="markup--em markup--p-em">fsx</em>’). <strong class="markup--strong markup--p-strong">Please note that preloading was not used in this case.</strong></p><p name="80f7" id="80f7" class="graf graf--p graf-after--p">All the trials were run on <em class="markup--em markup--p-em">ml.p3.8xlarge</em> (10 Gigabit per second network performance).</p><figure name="3b47" id="3b47" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*tituKZaabI7W91kMnbRZ5Q.png" data-width="760" data-height="381" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*tituKZaabI7W91kMnbRZ5Q.png"></figure><p name="3480" id="3480" class="graf graf--p graf-after--figure">While the absolute values of the throughput should not mean anything to you (as they are dependent on our own data record size, batch size, etc.), the relative values clearly show <strong class="markup--strong markup--p-strong">the throughput of the <em class="markup--em markup--p-em">tfr</em>, and <em class="markup--em markup--p-em">pipe gen</em> options to be comparable to <em class="markup--em markup--p-em">PipeModeDataset</em></strong>. Note that the performance of the <em class="markup--em markup--p-em">TFRecordDataset</em> is more choppy than the other options. If the throughput of the end to end training pipeline is sensitive to such choppiness, this may be something to consider.</p><p name="df86" id="df86" class="graf graf--p graf-after--p">The <em class="markup--em markup--p-em">file gen</em> trial timed out after only 7500 iterations… but I think you get the gist… Recall that this was a naive implementation and that it can most certainly be improved (as shown by the performance of <em class="markup--em markup--p-em">TFRecordDataset</em>).</p><p name="def9" id="def9" class="graf graf--p graf-after--p">The <em class="markup--em markup--p-em">fsx</em> throughput starts high, and then drops suddenly before timing out. The reason for this is that the while for the first 9600 iterations, we are accessing files that have already been copied to the file system, we then begin to read files that are being accessed for the first time. This means that FSx is only first copying them from S3. Remember, <strong class="markup--strong markup--p-strong">this latency can be avoided by preloading all of your data</strong>.</p><h3 name="6498" id="6498" class="graf graf--h3 graf-after--p">Summary</h3><p name="d446" id="d446" class="graf graf--p graf-after--h3 graf--trailing">Amazon Sagemaker Pipe Mode is a great default choice. It is relatively easy to set up, maximizes network bandwidth utilization and hides all the nitty gritty. But, for those sticky situations such as those mentioned above, it’s good to know that there are other options, isn’t it?</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/12038828075c"><time class="dt-published" datetime="2020-06-22T12:40:48.534Z">June 22, 2020</time></a>.</p><p><a href="https://medium.com/@julsimon/deep-dive-on-tensorflow-training-with-amazon-sagemaker-and-amazon-s3-12038828075c" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Videoâ€Šâ€”â€ŠDeep Dive: Quantizing Large Language Models</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Videoâ€Šâ€”â€ŠDeep Dive: Quantizing Large Language Models</h1>
</header>
<section data-field="subtitle" class="p-summary">
Quantization is an excellent technique to compress Large Language Models (LLM) and accelerate their inference.
</section>
<section data-field="body" class="e-content">
<section name="88cd" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="b01d" id="b01d" class="graf graf--h3 graf--leading graf--title">Videoâ€Šâ€”â€ŠDeep Dive: Quantizing Large LanguageÂ Models</h3><p name="e2ba" id="e2ba" class="graf graf--p graf-after--h3">Quantization is an excellent technique to compress Large Language Models (LLM) and accelerate their inference.</p><p name="6068" id="6068" class="graf graf--p graf-after--p">In this 2-part video, we discuss model quantization, first introducing what it is, and how to get an intuition of rescaling and the problems it creates. Then we introduce the different types of quantization: dynamic post-training quantization, static post-training quantization, and quantization-aware training. Finally, we look at and compare quantization techniques: PyTorch, ZeroQuant, bitsandbytes, SmoothQuant, GPTQ, AWQ, HQQ, and the Hugging Face Optimum Intel library ðŸ˜Ž</p><figure name="4738" id="4738" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*HfIZitpG6n_RpXeDw3AOsA.png" data-width="1372" data-height="771" src="https://cdn-images-1.medium.com/max/800/1*HfIZitpG6n_RpXeDw3AOsA.png"></figure><p name="92da" id="92da" class="graf graf--p graf-after--figure">Part 1:</p><figure name="cb3b" id="cb3b" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/kw7S-3s50uk?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><p name="e35f" id="e35f" class="graf graf--p graf-after--figure">Part 2:</p><figure name="1cf4" id="1cf4" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/fXBBwCIA0Ds?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/4eb414f9be76"><time class="dt-published" datetime="2024-03-06T18:52:43.703Z">March 6, 2024</time></a>.</p><p><a href="https://medium.com/@julsimon/video-deep-dive-quantizing-large-language-models-4eb414f9be76" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
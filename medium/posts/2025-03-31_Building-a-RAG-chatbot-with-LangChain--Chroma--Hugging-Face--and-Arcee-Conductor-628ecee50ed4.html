<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Building a RAG chatbot with LangChain, Chroma, Hugging Face, and Arcee Conductor</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Building a RAG chatbot with LangChain, Chroma, Hugging Face, and Arcee Conductor</h1>
</header>
<section data-field="subtitle" class="p-summary">
Retrieval-Augmented Generation (RAG)
</section>
<section data-field="body" class="e-content">
<section name="eb69" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7f6c" id="7f6c" class="graf graf--h3 graf--leading graf--title">Building a RAG chatbot with LangChain, Chroma, Hugging Face, and Arcee Conductor</h3><figure name="8e5b" id="8e5b" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*z0elNdM5LdxrT5eltjQVGw.png" data-width="1912" data-height="1074" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*z0elNdM5LdxrT5eltjQVGw.png"></figure><h3 name="5cb1" id="5cb1" class="graf graf--h3 graf-after--figure">Retrieval-Augmented Generation (RAG)</h3><p name="2ba5" id="2ba5" class="graf graf--p graf-after--h3">RAG is a hybrid approach that enhances the capabilities of generative models by incorporating a retrieval mechanism. This mechanism allows the model to access and utilize context from a knowledge base, such as a collection of PDF documents. By retrieving relevant information and providing it to the generative model, RAG can produce more accurate and contextually appropriate responses.</p><h3 name="9462" id="9462" class="graf graf--h3 graf-after--p">Arcee Conductor</h3><p name="45fa" id="45fa" class="graf graf--p graf-after--h3">One key challenge in building a chatbot is selecting the right model for each query. Different queries may require different levels of complexity and computational power. Arcee Conductor is a model selection service that automatically routes queries to the most suitable model based on the task requirements. This not only improves the quality of the responses but also optimizes the cost of inference.</p><figure name="a0ff" id="a0ff" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/GSR8Be8TvZw?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><h3 name="4b7e" id="4b7e" class="graf graf--h3 graf-after--figure">Building the RAG Chatbot</h3><h3 name="9ed8" id="9ed8" class="graf graf--h3 graf-after--h3">Setting Up the Environment</h3><p name="f5af" id="f5af" class="graf graf--p graf-after--h3">To get started, you’ll need to set up your development environment. The project uses Python and several open-source libraries, including LangChain, Chroma, and Gradio. It’s recommended to use a virtual environment to manage dependencies and avoid conflicts with other projects. The necessary dependencies are listed in the project’s GitLab repository, and you can install them using pip.</p><h3 name="7970" id="7970" class="graf graf--h3 graf-after--p">Data Preparation</h3><p name="3195" id="3195" class="graf graf--p graf-after--h3">The first step in building the RAG chatbot is to prepare the data. In this case, the data consists of PDF documents, which can be research articles or any other PDF files of your choice. These documents are stored in a folder, and the chatbot will process them to create a vector store. The vector store is a database of embeddings that represent the content of the documents, allowing the model to retrieve relevant information efficiently.</p><h3 name="bc84" id="bc84" class="graf graf--h3 graf-after--p">Embedding and Vector Search</h3><p name="5c61" id="5c61" class="graf graf--p graf-after--h3">To enable the RAG chatbot to understand and retrieve information from the PDF documents, we use a Hugging Face model for embedding. This model converts the text from the documents into dense vector representations, which are then stored in the vector store. When a query is made, the chatbot retrieves the most relevant document chunks based on these embeddings.</p><h3 name="c786" id="c786" class="graf graf--h3 graf-after--p">Orchestration with LangChain</h3><p name="a745" id="a745" class="graf graf--p graf-after--h3">LangChain is a powerful framework for building AI applications. It provides a high-level API for orchestrating the various components of the RAG chatbot, including the embedding model, the vector store, and the generative model. By using LangChain, we can easily create a pipeline that processes the query, retrieves relevant context, and generates a response.</p><h3 name="21e9" id="21e9" class="graf graf--h3 graf-after--p">User Interface with Gradio</h3><p name="393e" id="393e" class="graf graf--p graf-after--h3">Gradio is a Python library that simplifies the process of building user interfaces for machine learning models. In this project, we use Gradio to create a web-based interface for the RAG chatbot. The interface allows users to input queries, toggle the RAG functionality, and view the generated responses. Additionally, it displays the retrieved context and source documents, providing transparency and trust in the AI’s answers.</p><h3 name="f3e6" id="f3e6" class="graf graf--h3 graf-after--p">Deploying to Hugging Face</h3><p name="7232" id="7232" class="graf graf--p graf-after--h3">Once the chatbot is built and tested locally, it can be deployed as a Hugging Face Space. Hugging Face Spaces provide a platform for hosting and sharing machine learning applications. By deploying the chatbot to a Hugging Face Space, you can make it accessible to a wider audience. The deployment process is straightforward, and the project’s README file includes detailed instructions.</p><h3 name="5960" id="5960" class="graf graf--h3 graf-after--p">Demonstration and Results</h3><p name="b82f" id="b82f" class="graf graf--p graf-after--h3">To demonstrate the effectiveness of the RAG chatbot, we tested it with several queries. When the RAG functionality is disabled, the chatbot relies solely on the generative model, which often produces generic or incorrect responses. However, when RAG is enabled, the chatbot retrieves relevant context from the PDF documents and generates much more accurate and contextually appropriate answers.</p><p name="b679" id="b679" class="graf graf--p graf-after--p">For example, when asked about “Arcee Fusion,” a specific model merging technique, the vanilla model produced a vague and incorrect response. In contrast, the RAG-powered chatbot provided a detailed and accurate explanation, citing the main benefits and performance aspects of Arcee Fusion.</p><p name="93d7" id="93d7" class="graf graf--p graf-after--p">Similarly, when asked about the “main innovation of DELLA merging,” the vanilla model produced an out-of-domain response, while the RAG chatbot accurately described the technique and its significance.</p><h3 name="c063" id="c063" class="graf graf--h3 graf-after--p">Conclusion</h3><p name="d0b4" id="d0b4" class="graf graf--p graf-after--h3">Building a RAG chatbot that can query PDF documents opens up new possibilities for accessing and understanding complex, domain-specific information. By combining the strengths of retrieval and generative models, and leveraging a model selection service like Arcee Conductor, we can create chatbots that provide accurate, contextually relevant answers while optimizing performance and cost.</p><p name="0706" id="0706" class="graf graf--p graf-after--p">If you’re interested in exploring this technology further, we encourage you to:</p><blockquote name="4627" id="4627" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">• </em><a href="https://www.arcee.ai/book-a-demo" data-href="https://www.arcee.ai/book-a-demo" class="markup--anchor markup--blockquote-anchor" rel="noopener noreferrer nofollow noopener" target="_blank"><em class="markup--em markup--blockquote-em">Book a demo</em></a><em class="markup--em markup--blockquote-em"> to see Arcee Conductor in action.</em></blockquote><blockquote name="2e33" id="2e33" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">• Watch more videos on our </em><a href="https://www.youtube.com/@ArceeAI" data-href="https://www.youtube.com/@ArceeAI" class="markup--anchor markup--blockquote-anchor" rel="noopener noreferrer nofollow noopener" target="_blank"><em class="markup--em markup--blockquote-em">YouTube channel</em></a><em class="markup--em markup--blockquote-em"> for in-depth tutorials and insights.</em></blockquote><blockquote name="67cb" id="67cb" class="graf graf--blockquote graf-after--blockquote"><em class="markup--em markup--blockquote-em">• Follow Arcee AI on </em><a href="https://www.linkedin.com/company/arcee-ai" data-href="https://www.linkedin.com/company/arcee-ai" class="markup--anchor markup--blockquote-anchor" rel="noopener noreferrer nofollow noopener" target="_blank"><em class="markup--em markup--blockquote-em">LinkedIn</em></a><em class="markup--em markup--blockquote-em"> to stay updated on the latest developments and news.</em></blockquote><p name="9254" id="9254" class="graf graf--p graf-after--blockquote graf--trailing">We’re excited about the potential of RAG and look forward to seeing the innovative applications you will build with these tools. Keep rocking!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/628ecee50ed4"><time class="dt-published" datetime="2025-03-31T12:24:50.470Z">March 31, 2025</time></a>.</p><p><a href="https://medium.com/@julsimon/building-a-rag-chatbot-with-langchain-chroma-hugging-face-and-arcee-conductor-628ecee50ed4" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

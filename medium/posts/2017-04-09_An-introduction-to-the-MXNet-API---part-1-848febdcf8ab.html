<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>An introduction to the MXNet API — part 1</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">An introduction to the MXNet API — part 1</h1>
</header>
<section data-field="subtitle" class="p-summary">
Update August 1st, 2017: 
this series is now available in Japanese, Chinese and Korean.
</section>
<section data-field="body" class="e-content">
<section name="c385" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="9c85" id="9c85" class="graf graf--h3 graf--leading graf--title">An introduction to the MXNet API — part 1</h3><figure name="94ac" id="94ac" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*H0-jFUWPK6TQIXeNqTnaUg.png" data-width="638" data-height="359" src="https://cdn-images-1.medium.com/max/800/1*H0-jFUWPK6TQIXeNqTnaUg.png"><figcaption class="imageCaption">MXNet Tutorial</figcaption></figure><blockquote name="c166" id="c166" class="graf graf--blockquote graf-after--figure">Update August 1st, 2017: <br>this series is now available in <a href="http://postd.cc/an-introduction-to-the-mxnet-api-part-1/" data-href="http://postd.cc/an-introduction-to-the-mxnet-api-part-1/" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">Japanese</a>, <a href="http://www.infoq.com/cn/articles/an-introduction-to-the-mxnet-api-part01" data-href="http://www.infoq.com/cn/articles/an-introduction-to-the-mxnet-api-part01" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">Chinese</a> and <a href="http://blog.creation.net/mxnet-part-1-ndarrays-api" data-href="http://blog.creation.net/mxnet-part-1-ndarrays-api" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">Korean</a>.</blockquote><p name="e6a3" id="e6a3" class="graf graf--p graf-after--blockquote">In this series, I will try to give you an overview of the <a href="http://mxnet.io/" data-href="http://mxnet.io/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MXnet</a> Deep Learning library: we’ll look at its main features and its Python API (which I suspect will be the #1 choice). Later on, we’ll explore some of the MXNet tutorials and notebooks available online, and we’ll hopefully manage to understand every single line of code!</p><p name="e25a" id="e25a" class="graf graf--p graf-after--p">If you’d like learn more about the rationale and the architecture of MXNet, you should read this <a href="https://arxiv.org/abs/1512.01274" data-href="https://arxiv.org/abs/1512.01274" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">paper</a>, named “<em class="markup--em markup--p-em">MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems</em>”. We’ll cover most of the concepts presented in the paper, but hopefully in a more accessible way.</p><p name="85ea" id="85ea" class="graf graf--p graf-after--p">I’ll go as slow and explain as much as I need to. Expect minimal math and minimal jargon, but no (intentional) dumbing down. You won’t become an expert — I ain’t one anyway— but I hope you’ll learn enough to understand how you can add Deep Learning capabilities to your own applications.</p><h4 name="312a" id="312a" class="graf graf--h4 graf-after--p">Running MXNet locally</h4><p name="b8e0" id="b8e0" class="graf graf--p graf-after--h4">First things first: let’s install MXNet. You’ll find the official instructions <a href="http://mxnet.io/get_started/index.html" data-href="http://mxnet.io/get_started/index.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>, but here are some additional tips.</p><p name="b9e4" id="b9e4" class="graf graf--p graf-after--p">One of the cool features of MXNet is that <strong class="markup--strong markup--p-strong">it can run identically on CPU and GPU</strong> (we’ll see later how to pick one or the other for our computations). This means that even if your computer doesn’t have an Nvidia GPU (just like my MacBook), you can still write and run MXNet code which you’ll use later on GPU-enabled systems.</p><p name="529b" id="529b" class="graf graf--p graf-after--p">If your computer has such a GPU, that’s great but you need to install the <a href="https://developer.nvidia.com/cuda-toolkit" data-href="https://developer.nvidia.com/cuda-toolkit" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">CUDA</a> and <a href="https://developer.nvidia.com/cudnn" data-href="https://developer.nvidia.com/cudnn" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">cuDNN</a> toolkits, which tends to turn into a <strong class="markup--strong markup--p-strong">nightmare</strong> more often than not. At the slightest incompatibility between the MXNet binary and the Nvidia tools, your setup will be broken and you won’t be able to work.</p><p name="6741" id="6741" class="graf graf--p graf-after--p">For this reason, I would <strong class="markup--strong markup--p-strong">strongly</strong> advise you to use the Docker images provided on the MXNet website: one for CPU environments, one for GPU environments (which requires <a href="https://github.com/NVIDIA/nvidia-docker" data-href="https://github.com/NVIDIA/nvidia-docker" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">nvidia-docker</a>). These images come pre-installed with everything you need and allow you to get started in minutes.</p><pre name="3154" id="3154" class="graf graf--pre graf-after--p">sudo -H pip install mxnet  --upgrade<br>python<br>&gt;&gt;&gt; import mxnet as mx<br>&gt;&gt;&gt; mx.__version__<br>&#39;0.9.3a3&#39;</pre><p name="4826" id="4826" class="graf graf--p graf-after--pre">For what it’s worth, the Docker images also seem to be <strong class="markup--strong markup--p-strong">more up to date</strong> than the Python package available through ‘pip’.</p><pre name="d81a" id="d81a" class="graf graf--pre graf-after--p">docker run -it  mxnet/python<br>root@88a5fe9c8def:/# python<br>&gt;&gt;&gt; import mxnet as mx<br>&gt;&gt;&gt; mx.__version__<br>&#39;0.9.5&#39;</pre><h4 name="4b00" id="4b00" class="graf graf--h4 graf-after--pre">Running MXNet on AWS</h4><p name="4634" id="4634" class="graf graf--p graf-after--h4">AWS provides you with the <strong class="markup--strong markup--p-strong">Deep Learning AMI</strong>, available both for <a href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" data-href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Linux</a> and <a href="https://aws.amazon.com/marketplace/pp/B06VSPXKDX" data-href="https://aws.amazon.com/marketplace/pp/B06VSPXKDX" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Ubuntu</a>. This AMI comes pre-installed with many Deep Learning frameworks (MXNet included), as well as all the Nvidia tools and more. <strong class="markup--strong markup--p-strong">No plumbing needed</strong>.</p><pre name="093a" id="093a" class="graf graf--pre graf-after--p">====================================================================<br>       __|  __|_  )<br>       _|  (     /   Deep Learning AMI for Amazon Linux<br>      ___|\___|___|<br>====================================================================</pre><pre name="4c80" id="4c80" class="graf graf--pre graf-after--pre">[ec2-user@ip-172-31-42-173 ~]$ nvidia-smi -L<br>GPU 0: GRID K520 (UUID: GPU-d470337d-b59b-ca2a-fe6d-718f0faf2153)</pre><pre name="aa7b" id="aa7b" class="graf graf--pre graf-after--pre">[ec2-user@ip-172-31-42-173 ~]$ python<br>&gt;&gt;&gt; import mxnet as mx<br>&gt;&gt;&gt; mx.__version__<br>&#39;0.9.3&#39;</pre><p name="6e1f" id="6e1f" class="graf graf--p graf-after--pre">You can run this AMI either on a regular instance or on a GPU instance. If your computer doesn’t have an Nvidia GPU, this might come in handy later when we start training networks: your most inexpensive option will be to use a <strong class="markup--strong markup--p-strong">g2.2xlarge</strong> instance at $0.65 per hour.</p><p name="ceee" id="ceee" class="graf graf--p graf-after--p">For now, a good old-fashioned CPU is all we need! Let’s get started.</p><h4 name="1f5d" id="1f5d" class="graf graf--h4 graf-after--p">Why NDArrays are important</h4><p name="2545" id="2545" class="graf graf--p graf-after--h4">The first part of the MXNet API we’re going to look at in the <strong class="markup--strong markup--p-strong">NDArray API</strong>. An NDArray is an <strong class="markup--strong markup--p-strong">n-dimensional array, containing items of identical type and size</strong> (32-bit floats, 32-bit integers, etc).</p><p name="9224" id="9224" class="graf graf--p graf-after--p">Why are these arrays important? As explained in a <a href="https://medium.com/towards-data-science/fascinating-tales-of-a-strange-tomorrow-72048639e754" data-href="https://medium.com/towards-data-science/fascinating-tales-of-a-strange-tomorrow-72048639e754" class="markup--anchor markup--p-anchor" target="_blank">previous article</a>, training and running neural networks involve a lot of math operations. Multi-dimensional arrays is how we’ll store our data.</p><blockquote name="5a96" id="5a96" class="graf graf--blockquote graf-after--p">Input data, neuron weights and output data are stored in vectors and matrices, so it’s quite natural to have this kind of construct available.</blockquote><p name="7b8b" id="7b8b" class="graf graf--p graf-after--blockquote">Let’s take a simple example: categorizing images. The image below represents an handwritten ‘8’, 18x18 pixels.</p><figure name="f927" id="f927" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*D6pp5hTfUl8FmzYwJ3N8LQ.png" data-width="352" data-height="351" src="https://cdn-images-1.medium.com/max/800/1*D6pp5hTfUl8FmzYwJ3N8LQ.png"><figcaption class="imageCaption">The number 8, 18x18 pixels</figcaption></figure><p name="48c3" id="48c3" class="graf graf--p graf-after--figure">This image represents the same image as an 18x18 matrix, with each cell holding the greyscale value for the corresponding pixel: ‘0’ for white, ‘255’ for black and values in between for 254 shades of grey. This matrix representation is what we’ll run through a neural network to train it in categorizing digits from 0 to 9.</p><figure name="4e5b" id="4e5b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Ct7GN4a5gqONNUFV_qMu_A.png" data-width="357" data-height="356" src="https://cdn-images-1.medium.com/max/800/1*Ct7GN4a5gqONNUFV_qMu_A.png"><figcaption class="imageCaption">An 18x18 matrix, holding greyscale values for the image above</figcaption></figure><p name="cb37" id="cb37" class="graf graf--p graf-after--figure">Now imagine that we use colour images instead of greyscale images. Each image would now be described using 3 matrices, one for each colour, so our input data is now a little more complicated.</p><p name="578f" id="578f" class="graf graf--p graf-after--p">Let’s go one step further. Imagine we’re doing real time image recognition for autonomous driving: in order to make decisions on quality up-to-date data, we’re using 1000 x 1000-pixel RGB images at 30 frames per second. Every second, we’ll have to handle 90 1000 x 1000 matrices (30 frames x 3 colours). If each pixel is represented as a 32-bit value, that’s 90 x 1000 x 1000 x 4 bytes, more or less 343 Megabytes. If you have multiple cameras, things add up pretty quick.</p><p name="22b3" id="22b3" class="graf graf--p graf-after--p">That’s a lot of data to pump through a neural network: for maximal performance (i.e. minimal latency), GPUs don’t process images one by one: instead, they process them in batches. If we use a batch size of 8, our neural network will process input data in chunks of 1000 x 1000 x 24, i.e. a 3-dimensional array holding 8 1000 x 1000 images in 3 colours.</p><blockquote name="c467" id="c467" class="graf graf--blockquote graf--hasDropCapModel graf-after--p">Bottom line: you need to understand NDArrays :) They’re the bread and butter of neural networks, as they will be used to store pretty much all of our data.</blockquote><h4 name="d9b2" id="d9b2" class="graf graf--h4 graf-after--blockquote">The NDArray API</h4><p name="fa67" id="fa67" class="graf graf--p graf-after--h4">Now that we know why NDArrays are important, let’s look at how they work (yeah, code at last!). If you’ve worked with the <a href="http://www.numpy.org/" data-href="http://www.numpy.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">numpy</a> Python library, good news: NDArrays are extremely similar and you probably know most of the API, which is fully documented <a href="http://mxnet.io/api/python/ndarray.html" data-href="http://mxnet.io/api/python/ndarray.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><p name="a30b" id="a30b" class="graf graf--p graf-after--p">Let’s start with the basics. No explanation needed, I suppose :)</p><pre name="14c7" id="14c7" class="graf graf--pre graf-after--p">&gt;&gt;&gt; a = mx.nd.array([[1,2,3], [4,5,6]])<br>&gt;&gt;&gt; a.size<br>6<br>&gt;&gt;&gt; a.shape<br>(2L, 3L)<br>&gt;&gt;&gt; a.dtype<br>&lt;type &#39;numpy.float32&#39;&gt;<br><br></pre><p name="35b7" id="35b7" class="graf graf--p graf-after--pre">By default, an NDArray holds 32-bit floats, but we can customize that.</p><pre name="64e0" id="64e0" class="graf graf--pre graf-after--p">&gt;&gt;&gt; import numpy as np<br>&gt;&gt;&gt; b = mx.nd.array([[1,2,3], [2,3,4]], dtype=np.int32)<br>&gt;&gt;&gt; b.dtype</pre><p name="fed4" id="fed4" class="graf graf--p graf-after--pre">Printing an NDArray is as easy as this.</p><pre name="2423" id="2423" class="graf graf--pre graf-after--p">&gt;&gt;&gt; b.asnumpy()<br>array([[1, 2, 3],<br>       [2, 3, 4]], dtype=int32)</pre><p name="3920" id="3920" class="graf graf--p graf-after--pre">All the math operators you’d expect are available. Let’s try an element-wise matrix multiplication.</p><pre name="d515" id="d515" class="graf graf--pre graf-after--p">&gt;&gt;&gt; a = mx.nd.array([[1,2,3], [4,5,6]])<br>&gt;&gt;&gt; b = a*a<br>&gt;&gt;&gt; b.asnumpy()<br>array([[  1.,   4.,   9.],<br>       [ 16.,  25.,  36.]], dtype=float32)</pre><p name="2054" id="2054" class="graf graf--p graf-after--pre">How about an proper matrix multiplication (aka ‘dot product’)?</p><pre name="2885" id="2885" class="graf graf--pre graf-after--p">&gt;&gt;&gt; a = mx.nd.array([[1,2,3], [4,5,6]])<br>&gt;&gt;&gt; a.shape<br>(2L, 3L)<br>&gt;&gt;&gt; a.asnumpy()<br>array([[ 1.,  2.,  3.],<br>       [ 4.,  5.,  6.]], dtype=float32)</pre><pre name="9418" id="9418" class="graf graf--pre graf-after--pre">&gt;&gt;&gt; b = a.T<br>&gt;&gt;&gt; b.shape<br>(3L, 2L)<br>&gt;&gt;&gt; b.asnumpy()<br>array([[ 1.,  4.],<br>       [ 2.,  5.],<br>       [ 3.,  6.]], dtype=float32)</pre><pre name="4e13" id="4e13" class="graf graf--pre graf-after--pre">&gt;&gt;&gt; c = mx.nd.dot(a,b)<br>&gt;&gt;&gt; c.shape<br>(2L, 2L)<br>&gt;&gt;&gt; c.asnumpy()<br>array([[ 14.,  32.],<br>       [ 32.,  77.]], dtype=float32)</pre><p name="e2ac" id="e2ac" class="graf graf--p graf-after--pre">Let’s try something a little more complicated:</p><ul class="postList"><li name="a7b7" id="a7b7" class="graf graf--li graf-after--p">initialize a 1000 x 1000 matrix with a uniform distribution, stored on GPU#0 (I’m using a g2 instance here).</li><li name="f1c1" id="f1c1" class="graf graf--li graf-after--li">initialize another 1000 x 1000 matrix with a normal distribution (mean of 1 and standard deviation of 2), also on GPU#0.</li></ul><pre name="9637" id="9637" class="graf graf--pre graf-after--li">&gt;&gt;&gt; c = mx.nd.uniform(low=0, high=1, shape=(1000,1000), ctx=&quot;gpu(0)&quot;)<br>&gt;&gt;&gt; d = mx.nd.normal(loc=1, scale=2, shape=(1000,1000), ctx=&quot;gpu(0)&quot;)<br>&gt;&gt;&gt; e = mx.nd.dot(c,d)</pre><blockquote name="f978" id="f978" class="graf graf--blockquote graf--hasDropCapModel graf-after--pre">Remember that MXNet can run identically on CPU and GPU. This is an example of this: just replace “gpu(0)” by “cpu(0)” in the previous example and now the dot product will run on the CPU.</blockquote><p name="2c88" id="2c88" class="graf graf--p graf-after--blockquote">You should now know enough to start playing with NDArrays. There are also higher level functions to build neural networks (<em class="markup--em markup--p-em">FullyConnected</em>, etc.) but we’ll study them when we start looking at actual networks.</p><p name="d73d" id="d73d" class="graf graf--p graf-after--p graf--trailing">That’s it for today. In the next post, we’ll look at the Symbol API, which allows us to define data flows, which is pretty much what neural networks are all about. Thanks for reading and stay tuned.</p></div></div></section><section name="4a16" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="6565" id="6565" class="graf graf--p graf--leading">Next :</p><ul class="postList"><li name="e655" id="e655" class="graf graf--li graf-after--p"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-2-ce761513124e" data-href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-2-ce761513124e" class="markup--anchor markup--li-anchor" target="_blank">Part 2</a>: the Symbol API</li><li name="de6c" id="de6c" class="graf graf--li graf-after--li"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-3-1803112ba3a8" data-href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-3-1803112ba3a8" class="markup--anchor markup--li-anchor" target="_blank">Part 3</a>: the Module API</li><li name="8171" id="8171" class="graf graf--li graf-after--li"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-4-df22560b83fe" data-href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-4-df22560b83fe" class="markup--anchor markup--li-anchor" target="_blank">Part 4</a>: Using a pre-trained model for image classification (Inception v3)</li><li name="061d" id="061d" class="graf graf--li graf-after--li"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-5-9e78534096db" data-href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-5-9e78534096db" class="markup--anchor markup--li-anchor" target="_blank">Part 5</a>: More pre-trained models (VGG16 and ResNet-152)</li><li name="6b93" id="6b93" class="graf graf--li graf-after--li"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-6-fcdd7521ae87" data-href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-6-fcdd7521ae87" class="markup--anchor markup--li-anchor" target="_blank">Part 6</a>: Real-time object detection on a Raspberry Pi (and it speaks, too!)</li></ul><figure name="724a" id="724a" class="graf graf--figure graf--iframe graf-after--li"><iframe src="https://upscri.be/8f5f8b?as_embed=true" width="700" height="350" frameborder="0" scrolling="no"></iframe></figure></div><div class="section-inner sectionLayout--outsetColumn"><figure name="af7c" id="af7c" class="graf graf--figure graf--layoutOutsetCenter graf-after--figure"><img class="graf-image" data-image-id="1*bQlRSzFHJEmF4Q7PyrLgng.gif" data-width="725" data-height="71" src="https://cdn-images-1.medium.com/max/1200/1*bQlRSzFHJEmF4Q7PyrLgng.gif"></figure></div><div class="section-inner sectionLayout--outsetRow" data-paragraph-count="3"><figure name="654d" id="654d" class="graf graf--figure graf--layoutOutsetRow is-partialWidth graf-after--figure" style="width: 33.333%;"><a href="https://medium.com/becoming-human/artificial-intelligence-communities-c305f28e674c" data-href="https://medium.com/becoming-human/artificial-intelligence-communities-c305f28e674c" class="graf-imageAnchor" data-action="image-link" data-action-observe-only="true"><img class="graf-image" data-image-id="1*2f7OqE2AJK1KSrhkmD9ZMw.png" data-width="255" data-height="170" src="https://cdn-images-1.medium.com/max/400/1*2f7OqE2AJK1KSrhkmD9ZMw.png"></a></figure><figure name="65ee" id="65ee" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 33.333%;"><a href="https://upscri.be/8f5f8b" data-href="https://upscri.be/8f5f8b" class="graf-imageAnchor" data-action="image-link" data-action-observe-only="true"rel="noopener"target="_blank"><img class="graf-image" data-image-id="1*v-PpfkSWHbvlWWamSVHHWg.png" data-width="255" data-height="170" src="https://cdn-images-1.medium.com/max/400/1*v-PpfkSWHbvlWWamSVHHWg.png"></a></figure><figure name="dd1b" id="dd1b" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure graf--trailing" style="width: 33.333%;"><a href="https://medium.com/becoming-human/write-for-us-48270209de63" data-href="https://medium.com/becoming-human/write-for-us-48270209de63" class="graf-imageAnchor" data-action="image-link" data-action-observe-only="true"><img class="graf-image" data-image-id="1*Wt2auqISiEAOZxJ-I7brDQ.png" data-width="255" data-height="170" src="https://cdn-images-1.medium.com/max/400/1*Wt2auqISiEAOZxJ-I7brDQ.png"></a></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/848febdcf8ab"><time class="dt-published" datetime="2017-04-09T18:22:51.604Z">April 9, 2017</time></a>.</p><p><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
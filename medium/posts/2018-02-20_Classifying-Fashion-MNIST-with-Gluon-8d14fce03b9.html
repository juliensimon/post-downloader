<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Classifying Fashion-MNIST with Gluon</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Classifying Fashion-MNIST with Gluon</h1>
</header>
<section data-field="subtitle" class="p-summary">
In a previous post, we took a first look at the Gluon API, a high-level API for built on top of Apache MXNet.
</section>
<section data-field="body" class="e-content">
<section name="b305" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="72fa" id="72fa" class="graf graf--h3 graf--leading graf--title">Classifying Fashion-MNIST with Gluon</h3><p name="fb31" id="fb31" class="graf graf--p graf-after--h3">In a <a href="https://medium.com/@julsimon/gluon-building-blocks-for-your-deep-learning-universe-4bce4e56ef55" data-href="https://medium.com/@julsimon/gluon-building-blocks-for-your-deep-learning-universe-4bce4e56ef55" class="markup--anchor markup--p-anchor" target="_blank">previous post</a>, we took a first look at the <strong class="markup--strong markup--p-strong">Gluon API</strong>, a <a href="https://mxnet.incubator.apache.org/api/python/gluon/gluon.html#gluon-api" data-href="https://mxnet.incubator.apache.org/api/python/gluon/gluon.html#gluon-api" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener" target="_blank">high-level API</a> for built on top of <a href="http://mxnet.incubator.apache.org" data-href="http://mxnet.incubator.apache.org" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener" target="_blank">Apache MXNet</a>.</p><p name="490d" id="490d" class="graf graf--p graf-after--p">In this post, we’ll keep exploring Gluon but first we need a cool dataset to work with.</p><blockquote name="ae28" id="ae28" class="graf graf--blockquote graf-after--p">Code is available on <a href="https://github.com/juliensimon/dlnotebooks" data-href="https://github.com/juliensimon/dlnotebooks" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">Github</a>.</blockquote><h4 name="4dbf" id="4dbf" class="graf graf--h4 graf-after--blockquote">The Fashion-MNIST dataset</h4><p name="9e55" id="9e55" class="graf graf--p graf-after--h4">Put together by e-tailer <a href="https://jobs.zalando.com/tech/blog/" data-href="https://jobs.zalando.com/tech/blog/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Zalando</a>, <a href="https://github.com/zalandoresearch/fashion-mnist" data-href="https://github.com/zalandoresearch/fashion-mnist" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Fashion-MNIST</strong></a> is a <strong class="markup--strong markup--p-strong">drop-in replacement</strong> for the well-known (and probably over-used) <a href="http://yann.lecun.com/exdb/mnist/" data-href="http://yann.lecun.com/exdb/mnist/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">MNIST</a> dataset: same number of samples, same number of classes and same filenames! You’ll find plenty of details in this <a href="https://arxiv.org/abs/1708.07747" data-href="https://arxiv.org/abs/1708.07747" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">technical report</a>.</p><p name="ff29" id="ff29" class="graf graf--p graf-after--p">Instead of digits, this data set contains the following <strong class="markup--strong markup--p-strong">fashion items</strong>: t-shirt/top, trouser, pullover, dress, coat, sandal, shirt, sneaker, bag and ankle boot. Some items look very similar, which is likely to make our classification job harder.</p><figure name="17af" id="17af" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*5HWHuNa8ddwO1l0ifVrH4Q.png" data-width="480" data-height="480" src="https://cdn-images-1.medium.com/max/800/1*5HWHuNa8ddwO1l0ifVrH4Q.png"><figcaption class="imageCaption">Samples from Fashion-MNIST</figcaption></figure><h4 name="a15e" id="a15e" class="graf graf--h4 graf-after--figure">Loading the dataset</h4><p name="120d" id="120d" class="graf graf--p graf-after--h4">Thanks to the <strong class="markup--strong markup--p-strong">Gluon vision API</strong>, it couldn’t be simpler to load the training set and the validation set. Each sample is a 28x28 greyscale image shaped (28, 28, 1). We’ll use a simple transform function to reshape it to (1,28,28).</p><figure name="f23e" id="f23e" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/6a3fef5400df6f2a5fec486ccc90139e.js"></script></figure><h4 name="0aa8" id="0aa8" class="graf graf--h4 graf-after--figure"><strong class="markup--strong markup--h4-strong">Building a configurable Convolutional Neural Network</strong></h4><p name="efd2" id="efd2" class="graf graf--p graf-after--h4">We’re going to try out a number of network architectures, so let’s write a function that lets us build a variety of CNNs from the following <a href="https://mxnet.incubator.apache.org/api/python/gluon.html" data-href="https://mxnet.incubator.apache.org/api/python/gluon.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Gluon layers</a>:</p><ul class="postList"><li name="831c" id="831c" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Convolution</strong> and <strong class="markup--strong markup--li-strong">Max Pooling</strong> layers, with parameters for kernel size, padding, pooling and stride.</li><li name="525a" id="525a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Dense</strong> layer for final classification,</li><li name="d3d3" id="d3d3" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Dropout</strong> and <strong class="markup--strong markup--li-strong">Batch Normalization</strong> layers to fight overfitting and help our network learn better.</li></ul><p name="523b" id="523b" class="graf graf--p graf-after--li">By default, we’ll use the <strong class="markup--strong markup--p-strong">ReLU activation function</strong> but let’s also plan for <strong class="markup--strong markup--p-strong">Leaky ReLU</strong>, which is a separate layer in Gluon.</p><figure name="ba40" id="ba40" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/fe8edac20205f63c99f7c0ab7205dda3.js"></script></figure><p name="ac59" id="ac59" class="graf graf--p graf-after--figure">Thanks to this function, we can now build a variety of CNNs with one single line of code. Here’s a simple example.</p><figure name="52a0" id="52a0" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/08c2a83bd3be3bb3cad834ff85aebe3e.js"></script></figure><p name="1b13" id="1b13" class="graf graf--p graf-after--figure">The <strong class="markup--strong markup--p-strong">flexibility</strong> of the Gluon API is really great here. I must admit that this would have been more work with the <a href="https://mxnet.incubator.apache.org/api/python/symbol.html" data-href="https://mxnet.incubator.apache.org/api/python/symbol.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">symbolic API</a> in MXNet :)</p><p name="970a" id="970a" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Initializing the model</strong></p><p name="0f7a" id="0f7a" class="graf graf--p graf-after--p">We have to initialize weights, pick an optimizer and set its parameters. Nothing unusual. Let’s settle for Xavier initialization, but feel free to try <a href="https://mxnet.incubator.apache.org/api/python/optimization.html" data-href="https://mxnet.incubator.apache.org/api/python/optimization.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">something else</a>.</p><figure name="17dd" id="17dd" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/1792f21b1670516ae9764def5fca0ea6.js"></script></figure><h4 name="0233" id="0233" class="graf graf--h4 graf-after--figure">Computing accuracy</h4><p name="5ff6" id="5ff6" class="graf graf--p graf-after--h4">During training, we’d like to measure <strong class="markup--strong markup--p-strong">training</strong> and <strong class="markup--strong markup--p-strong">validation</strong> accuracy. Let’s use an MXNet <a href="https://mxnet.incubator.apache.org/api/python/metric.html" data-href="https://mxnet.incubator.apache.org/api/python/metric.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">metric</strong></a> to compute them.</p><figure name="38f0" id="38f0" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/bcaeba6f98381f35081218e3d2d785d2.js"></script></figure><h4 name="aa31" id="aa31" class="graf graf--h4 graf-after--figure">Training the model</h4><p name="f547" id="f547" class="graf graf--p graf-after--h4">Our training loop is the standard Gluon training loop:</p><ul class="postList"><li name="b06b" id="b06b" class="graf graf--li graf-after--p">Iterate over <strong class="markup--strong markup--li-strong">epochs</strong> and <strong class="markup--strong markup--li-strong">batches</strong>,</li><li name="0bdd" id="0bdd" class="graf graf--li graf-after--li">Record <strong class="markup--strong markup--li-strong">gradients</strong> while propagating, computing the <strong class="markup--strong markup--li-strong">loss function</strong> and back propagating,</li><li name="79a7" id="79a7" class="graf graf--li graf-after--li">Applying a <strong class="markup--strong markup--li-strong">training step</strong>, i.e. updating the weights.</li></ul><p name="b3b1" id="b3b1" class="graf graf--p graf-after--li">In the process, we’re also computing accuracies and storing their values for plotting purposes.</p><figure name="0930" id="0930" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/8d29330b068fdfe8490b24ea90af220a.js"></script></figure><h4 name="3b77" id="3b77" class="graf graf--h4 graf-after--figure">Measuring and plotting accuracy</h4><p name="462e" id="462e" class="graf graf--p graf-after--h4">Once training is complete, let’s plot training accuracy and validation accuracy vs epochs. As usual, we’ll use <a href="http://matplotlib.org" data-href="http://matplotlib.org" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">matplotlib</a>. Pretty standard stuff, right?</p><figure name="ca81" id="ca81" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/358c8a0db3fcd5d1c14819ab55bfba7b.js"></script></figure><h4 name="9c77" id="9c77" class="graf graf--h4 graf-after--figure">Strategy</h4><p name="7dff" id="7dff" class="graf graf--p graf-after--h4">Network architecture, hyper parameters, layer parameters: so many combinations to explore… Let’s try to set some guidelines.</p><p name="2443" id="2443" class="graf graf--p graf-after--p">We’ll start from a <strong class="markup--strong markup--p-strong">basic CNN</strong>, known to work well on the <strong class="markup--strong markup--p-strong">MNIST</strong> dataset. We’ll apply it as is to Fashion-MNIST to get a baseline.</p><p name="67f0" id="67f0" class="graf graf--p graf-after--p">First, we’ll work on getting the <strong class="markup--strong markup--p-strong">best training performance</strong> possible, making sure that the network is large enough to learn the training dataset.</p><p name="e7eb" id="e7eb" class="graf graf--p graf-after--p">We’ll probably end up <strong class="markup--strong markup--p-strong">overfitting</strong> it in the process, which is why we’ll then work on <strong class="markup--strong markup--p-strong">improving validation accuracy</strong>.</p><p name="346b" id="346b" class="graf graf--p graf-after--p">Very well then, let’s get to work!</p><h4 name="f11c" id="f11c" class="graf graf--h4 graf-after--p">First try: basic CNN</h4><p name="826d" id="826d" class="graf graf--p graf-after--h4">The following network scores <strong class="markup--strong markup--p-strong">99.2%</strong> validation accuracy on MNIST.</p><ul class="postList"><li name="4be0" id="4be0" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Convolutional layer</strong> with 64 3x3 filters, padding and stride set to 1 (1x28x28 → 64x28x28). This layer doesn’t shrink the image (a.k.a. ‘same’ convolution) as it’s quite small already.</li><li name="0179" id="0179" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Max Pooling layer</strong> with 2x2 pooling and stride set to 2 (64x28x28 → 64x13x13).</li><li name="718c" id="718c" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Convolutional layer</strong> with 64 3x3 filters, padding and stride set to 1 (64x13x13 → 64x10x10).</li><li name="46e1" id="46e1" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Max Pooling layer</strong> with 2x2 pooling and stride set to 2 (64x10x10 → 64x5x5)</li><li name="7f5a" id="7f5a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Flatten layer</strong> (64x5x5 →1600)</li><li name="f35a" id="f35a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Fully connected layer</strong> with 256 neurons (1600 → 256).</li><li name="8b42" id="8b42" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Fully connected layer</strong> with 64 neurons (256 → 64).</li><li name="961b" id="961b" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Output layer</strong> with 10 neurons (64 → 10).</li></ul><p name="0243" id="0243" class="graf graf--p graf-after--li">We’ll use <strong class="markup--strong markup--p-strong">ReLU</strong> for all activation layers.</p><figure name="305a" id="305a" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/c7f7af159fcebe758f02dd7dd26773f5.js"></script></figure><p name="9ded" id="9ded" class="graf graf--p graf-after--figure">Here’s the result after 50 epochs (<a href="https://gist.github.com/juliensimon/e9b318825d864978f254ebd5afcd0720" data-href="https://gist.github.com/juliensimon/e9b318825d864978f254ebd5afcd0720" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">training log</a>).</p><figure name="4efd" id="4efd" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*wjK0ET9mxHNcHOUp45hwWg.png" data-width="408" data-height="266" src="https://cdn-images-1.medium.com/max/800/1*wjK0ET9mxHNcHOUp45hwWg.png"><figcaption class="imageCaption">Epoch#49 Training=<strong class="markup--strong markup--figure-strong">0.9988</strong> Validation=<strong class="markup--strong markup--figure-strong">0.9242</strong></figcaption></figure><p name="9980" id="9980" class="graf graf--p graf-after--figure">Top validation accuracy is<strong class="markup--strong markup--p-strong"> 92.42%</strong>. This is significantly <strong class="markup--strong markup--p-strong">lower</strong> than the MNIST score (99.2%), which goes to show that Fashion MNIST is indeed more difficult to learn. Good :-&gt;</p><p name="5669" id="5669" class="graf graf--p graf-after--p">On the bright side, it does look like this network is capable of learning the dataset. It also scored much higher than all <strong class="markup--strong markup--p-strong">non Deep Learning</strong> based techniques <a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/" data-href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">benchmarked</a> on Fashion-MNIST (the top one is a variation of Support Vector Machines at 89.7%).</p><p name="a1e0" id="a1e0" class="graf graf--p graf-after--p">So, hurrah for Deep Learning, but let’s improve this score, shall we?</p><h4 name="3b4b" id="3b4b" class="graf graf--h4 graf-after--p">Second try: use a better optimizer</h4><p name="f4e4" id="f4e4" class="graf graf--p graf-after--h4">We used SGD with a fixed learning rate, which is ok to get a quick feeling for how the network performs. However, more <a href="http://ruder.io/optimizing-gradient-descent/" data-href="http://ruder.io/optimizing-gradient-descent/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">modern optimizers</strong></a> will definitely improve performance.</p><p name="2c7f" id="2c7f" class="graf graf--p graf-after--p">Popular choices includes <strong class="markup--strong markup--p-strong">AdaDelta</strong> (<a href="https://arxiv.org/abs/1212.5701" data-href="https://arxiv.org/abs/1212.5701" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">paper</a>), <strong class="markup--strong markup--p-strong">AdaGrad</strong> (<a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" data-href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">pdf</a>) or <strong class="markup--strong markup--p-strong">Adam</strong> (<a href="https://arxiv.org/abs/1412.6980" data-href="https://arxiv.org/abs/1412.6980" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">paper</a>). Which one should we pick? It looks like everyone tends to rely on Adam, so let’s try it for 50 epochs (<a href="https://gist.github.com/juliensimon/ddfe77f496ff116e134f388f26224095" data-href="https://gist.github.com/juliensimon/ddfe77f496ff116e134f388f26224095" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">training log</a>).</p><figure name="5f21" id="5f21" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Et6Jo6_w_nX37EvI0Dw-Wg.png" data-width="408" data-height="266" src="https://cdn-images-1.medium.com/max/800/1*Et6Jo6_w_nX37EvI0Dw-Wg.png"><figcaption class="imageCaption">Epoch#10 Training=<strong class="markup--strong markup--figure-strong">0.9716</strong> Validation=<strong class="markup--strong markup--figure-strong">0.9305</strong></figcaption></figure><p name="0c42" id="0c42" class="graf graf--p graf-after--figure">Top validation accuracy is<strong class="markup--strong markup--p-strong"> 93.05% </strong>at epoch #10 (!). Adam does learn very fast indeed.</p><h4 name="6388" id="6388" class="graf graf--h4 graf-after--p">Third try: add Batch Normalization</h4><p name="1b00" id="1b00" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">Batch Normalization</strong> (<a href="https://arxiv.org/abs/1502.03167" data-href="https://arxiv.org/abs/1502.03167" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">paper</a>) is a technique that helps <strong class="markup--strong markup--p-strong">train faster</strong> and <strong class="markup--strong markup--p-strong">avoid overfitting</strong> by normalizing values for each training batch. The authors recommend applying it to the inputs of activation layers.</p><p name="4d34" id="4d34" class="graf graf--p graf-after--p">Let’s update our network accordingly and use this technique for both the convolutional layers and fully connected layers.</p><figure name="5a72" id="5a72" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/664bb2daec8467d308fd7df11c6020ac.js"></script></figure><p name="c2cc" id="c2cc" class="graf graf--p graf-after--figure">Here’s the result (<a href="https://gist.github.com/juliensimon/58e1ba6271c5c1d09241ad8a9ef6b7b5" data-href="https://gist.github.com/juliensimon/58e1ba6271c5c1d09241ad8a9ef6b7b5" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">training log</a>).</p><figure name="6e5f" id="6e5f" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*CvRoO7dAeQFZX1gWjV0LAA.png" data-width="408" data-height="266" src="https://cdn-images-1.medium.com/max/800/1*CvRoO7dAeQFZX1gWjV0LAA.png"><figcaption class="imageCaption">Epoch#45 Training=<strong class="markup--strong markup--figure-strong">0.9994</strong> Validation=<strong class="markup--strong markup--figure-strong">0.9331</strong></figcaption></figure><p name="4408" id="4408" class="graf graf--p graf-after--figure">Compared to previous runs, this one learned <strong class="markup--strong markup--p-strong">even faster</strong>. With respect to validation accuracy, we got a small improvement at <strong class="markup--strong markup--p-strong">93.31%</strong>.</p><h4 name="d7da" id="d7da" class="graf graf--h4 graf-after--p">Fourth try: add Dropout</h4><p name="05fe" id="05fe" class="graf graf--p graf-after--h4">Training performance is now very good. Let’s now work on improving <strong class="markup--strong markup--p-strong">validation accuracy</strong>. Batch Normalization did help a bit, but we should be able to do even better by adding <strong class="markup--strong markup--p-strong">Dropout</strong> layers.</p><p name="78db" id="78db" class="graf graf--p graf-after--p">Dropout (<a href="https://arxiv.org/abs/1207.0580" data-href="https://arxiv.org/abs/1207.0580" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">paper</a>) is a technique that <strong class="markup--strong markup--p-strong">randomly sets to zero a configurable fraction of connections</strong> between two layers. By throwing this wrench into the training process, we slow it down, make it <strong class="markup--strong markup--p-strong">work harder</strong> at figuring out <strong class="markup--strong markup--p-strong">unexpected inputs</strong> and hopefully help the model <strong class="markup--strong markup--p-strong">generalize better</strong>.</p><p name="82d3" id="82d3" class="graf graf--p graf-after--p">Let’s add <strong class="markup--strong markup--p-strong">30% dropout</strong> after each convolution block and before each Dense layer. That’s a lot of Dropout: training should be much slower, so we’ll train for 100 epochs.</p><figure name="c71a" id="c71a" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/66ebb8f24c1fe41adcbfad7699dca764.js"></script></figure><p name="9714" id="9714" class="graf graf--p graf-after--figure">Here’s the <a href="https://gist.github.com/juliensimon/2f120c911ddc7d604c93c7e24408e40b" data-href="https://gist.github.com/juliensimon/2f120c911ddc7d604c93c7e24408e40b" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">training log</a>. The best validation accuracy is reached at epoch #72: <strong class="markup--strong markup--p-strong">94.39%</strong>. Dropout helped us squeeze <strong class="markup--strong markup--p-strong">an extra 1%</strong> accuracy!</p><figure name="8b9e" id="8b9e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*xu5i5nM1FruCaJB50GNm9Q.png" data-width="408" data-height="266" src="https://cdn-images-1.medium.com/max/800/1*xu5i5nM1FruCaJB50GNm9Q.png"><figcaption class="imageCaption">Epoch#72 Training=<strong class="markup--strong markup--figure-strong">0.9956</strong> Validation=<strong class="markup--strong markup--figure-strong">0.9439</strong></figcaption></figure><h4 name="c335" id="c335" class="graf graf--h4 graf-after--figure">Now what?</h4><p name="f6d9" id="f6d9" class="graf graf--p graf-after--h4">I’m sure we could go higher if we kept experimenting: tuning dropout , trying out different activation functions like Leaky ReLU, using data augmentation, maybe adding more convolution kernels and so on. This is a rather long post already, so let’s stop there :) However, please <strong class="markup--strong markup--p-strong">keep tweaking</strong>, it’s the best way to learn (pun not intended) and the Gluon API makes it particularly easy to <strong class="markup--strong markup--p-strong">build networks programatically</strong>.</p><blockquote name="6be8" id="6be8" class="graf graf--blockquote graf-after--p">Just out of curiosity, I ran this improved network on MNIST and got to 99.52% accuracy after only 16 epochs!</blockquote><p name="7d41" id="7d41" class="graf graf--p graf-after--blockquote graf--trailing">As always, thanks for reading. Happy to answer questions here or on <a href="https://twitter.com/julsimon/" data-href="https://twitter.com/julsimon/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Twitter</a>.</p></div></div></section><section name="2675" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="2d37" id="2d37" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">Improving validation accuracy… there’s no way but the hard way :*)</em></p><figure name="9331" id="9331" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/4DHHv5OuEzY?feature=oembed" width="640" height="480" frameborder="0" scrolling="no"></iframe></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/8d14fce03b9"><time class="dt-published" datetime="2018-02-20T15:14:15.236Z">February 20, 2018</time></a>.</p><p><a href="https://medium.com/@julsimon/classifying-fashion-mnist-with-gluon-8d14fce03b9" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

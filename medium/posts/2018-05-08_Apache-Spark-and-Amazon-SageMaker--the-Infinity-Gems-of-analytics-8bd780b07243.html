<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Apache Spark and Amazon SageMaker, the Infinity Gems of analytics</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Apache Spark and Amazon SageMaker, the Infinity Gems of analytics</h1>
</header>
<section data-field="subtitle" class="p-summary">
In a previous post, I showed you how to build a spam classifier by running PySpark on an Amazon SageMaker notebook instance.
</section>
<section data-field="body" class="e-content">
<section name="4f02" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7070" id="7070" class="graf graf--h3 graf--leading graf--title">Apache Spark and Amazon SageMaker, the Infinity Gems of analytics</h3><p name="300e" id="300e" class="graf graf--p graf-after--h3">In a previous post, I showed you <a href="https://medium.com/@julsimon/building-a-spam-classifier-pyspark-mllib-vs-sagemaker-xgboost-1980158a900f" data-href="https://medium.com/@julsimon/building-a-spam-classifier-pyspark-mllib-vs-sagemaker-xgboost-1980158a900f" class="markup--anchor markup--p-anchor" target="_blank">how to build a spam classifier</a> by running <a href="https://spark.apache.org/docs/latest/api/python/index.html" data-href="https://spark.apache.org/docs/latest/api/python/index.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">PySpark</strong></a> on an <a href="https://aws.amazon.com/sagemaker" data-href="https://aws.amazon.com/sagemaker" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon SageMaker</strong></a><strong class="markup--strong markup--p-strong"> </strong>notebook instance.</p><p name="62b7" id="62b7" class="graf graf--p graf-after--p">This is a fine setup for experimentation but neither scalable nor automated enough for production. Now, let’s go all the way and use a proper <a href="https://aws.amazon.com/emr" data-href="https://aws.amazon.com/emr" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon EMR</strong></a> cluster running Spark and using the <a href="https://github.com/aws/sagemaker-spark/" data-href="https://github.com/aws/sagemaker-spark/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">SageMaker Spark SDK</strong></a> to fire up training jobs.</p><figure name="9e01" id="9e01" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*IMN1uGhTOkn7ccgv." data-width="736" data-height="301" src="https://cdn-images-1.medium.com/max/800/0*IMN1uGhTOkn7ccgv."><figcaption class="imageCaption">Data Science Thanos: “With the SageMaker and Spark gems, even the mightiest data sets will bow to my will!”.</figcaption></figure><blockquote name="04b0" id="04b0" class="graf graf--blockquote graf-after--figure">We also <a href="https://medium.com/@julsimon/mixing-spark-with-sagemaker-d30d34ffaee7" data-href="https://medium.com/@julsimon/mixing-spark-with-sagemaker-d30d34ffaee7" class="markup--anchor markup--blockquote-anchor" target="_blank">briefly touched upon the “why?”</a>. There’s more to it and I just recorded a webinar on this topic… but I don’t want to spoil it :) Just rest assured that half the living universe *doesn’t* die at the end. I’ll share the video when it’s live on YouTube.</blockquote><h4 name="ea1c" id="ea1c" class="graf graf--h4 graf-after--blockquote">SDK examples</h4><p name="2672" id="2672" class="graf graf--p graf-after--h4">The <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/apache-spark.html" data-href="https://docs.aws.amazon.com/sagemaker/latest/dg/apache-spark.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">SageMaker documentation</a> includes the following examples of using SageMaker and Spark:</p><ul class="postList"><li name="f04b" id="f04b" class="graf graf--li graf-after--p">Classifying MNIST with the built-in <strong class="markup--strong markup--li-strong">XGBoost</strong> algorithm (PySpark).</li><li name="5c9c" id="5c9c" class="graf graf--li graf-after--li">Clustering MNIST with the built-in <strong class="markup--strong markup--li-strong">K-Means</strong> algorithm (PySpark and Scala).</li><li name="0b0a" id="0b0a" class="graf graf--li graf-after--li">Clustering MNIST with a <a href="https://spark.apache.org/docs/2.2.0/ml-pipeline.html" data-href="https://spark.apache.org/docs/2.2.0/ml-pipeline.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">Spark pipeline</strong></a>, running the <strong class="markup--strong markup--li-strong">PCA</strong> algorithm in MLlib and the built-in <strong class="markup--strong markup--li-strong">K-Means</strong> algorithm in SageMaker (Scala).</li></ul><p name="9abb" id="9abb" class="graf graf--p graf-after--li">Copying and pasting from web pages is unpleasant, so I did it for you. I’m happy to share these examples in <strong class="markup--strong markup--p-strong">text and Zeppelin format on </strong><a href="https://gitlab.com/juliensimon/dlnotebooks/tree/master/spark/sagemaker-spark" data-href="https://gitlab.com/juliensimon/dlnotebooks/tree/master/spark/sagemaker-spark" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Github</strong></a><strong class="markup--strong markup--p-strong">.</strong></p><blockquote name="0b33" id="0b33" class="graf graf--blockquote graf--hasDropCapModel graf-after--p"><a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-zeppelin.html" data-href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-zeppelin.html" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">Zeppelin is pre-installed on EMR</a>. Here’s how to <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-web-interfaces.html" data-href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-web-interfaces.html" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">set up remote connectivity</a> from your machine to the EMR web applications.</blockquote><p name="fb38" id="fb38" class="graf graf--p graf-after--blockquote">Just make sure you update the IAM role used in the code (account number, role name) and you’re all set. Don’t thank me: I’m just doing my job :*)</p><div name="0170" id="0170" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://github.com/juliensimon/dlnotebooks/tree/master/spark" data-href="https://github.com/juliensimon/dlnotebooks/tree/master/spark" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/juliensimon/dlnotebooks/tree/master/spark"><strong class="markup--strong markup--mixtapeEmbed-strong">juliensimon/dlnotebooks</strong><br><em class="markup--em markup--mixtapeEmbed-em">dlnotebooks - Machine Learning &amp; Deep Learning notebooks</em>github.com</a><a href="https://github.com/juliensimon/dlnotebooks/tree/master/spark" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="0c28d497215555e65872f07e493c5dbe" data-thumbnail-img-id="0*IAgrSvYRSb3de8Li." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*IAgrSvYRSb3de8Li.);"></a></div><p name="5d1a" id="5d1a" class="graf graf--p graf-after--mixtapeEmbed">I would suggest running all these examples and reading the <a href="https://readthedocs.org/projects/sagemaker-pyspark/" data-href="https://readthedocs.org/projects/sagemaker-pyspark/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">SageMaker Spark SDK documentation</strong></a> to making sure you understand the finer points. Not that there are many: this felt pretty straightforward when I did, so it shouldn’t take you long either.</p><h4 name="7ac0" id="7ac0" class="graf graf--h4 graf-after--p">Revisiting our spam classifier</h4><p name="394c" id="394c" class="graf graf--p graf-after--h4">We’ll use the exact same technique as in the previous post (shamelessly copying and pasting here, ha!).</p><blockquote name="ae81" id="ae81" class="graf graf--blockquote graf-after--p">Our raw data set is composed of <strong class="markup--strong markup--blockquote-strong">1-line messages</strong> stored in <strong class="markup--strong markup--blockquote-strong">two files</strong>:</blockquote><blockquote name="39c2" id="39c2" class="graf graf--blockquote graf-after--blockquote">- the ‘<a href="https://github.com/juliensimon/dlnotebooks/blob/master/spark/ham" data-href="https://github.com/juliensimon/dlnotebooks/blob/master/spark/ham" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener noopener" target="_blank">ham</a>’ file: 4827 valid messages,</blockquote><blockquote name="023b" id="023b" class="graf graf--blockquote graf-after--blockquote">- the ‘<a href="https://github.com/juliensimon/dlnotebooks/blob/master/spark/spam" data-href="https://github.com/juliensimon/dlnotebooks/blob/master/spark/spam" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener noopener" target="_blank">spam</a>’ file: 747 messages.</blockquote><blockquote name="cbd6" id="cbd6" class="graf graf--blockquote graf-after--blockquote">In order to classify these messages, we need to build an intermediate data set with <strong class="markup--strong markup--blockquote-strong">two classes</strong>. For this purpose, we’re going to use a simple but efficient technique called <a href="https://en.wikipedia.org/wiki/Feature_hashing" data-href="https://en.wikipedia.org/wiki/Feature_hashing" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener noopener" target="_blank"><strong class="markup--strong markup--blockquote-strong">Feature Hashing</strong></a>:</blockquote><blockquote name="b7b7" id="b7b7" class="graf graf--blockquote graf-after--blockquote">For each message in the data set, we first <strong class="markup--strong markup--blockquote-strong">hash</strong> its words into a <strong class="markup--strong markup--blockquote-strong">fixed</strong> number of buckets.</blockquote><blockquote name="d38c" id="d38c" class="graf graf--blockquote graf-after--blockquote">Then, we build a <strong class="markup--strong markup--blockquote-strong">vector</strong> indicating non-zero occurrences for each word: these are the <strong class="markup--strong markup--blockquote-strong">features</strong> that will be used to decide whether a message is spam or not.</blockquote><blockquote name="6b8e" id="6b8e" class="graf graf--blockquote graf-after--blockquote">For a valid message, the corresponding <strong class="markup--strong markup--blockquote-strong">label</strong> will be zero, i.e. the message is not spam. Accordingly, for a spam message, the label will be one.</blockquote><blockquote name="a358" id="a358" class="graf graf--blockquote graf-after--blockquote">Finally, we split the data set<strong class="markup--strong markup--blockquote-strong"> 80/20</strong> for training and validation</blockquote><p name="7124" id="7124" class="graf graf--p graf-after--blockquote">Nothing new here. I just added is a bit of clean-up: convert everything to lower case, remove all punctuation and numbers, trim white spaces. In real-life, you’d certainly want to do more (stemming, etc.).</p><figure name="5451" id="5451" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/1337dae92f0c927ef06859845ff56f84.js"></script></figure><p name="8aa5" id="8aa5" class="graf graf--p graf-after--figure">Once we’re done, the data set looks like this: each line holds a label and a feature vector.</p><figure name="276b" id="276b" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/275cc49415f0d0c2e9f54d2543deff34.js"></script></figure><h4 name="4eeb" id="4eeb" class="graf graf--h4 graf-after--figure">Training with XGBoost</h4><p name="b448" id="b448" class="graf graf--p graf-after--h4">Now we get to the good stuff: let’s use the <strong class="markup--strong markup--p-strong">high-level API</strong> in the SageMaker Spark SDK to train with XGBoost.</p><p name="8c1e" id="8c1e" class="graf graf--p graf-after--p">First, we have to convert the training set to <strong class="markup--strong markup--p-strong">libsvm</strong> format, which is what XGBoost <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html" data-href="https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">expects</a>. Fortunately, Spark has a friendly API for this.</p><blockquote name="8150" id="8150" class="graf graf--blockquote graf-after--p">Most if not all other built-in algorithms can train on protobuf data: the SageMaker Spark SDK will <strong class="markup--strong markup--blockquote-strong">automatically</strong> handle conversion between DataFrames and protobuf. XGBoost is an open-source algorithm, which is why it’s a bit different in this respect.</blockquote><p name="0d45" id="0d45" class="graf graf--p graf-after--blockquote">Then, we set up our training and prediction infrastructure in a <strong class="markup--strong markup--p-strong">single API call</strong>: this is even simpler than the regular <a href="https://github.com/aws/sagemaker-python-sdk" data-href="https://github.com/aws/sagemaker-python-sdk" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">SageMaker SDK</a>.</p><p name="2b94" id="2b94" class="graf graf--p graf-after--p">Finally, we set up hyper parameters and start training.</p><figure name="48d6" id="48d6" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/21c7e246e41947b9c4f3c01dcd2d4714.js"></script></figure><p name="2305" id="2305" class="graf graf--p graf-after--figure">This fires up our training instance from Spark and after a few minutes, voila! Our model has been trained…</p><figure name="be79" id="be79" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*BY8rRXqudWrdMpDUGmZ4qA.png" data-width="1994" data-height="914" src="https://cdn-images-1.medium.com/max/800/1*BY8rRXqudWrdMpDUGmZ4qA.png"></figure><p name="a19d" id="a19d" class="graf graf--p graf-after--figure">… and deployed.</p><figure name="de79" id="de79" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Kho_vz9y4S1Rn6PJqjTllw.png" data-width="1932" data-height="472" src="https://cdn-images-1.medium.com/max/800/1*Kho_vz9y4S1Rn6PJqjTllw.png"></figure><p name="c4d4" id="c4d4" class="graf graf--p graf-after--figure">Isn’t this the <strong class="markup--strong markup--p-strong">simplest</strong> integration ever? :) If you needed to train on 100 instances, things wouldn’t be any different.</p><h4 name="1283" id="1283" class="graf graf--h4 graf-after--p">Predicting with XGBoost</h4><p name="e588" id="e588" class="graf graf--p graf-after--h4">Predicting is simple too: we just need convert the test data set to libsvm and predict.</p><figure name="a189" id="a189" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/dc43521368c3cd50dca10fc0aa5bd0ba.js"></script></figure><p name="f2e0" id="f2e0" class="graf graf--p graf-after--figure">Here’s what the predicted data and the accuracy look like.</p><figure name="1fe7" id="1fe7" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/5105eeb63fc618ec953626d661e30b8b.js"></script></figure><p name="6210" id="6210" class="graf graf--p graf-after--figure">What about the EMR cluster? Well, it didn’t even blink. It takes more than this tiny data set to put four m4.2xlarge instances to work :)</p><figure name="4cb6" id="4cb6" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*it_uSHlDmYpfBdzRyhwMgw.png" data-width="1728" data-height="924" src="https://cdn-images-1.medium.com/max/800/1*it_uSHlDmYpfBdzRyhwMgw.png"></figure><p name="a7bc" id="a7bc" class="graf graf--p graf-after--figure">Still, you could be processing <strong class="markup--strong markup--p-strong">huge data sets</strong> in exactly the same way:</p><ul class="postList"><li name="5343" id="5343" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">ETL</strong> at scale on Spark,</li><li name="51db" id="51db" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Store</strong> processed data in <em class="markup--em markup--li-em">DataFrames</em> or in S3,</li><li name="4b26" id="4b26" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Train</strong> at scale on SageMaker, possibly using one of the so-called “<a href="https://www.allthingsdistributed.com/2018/03/Infinitely-scalable-machine-learning-with-Amazon-SageMaker.html" data-href="https://www.allthingsdistributed.com/2018/03/Infinitely-scalable-machine-learning-with-Amazon-SageMaker.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">infinitely scalable algorithms</a>” (my <a href="https://www.youtube.com/watch?v=IeIUr78OrE0" data-href="https://www.youtube.com/watch?v=IeIUr78OrE0" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">session from the Tel Aviv Summit</a> will also tell you more).</li><li name="aaa3" id="aaa3" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Deploy</strong> at scale on SageMaker with <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling.html" data-href="https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">auto scaling</a>.</li></ul><p name="183d" id="183d" class="graf graf--p graf-after--li">You don’t usually get the best of both worlds in life (most of us would settle for the best of *one* world, right?). However, when it comes to analytics at scale, this Spark-SageMaker combo has <strong class="markup--strong markup--p-strong">a lot</strong> going for it.</p><p name="1351" id="1351" class="graf graf--p graf-after--p">Very curious to see what you will build with this, so go and <strong class="markup--strong markup--p-strong">shake the universe</strong>, my friends!</p><p name="e64e" id="e64e" class="graf graf--p graf-after--p graf--trailing">That’s it for today. As always, thank you for reading. Happy to answer questions here or on <a href="https://twitter.com/julsimon/" data-href="https://twitter.com/julsimon/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Twitter</a>.</p></div></div></section><section name="7668" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="9514" id="9514" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">I guess this advice also stands for analytics at scale \m/</em></p><figure name="0273" id="0273" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/CTt1vk9nM9c?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/8bd780b07243"><time class="dt-published" datetime="2018-05-08T20:24:53.101Z">May 8, 2018</time></a>.</p><p><a href="https://medium.com/@julsimon/apache-spark-and-amazon-sagemaker-the-infinity-gems-of-analytics-8bd780b07243" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
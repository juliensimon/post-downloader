<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Deploying SuperNova-Lite on Inferentia2: the best 8B model for $1 an hour!</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Deploying SuperNova-Lite on Inferentia2: the best 8B model for $1 an hour!</h1>
</header>
<section data-field="subtitle" class="p-summary">
In this video, you will learn about Llama-3.1-SuperNova-Lite, the best open-source 8B model available today according to the Hugging Face…
</section>
<section data-field="body" class="e-content">
<section name="f244" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="7f18" id="7f18" class="graf graf--h3 graf--leading graf--title">Deploying SuperNova-Lite on Inferentia2: the best 8B model for $1 an hour!</h3><p name="9c68" id="9c68" class="graf graf--p graf-after--h3">In this video, you will learn about <a href="https://huggingface.co/arcee-ai/Llama-3.1-SuperNova-Lite" data-href="https://huggingface.co/arcee-ai/Llama-3.1-SuperNova-Lite" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Llama-3.1-SuperNova-Lite</a>, the best open-source 8B model available today according to the <a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard" data-href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Hugging Face Open LLM Leaderboard</a>.</p><figure name="72eb" id="72eb" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*GhJip1BfIars8AuHSCz-MQ.png" data-width="1906" data-height="1072" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*GhJip1BfIars8AuHSCz-MQ.png"></figure><p name="7e62" id="7e62" class="graf graf--p graf-after--figure">Llama-3.1-SuperNova-Lite is an 8B parameter model developed by Arcee.ai, based on the Llama-3.1–8B-Instruct architecture. It is a distilled version of the larger Llama-3.1–405B-Instruct model, leveraging offline logits extracted from the 405B parameter variant. This 8B variation of Llama-3.1-SuperNova maintains high performance while offering exceptional instruction-following capabilities and domain-specific adaptability.</p><p name="3f6c" id="3f6c" class="graf graf--p graf-after--p">I’ll show you how to compile on the fly and deploy SuperNova Lite on a SageMaker endpoint powered by an inf2.xlarge instance, the smallest Inferentia2 instance available at only $0.99 an hour!</p><figure name="b043" id="b043" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/eaO_4nqrBbs?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/68b3f08f9ab0"><time class="dt-published" datetime="2024-09-19T13:42:35.501Z">September 19, 2024</time></a>.</p><p><a href="https://medium.com/@julsimon/deploying-supernova-lite-on-inferentia2-the-best-8b-model-for-1-an-hour-68b3f08f9ab0" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>

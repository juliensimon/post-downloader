<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Training with PyTorch on Amazon SageMaker</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Training with PyTorch on Amazon SageMaker</h1>
</header>
<section data-field="subtitle" class="p-summary">
PyTorch is a flexible open source framework for Deep Learning experimentation. In this post, you will learn how to train PyTorch jobs on…
</section>
<section data-field="body" class="e-content">
<section name="b86f" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="db4c" id="db4c" class="graf graf--h3 graf--leading graf--title">Training with PyTorch on Amazon SageMaker</h3><p name="a226" id="a226" class="graf graf--p graf-after--h3"><a href="https://pytorch.org/" data-href="https://pytorch.org/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">PyTorch</strong></a> is a flexible open source framework for Deep Learning experimentation. In this post, you will learn how to train PyTorch jobs on <a href="https://aws.amazon.com/sagemaker" data-href="https://aws.amazon.com/sagemaker" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon SageMaker</strong></a>. I’ll show you how to:</p><ul class="postList"><li name="292e" id="292e" class="graf graf--li graf-after--p">build a <strong class="markup--strong markup--li-strong">custom Docker container</strong> for CPU and GPU training,</li><li name="1e62" id="1e62" class="graf graf--li graf-after--li">pass <strong class="markup--strong markup--li-strong">parameters</strong> to a PyTorch script,</li><li name="b576" id="b576" class="graf graf--li graf-after--li">save the <strong class="markup--strong markup--li-strong">trained model</strong>.</li></ul><p name="b79f" id="b79f" class="graf graf--p graf-after--li">As usual, you’ll find my code on <a href="https://github.com/juliensimon/dlnotebooks/tree/master/pytorch/01-custom-container" data-href="https://github.com/juliensimon/dlnotebooks/tree/master/pytorch/01-custom-container" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Github</a> :)</p><figure name="c4d3" id="c4d3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*_f9fpdvqnbww5_GG.jpg" data-width="720" data-height="497" src="https://cdn-images-1.medium.com/max/800/0*_f9fpdvqnbww5_GG.jpg"><figcaption class="imageCaption">Uruks train PyTorch on SageMaker. That’s a fact.</figcaption></figure><h3 name="221f" id="221f" class="graf graf--h3 graf-after--figure">Building a custom container</h3><p name="1a66" id="1a66" class="graf graf--p graf-after--h3">SageMaker provides a collection of <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html" data-href="https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">built-in algorithms</a> as well as environments for TensorFlow and MXNet… but not for PyTorch. Fortunately, developers have the option to <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html" data-href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">build custom containers for training and prediction</a>.</p><p name="6b17" id="6b17" class="graf graf--p graf-after--p">Obviously, a number of <strong class="markup--strong markup--p-strong">conventions</strong> need to be defined for SageMaker to successfully invoke a custom container:</p><ul class="postList"><li name="cae4" id="cae4" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Name of the training and prediction scripts</strong>: by default, they should respectively be set to ‘<em class="markup--em markup--li-em">train</em>’ and ‘<em class="markup--em markup--li-em">serve</em>’, be executable and have no extension. SageMaker will start training by running ‘<em class="markup--em markup--li-em">docker run your_container train</em>’.</li><li name="2487" id="2487" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Location of hyper parameters </strong>in the container: <em class="markup--em markup--li-em">/opt/ml/input/config/hyperparameters.json</em>.</li><li name="6a68" id="6a68" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Location of input data parameters </strong>in the container: <em class="markup--em markup--li-em">/opt/ml/input/data</em>.</li></ul><p name="46f5" id="46f5" class="graf graf--p graf-after--li">This will require some changes in our PyTorch script, the well-known example of <a href="https://github.com/pytorch/examples/blob/master/mnist/main.py" data-href="https://github.com/pytorch/examples/blob/master/mnist/main.py" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">learning MNIST with a simple CNN</a>. As you will see in a moment, they are quite minor and you won’t have any trouble adding them to your own code.</p><h4 name="43b6" id="43b6" class="graf graf--h4 graf-after--p">Building a Docker container</h4><p name="aa4d" id="aa4d" class="graf graf--p graf-after--h4">Here’s the <strong class="markup--strong markup--p-strong">Docker file</strong>.</p><figure name="6c3b" id="6c3b" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/24713fec3b336ba314d29f8cc7f77f43.js"></script></figure><p name="57aa" id="57aa" class="graf graf--p graf-after--figure">We start from the <strong class="markup--strong markup--p-strong">CUDA 9.0 image</strong>, which is also based on Ubuntu 16.04. This one has all the CUDA libraries that PyTorch needs. We then add <strong class="markup--strong markup--p-strong">Python 3</strong> and the PyTorch packages.</p><blockquote name="f242" id="f242" class="graf graf--blockquote graf-after--p">Unlike MXNet, PyTorch comes in a single package that support both CPU and GPU training.</blockquote><p name="7aa3" id="7aa3" class="graf graf--p graf-after--blockquote">Once this is done, we clean up various caches to shrink the container size a bit. Then, we copy the <strong class="markup--strong markup--p-strong">PyTorch script</strong> to <em class="markup--em markup--p-em">/opt/program</em> with the proper name (‘<em class="markup--em markup--p-em">train</em>’) and we make it executable.</p><blockquote name="8ff0" id="8ff0" class="graf graf--blockquote graf-after--p">For more flexibility, we could write a generic launcher that would fetch the actual training script from an S3 location passed as an hyper parameter. This is left as an exercise for the reader ;)</blockquote><p name="5a63" id="5a63" class="graf graf--p graf-after--blockquote">Finally, we set the directory of our script as the <strong class="markup--strong markup--p-strong">work directory</strong> and add it to the <strong class="markup--strong markup--p-strong">path</strong>.</p><p name="7214" id="7214" class="graf graf--p graf-after--p">It’s not a long file, but as usual with these things, every detail counts.</p><h4 name="8f5c" id="8f5c" class="graf graf--h4 graf-after--p">Creating a Docker repository in Amazon ECR</h4><p name="753a" id="753a" class="graf graf--p graf-after--h4">SageMaker requires that the containers it fetches are hosted in <a href="http://aws.amazon.com/ecr" data-href="http://aws.amazon.com/ecr" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Amazon ECR</strong></a>. Let’s create a repo and login to it.</p><figure name="c801" id="c801" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/08388e7358a618e62f92de1d409f6808.js"></script></figure><h4 name="2ca1" id="2ca1" class="graf graf--h4 graf-after--figure">Building and pushing our containers to ECR</h4><p name="c21d" id="c21d" class="graf graf--p graf-after--h4">OK, now it’s time to build both containers and push them to their repos. We’ll do this separately for the CPU and GPU versions. Strictly Docker stuff. Please refer to the notebook for details on variables.</p><figure name="da51" id="da51" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/edb9fedb661479a9db77c21fbddd9ed6.js"></script></figure><p name="8b48" id="8b48" class="graf graf--p graf-after--figure">Once we’re done, things should look like this and you should also see your container in ECR.</p><figure name="5102" id="5102" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*exUS1tuc2MjBwrt4vsXjeg.png" data-width="1866" data-height="132" src="https://cdn-images-1.medium.com/max/800/1*exUS1tuc2MjBwrt4vsXjeg.png"></figure><p name="19eb" id="19eb" class="graf graf--p graf-after--figure">The Docker part is over. Now let’s configure our training job in SageMaker.</p><h3 name="4ccd" id="4ccd" class="graf graf--h3 graf-after--p">Configuring the training job</h3><p name="2181" id="2181" class="graf graf--p graf-after--h3">This is actually quite underwhelming, which is great news: <strong class="markup--strong markup--p-strong">nothing really differs from training with a built-in algorithm!</strong></p><p name="2653" id="2653" class="graf graf--p graf-after--p">First we need to <strong class="markup--strong markup--p-strong">upload the MNIST data set</strong> from our local machine to S3. We’ve done this many times before, nothing new here.</p><figure name="0339" id="0339" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/c105a2d19ef6357253e1223bf2e50dae.js"></script></figure><p name="ddf7" id="ddf7" class="graf graf--p graf-after--figure">Then, we configure the training job by:</p><ul class="postList"><li name="d140" id="d140" class="graf graf--li graf-after--p">selecting one of the containers we just built and setting the usual parameters for SageMaker <a href="https://sagemaker.readthedocs.io/en/latest/estimators.html" data-href="https://sagemaker.readthedocs.io/en/latest/estimators.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--li-strong">estimators,</strong></a></li><li name="b235" id="b235" class="graf graf--li graf-after--li">passing <strong class="markup--strong markup--li-strong">hyper parameters</strong> to the PyTorch script.</li><li name="f40e" id="f40e" class="graf graf--li graf-after--li">passing <strong class="markup--strong markup--li-strong">input data</strong> to the PyTorch script.</li></ul><blockquote name="85c8" id="85c8" class="graf graf--blockquote graf-after--li">Unlike Keras, PyTorch has <a href="https://pytorch.org/docs/master/cuda.html" data-href="https://pytorch.org/docs/master/cuda.html" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">APIs</a> to check if CUDA is available and to detect how many GPUs are available. Thus, we don’t need to pass this information in an hyper parameter. <a href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html" data-href="https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">Multi-GPU training</a> is also possible but requires extra work: MXNet makes it <a href="https://mxnet.incubator.apache.org/faq/multi_devices.html" data-href="https://mxnet.incubator.apache.org/faq/multi_devices.html" class="markup--anchor markup--blockquote-anchor" rel="noopener" target="_blank">much simpler</a>.</blockquote><figure name="6f6e" id="6f6e" class="graf graf--figure graf--iframe graf-after--blockquote"><script src="https://gist.github.com/juliensimon/a93769c712b522765bc5c08a2408bb7a.js"></script></figure><p name="cea8" id="cea8" class="graf graf--p graf-after--figure">That’s it for training. The last part we’re missing is adapting our PyTorch script for SageMaker. Let’s get to it.</p><h3 name="1286" id="1286" class="graf graf--h3 graf-after--p">Adapting the PyTorch script for SageMaker</h3><p name="62c6" id="62c6" class="graf graf--p graf-after--h3">We need to take care of hyper parameters, input data, multi-GPU configuration, loading the data set and saving models.</p><h4 name="6d28" id="6d28" class="graf graf--h4 graf-after--p">Passing hyper parameters and input data configuration</h4><p name="306a" id="306a" class="graf graf--p graf-after--h4">As mentioned earlier, SageMaker copies hyper parameters to <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">/opt/ml/input/config/hyperparameters.json</em></strong>. All we have to do is read this file, extract parameters and set default values if needed.</p><figure name="d9dd" id="d9dd" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/003c0f78a095fd7d8049a20f549f3477.js"></script></figure><p name="934c" id="934c" class="graf graf--p graf-after--figure">In a similar fashion, SageMaker copies the input data configuration to <em class="markup--em markup--p-em">/opt/ml/input/data. </em>We’ll handle things in exactly the same way.</p><blockquote name="1d93" id="1d93" class="graf graf--blockquote graf--hasDropCapModel graf-after--p">In this example, I don’t need this configuration info, but this is how you’d read it if you did :)</blockquote><h4 name="1dbd" id="1dbd" class="graf graf--h4 graf-after--blockquote">Loading the training and validation set</h4><p name="9f98" id="9f98" class="graf graf--p graf-after--h4">When training in file mode (which is the case here), SageMaker <strong class="markup--strong markup--p-strong">automatically</strong> copies the data set to <em class="markup--em markup--p-em">/opt/ml/input/&lt;channel_name&gt;</em>: here, we defined the <em class="markup--em markup--p-em">train</em> and <em class="markup--em markup--p-em">validation</em> channels, so we’ll have to:</p><ul class="postList"><li name="44f4" id="44f4" class="graf graf--li graf-after--p">read the MNIST files from the corresponding directories,</li><li name="0a5d" id="0a5d" class="graf graf--li graf-after--li">build <a href="https://pytorch.org/docs/master/data.html" data-href="https://pytorch.org/docs/master/data.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><em class="markup--em markup--li-em">DataSet</em></a> objects for the training and validation set,</li><li name="bfaf" id="bfaf" class="graf graf--li graf-after--li">load them using the <a href="https://pytorch.org/docs/master/data.html" data-href="https://pytorch.org/docs/master/data.html" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank"><em class="markup--em markup--li-em">DataLoader</em></a> object.</li></ul><figure name="e439" id="e439" class="graf graf--figure graf--iframe graf-after--li"><script src="https://gist.github.com/juliensimon/6bb0bfeabeb7e0e85b1a86bfafb1ca11.js"></script></figure><h4 name="9b98" id="9b98" class="graf graf--h4 graf-after--figure">Saving the model</h4><p name="031b" id="031b" class="graf graf--p graf-after--h4">The very last thing we need to do once training is complete is to save the model in <strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">/opt/ml/model: </em></strong>SageMaker will grab all artefacts present in this directory, build a file called <em class="markup--em markup--p-em">model.tar.gz</em> and copy it to the S3 bucket used by the training job.</p><figure name="fcf9" id="fcf9" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/15eb65e539ade151990b33d5c83e8a11.js"></script></figure><p name="1bda" id="1bda" class="graf graf--p graf-after--figure">That’s it. As you can see, it’s all about interfacing your script with SageMaker input and output. The bulk of your PyTorch code doesn’t require any modification.</p><h3 name="0f95" id="0f95" class="graf graf--h3 graf-after--p">Running the script</h3><p name="7de9" id="7de9" class="graf graf--p graf-after--h3">Alright, let’s run this on a <strong class="markup--strong markup--p-strong">p3.2xlarge</strong> instance.</p><figure name="f403" id="f403" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/juliensimon/aa182bb4bd2da4510f4c6460f0c4143b.js"></script></figure><p name="57be" id="57be" class="graf graf--p graf-after--figure">Let’s check the <strong class="markup--strong markup--p-strong">S3 bucket</strong>.</p><pre name="1639" id="1639" class="graf graf--pre graf-after--p">$ <strong class="markup--strong markup--pre-strong">aws</strong> s3 ls $BUCKET/pytorch/output/pytorch-mnist-cnn-2018-06-02-08-16-11-355/output/<br>2018-06-02 08:20:28      86507 model.tar.gz<br>$ <strong class="markup--strong markup--pre-strong">aws</strong> s3 cp $BUCKET/pytorch/output/pytorch-mnist-cnn-2018-06-02-08-16-11-355/output/ .<br>$ <strong class="markup--strong markup--pre-strong">tar</strong> tvfz model.tar.gz<br>-rw-r--r-- 0/0   99436 2018-06-02 08:20 mnist-cnn-10.pt</pre><p name="3d40" id="3d40" class="graf graf--p graf-after--pre">Pretty cool, right? We can now use this model <strong class="markup--strong markup--p-strong">anywhere</strong> we like.</p><p name="ca57" id="ca57" class="graf graf--p graf-after--p">That’s it for today. Another (hopefully) nice example of using SageMaker to <strong class="markup--strong markup--p-strong">train your custom jobs on fully-managed infrastructure</strong>!</p><p name="6890" id="6890" class="graf graf--p graf-after--p graf--trailing">Happy to answer questions here or on <a href="https://twitter.com/julsimon" data-href="https://twitter.com/julsimon" class="markup--anchor markup--p-anchor" rel="noopener nofollow noopener noopener nofollow noopener noopener noopener noopener noopener noopener" target="_blank">Twitter</a>. For more content, please feel free to check out my <a href="https://www.youtube.com/juliensimonfr" data-href="https://www.youtube.com/juliensimonfr" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener noopener nofollow noopener noopener noopener noopener noopener noopener" target="_blank">YouTube channel</a>.</p></div></div></section><section name="853e" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="3e64" id="3e64" class="graf graf--p graf--leading"><em class="markup--em markup--p-em">Obvious choice ;)</em></p><figure name="300d" id="300d" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/M_KTlSbaVUU?feature=oembed" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@julsimon" class="p-author h-card">Julien Simon</a> on <a href="https://medium.com/p/58fca8c69987"><time class="dt-published" datetime="2018-06-04T07:42:23.660Z">June 4, 2018</time></a>.</p><p><a href="https://medium.com/@julsimon/training-with-pytorch-on-amazon-sagemaker-58fca8c69987" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 26, 2025.</p></footer></article></body></html>
<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Apache MXNet as a backend for Keras 2</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="06c7">Apache MXNet as a backend for Keras 2</h3><p id="7ba5">In a previous post, we saw how <a href="https://mxnet.incubator.apache.org/" target="_blank"><strong class="markup--p-strong">Apache MXNet</strong></a> could be used as backend for <strong class="markup--p-strong">Keras 1.2</strong> — and how fast it was.</p><div class="graf--mixtapeEmbed" id="bcb6"><a class="markup--mixtapeEmbed-anchor" href="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0" title="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0"><strong class="markup--mixtapeEmbed-strong">Keras shoot-out: TensorFlow vs MXNet</strong><br/><em class="markup--mixtapeEmbed-em">A few months, we took an early look at running Keras with Apache MXNet as its backend. Things were pretty beta at the…</em>medium.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="e1f3e16b2a79ed0f75ee2660509c9131" data-thumbnail-img-id="1*1VZzy-6pi_CNZpL0UfwHKQ.jpeg" href="https://medium.com/@julsimon/keras-shoot-out-tensorflow-vs-mxnet-51ae2b30a9c0" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*1VZzy-6pi_CNZpL0UfwHKQ.jpeg);"></a></div><p class="graf-after--mixtapeEmbed" id="0f61">Lo and behold, you can now use it with <strong class="markup--p-strong">Keras 2</strong> (with some restrictions). This is great news both for the Keras community and for the MXNet community, so how about a collective thumbs up to <a href="https://github.com/sandeep-krishnamurthy" target="_blank">@sandeep-krishnamurthy</a>, <a href="https://github.com/jiajiechen" target="_blank">@jiajiechen</a>, <a href="https://github.com/karan6181" target="_blank">@karan6181</a>, <a href="https://github.com/roywei" target="_blank">@roywei</a>, <a href="https://github.com/kalyc" target="_blank">@kalyc</a> for their contribution.</p><p id="ed71">This post will show how you how to install this version of Keras, tell you what is supported and what isn’t at the moment and of course how to run your trainings faster by using multiple GPUs.</p><figure id="0e0a"><img class="graf-image" src="image01.webp"/><figcaption>Yeah, it’s a bit of an upgrade.</figcaption></figure><h3 id="b6fa">Installation</h3><p id="683b">Let’s fire up an EC2 instance with the <a href="https://aws.amazon.com/machine-learning/amis/" target="_blank">Deep Learning AMI</a>. I’ll use the Conda version which lets us easily manage different Python environments… and avoid making a huge mess of everything ;)</p><pre class="graf--pre" id="4b7a">$ conda create -n mxnet-keras<br/>$ source activate mxnet-keras<br/>$ pip3 install mxnet-cu90 --upgrade<br/>$ pip3 install keras-mxnet --upgrade<br/>$ python3<br/>&gt;&gt;&gt; import mxnet, keras<br/>&gt;&gt;&gt; print ("%s %s" % (mxnet.__version__, keras.__version__))<br/>1.2.0 2.1.6</pre><p class="graf-after--pre" id="5a3d">Good. Now let’s make sure that MXNet is actually set as the backend for Keras.</p><pre class="graf--pre" id="1126">$ cat ~/.keras/keras.json<br/>{<br/>"backend": "mxnet",<br/>"image_data_format": "channels_first"<br/>}</pre><p class="graf-after--pre" id="9940">Setting ‘<em class="markup--p-em">image_data_format</em>’ to ‘<em class="markup--p-em">channels_first</em>’ will make MXNet training faster. When working with image data, the input shape can either be ‘<em class="markup--p-em">channels_first</em>’, i.e. (number of channels, height, width), or ‘<em class="markup--p-em">channels_last</em>’, i.e. (height, width, number of channels).</p><blockquote class="graf--blockquote" id="4548">For MNIST, this would either be (1, 28, 28) or (28, 28, 1) : one channel (black and white pictures), 28 pixels by 28 pixels. For ImageNet, it would be (3, 224, 224) or (224, 224, 3): three channels (red, green and blue), 224 pixels by 224 pixels.</blockquote><p class="graf-after--blockquote" id="ccc5">We’re ready to play!</p><h3 id="1cda">Supported features</h3><p id="4c63">This is still work in progress. You can check the <a href="https://github.com/awslabs/keras-apache-mxnet/releases" target="_blank">super detailed release notes</a> (great work, team) to see what’s supported and what isn’t.</p><p id="7f04">In a nutshell (copying from the releases notes):</p><pre class="graf--pre" id="bcb0">- Supports <strong class="markup--pre-strong">Convolutional Neural Network</strong> (CNN) and <strong class="markup--pre-strong">experimental Recurrent Neural Network</strong> (RNN) training and inference.</pre><pre class="graf--pre graf-after--pre" id="2660">- Supports high performance, distributed <a class="markup--pre-anchor" href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/multi_gpu_training.md" target="_blank"><strong class="markup--pre-strong">Multi-GPU training</strong></a> of CNN and RNN networks.</pre><pre class="graf--pre graf-after--pre" id="f5d8">- Supports <a class="markup--pre-anchor" href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/save_mxnet_model.md" target="_blank"><strong class="markup--pre-strong">exporting native MXNet Model from Keras-MXNet</strong></a> trained model. Enabling faster research with Keras interface and high performance, large scale inference in production with the native MXNet engine. You can use all language bindings of MXNet (Scala/Python/Julia/R/Perl) for inference on the exported model.</pre><pre class="graf--pre graf-after--pre" id="955a">- Add <a class="markup--pre-anchor" href="https://github.com/awslabs/keras-apache-mxnet/tree/master/benchmark#setup" target="_blank"><strong class="markup--pre-strong">Keras benchmarking utility</strong></a> for performing CNN and RNN benchmarks with standard networks and datasets. Supports benchmarking on CPU, one GPU and multi-GPU distributed training.</pre><p class="graf-after--pre" id="36e8">A few comments:</p><ul class="postList"><li id="39eb">Of course, <strong class="markup--li-strong">multi-GPU trainin</strong>g is extremely important. We’ll see in a second how easy it is to add it to any existing Keras script.</li><li id="c4f5">Using Keras with MXNet brings a <strong class="markup--li-strong">major performance boost</strong> over other backends. <a href="https://github.com/awslabs/keras-apache-mxnet/tree/master/benchmark" target="_blank">Detailed benchmarks</a> are available, they’re most definitely worth a read ;)</li><li id="f8fd">The third point is <strong class="markup--li-strong">extremely</strong> important IMHO. You can use <strong class="markup--li-strong">Keras for fast experimentation</strong>, possibly reusing or tweaking models from the vast collection that is available out there. Then, you can export it as a native MXNet model and use it in <strong class="markup--li-strong">production with MXNet only</strong>, which will speed things up further because MXNet is implemented in <strong class="markup--li-strong">C++</strong>. Very useful feature. You’ll find a complete example <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/docs/mxnet_backend/save_mxnet_model.md" target="_blank">here</a>.</li></ul><h3 id="9f6a">Multi-GPU training</h3><p id="5ac8">In the Keras 1.2 version, this was available by building an MXNet-style context.</p><pre class="graf--pre" id="af32">NUM_GPU = 4<br/>gpu_list = []                       <br/>for i in range(NUM_GPU): <br/>    gpu_list.append('gpu(%d)' % i)                                               </pre><pre class="graf--pre graf-after--pre" id="36c3">model.compile(<br/>   loss='categorical_crossentropy',                            <br/>   optimizer=SGD(),                        <br/>   metrics=['accuracy'],                        <br/>   context=gpu_list)</pre><p class="graf-after--pre" id="f2c9">Now all we have to do is:</p><pre class="graf--pre" id="55bc">from keras.utils import multi_gpu_model<br/>...<br/>model = multi_gpu_model(model, gpus=4)<br/>model.compile(loss='categorical_crossentropy',<br/>              optimizer=SGD(),<br/>              metrics=['accuracy'])</pre><p class="graf-after--pre" id="0ec2">This is definitely more convenient. Just wrap the model with <em class="markup--p-em">multi_gpu_model()</em> before compiling it and voila!</p><h3 id="5e66">Example</h3><p id="8d85">Using a p3.16xlarge instance, let’s clone the <a href="https://github.com/awslabs/keras-apache-mxnet" target="_blank"><strong class="markup--p-strong">keras-mxnet</strong></a> repo.</p><pre class="graf--pre" id="fe5c">$ git clone https://github.com/awslabs/keras-apache-mxnet.git</pre><p class="graf-after--pre" id="21c2">First, we’re going to run the <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/cifar10_resnet.py" target="_blank"><em class="markup--p-em">cifar10_resnet.py</em></a> script, which trains ResNet20v1 on the CIFAR-10 data set. Unsurprisingly, we only use a single GPU ;)</p><figure id="c967"><img class="graf-image" src="image03.webp"/></figure><p id="d705">One epoch takes <strong class="markup--p-strong">1309 seconds</strong> (almost 22 minutes).</p><pre class="graf--pre" id="7aa4">1563/1563 [==============================] - 1309s 838ms/step - loss: 1.6875 - acc: 0.4412 - val_loss: 1.7708 - val_acc: 0.4323</pre><p class="graf-after--pre" id="bb27">Now, let’s run <a href="https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/cifar10_resnet_multi_gpu.py" target="_blank"><em class="markup--p-em">cifar10_resnet_multi_gpu.py</em></a> script on 8 GPUs :) All it takes is adding the couple of lines mentioned above.</p><figure id="009e"><img class="graf-image" src="image02.webp"/><figcaption>Oh yesssss. My preciousss.</figcaption></figure><p id="c75a">One epoch now takes <strong class="markup--p-strong">190 seconds</strong>.</p><pre class="graf--pre" id="4c10">1563/1563 [==============================] - 190s 122ms/step - loss: 1.2006 - acc: 0.6315 - val_loss: 1.2958 - val_acc: 0.61</pre><p class="graf-after--pre" id="da87">1309/190 = 6.88. Not quite 8x speedup, but pretty close!</p><p id="b221">That’s it for today. I’m really excited about the combination of Keras and MXNet. Flexibility and speed! <strong class="markup--p-strong">Please give it a try.</strong></p><p id="6890">Happy to answer questions here or on <a href="https://twitter.com/julsimon" rel="noopener nofollow noopener noopener nofollow noopener noopener noopener" target="_blank">Twitter</a>. For more content, please feel free to check out my <a href="https://www.youtube.com/juliensimonfr" rel="nofollow noopener noopener noopener nofollow noopener noopener noopener" target="_blank">YouTube channel</a>.</p></div></div></section>
</section>
</article></body></html>
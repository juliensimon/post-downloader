<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Using Chalice to serve SageMaker predictions</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="8e8f">Using Chalice to serve SageMaker predictions</h3><p id="e418"><a href="https://aws.amazon.com/sagemaker" target="_blank"><strong class="markup--p-strong">Amazon SageMaker</strong></a> makes it easy to train and deploy Machine Learning models hosted on HTTP endpoints. However, in most cases you won’t expose these endpoints directly. <strong class="markup--p-strong">Pre-processing </strong>and<strong class="markup--p-strong"> post-processing steps</strong> are likely to be required: authentication, throttling, data transformation and enrichment, logging, etc.</p><p id="32a4">In this post, we will use <a href="https://github.com/aws/chalice" target="_blank"><strong class="markup--p-strong">AWS Chalice</strong></a> to build a <strong class="markup--p-strong">web service acting as a front-end for a SageMaker endpoint</strong>.</p><p id="4f2e">Let’s get started.</p><figure id="bd1a"><img class="graf-image" src="image01.webp"/><figcaption>Oh, you’re the front-end service, I suppose.</figcaption></figure><h4 id="c43d">Training and deploying our SageMaker model</h4><p id="1bdb">I’ve already written a couple of posts (<a href="https://medium.com/@julsimon/building-a-movie-recommender-with-factorization-machines-on-amazon-sagemaker-cedbfc8c93d8" target="_blank">here</a> and <a href="https://medium.com/@julsimon/image-classification-on-amazon-sagemaker-9b66193c8b54" target="_blank">here</a>) on training and deploying SageMaker models, so I won’t go into these details again. For our purpose, we’ll use the <strong class="markup--p-strong">built-in algorithm for image classification</strong> to train a model on the <a href="https://authors.library.caltech.edu/7694/" target="_blank"><strong class="markup--p-strong">Caltech-256</strong></a> data set, as presented in this <a href="https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-transfer-learning.ipynb" target="_blank"><strong class="markup--p-strong">tutorial</strong></a>.</p><p id="3ba6">Once training and deployment are complete, the endpoint is ready for prediction.</p><figure id="ca32"><script src="https://gist.github.com/juliensimon/df5b4102c719db18d82724fbc3e2a7a9.js"></script></figure><h4 id="691d">Invoking a SageMaker model</h4><p id="4700">First, we need to figure out what data format the algo expects: as explained in the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html" target="_blank">documentation</a>, we need to post <strong class="markup--p-strong">binary data with the <em class="markup--p-em">application/x-image</em> content type</strong>.</p><p id="5bbc">We’ll do this with the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_runtime_InvokeEndpoint.html" target="_blank"><strong class="markup--p-strong"><em class="markup--p-em">InvokeEndpoint</em></strong></a> API, which you’ll find it in your favourite AWS SDK: we simply need to provide an <strong class="markup--p-strong">endpoint name</strong> and of course the <strong class="markup--p-strong">body</strong>.</p><blockquote class="graf--blockquote" id="bd07">AWS CLI users: don’t be confused if you don’t see it InvokeEndpoint in the list of SageMaker APIs: it’s in ‘sagemaker-runtime’, not in ‘sagemaker’</blockquote><p class="graf-after--blockquote" id="3c11">Here’s an example with <a href="https://github.com/boto/boto3" target="_blank"><strong class="markup--p-strong">boto3</strong></a>.</p><figure id="161a"><script src="https://gist.github.com/juliensimon/41d6348bdd1eac956b35feafbc638347.js"></script></figure><pre class="graf--pre" id="ad26">$ python invoke.py<br/>b'[1.4174277566780802e-05, 1.6996695194393396e-05, 0.00011234339035581797, 0.0002156866539735347, 3.110157194896601e-05, 0.00025752029614523053, 2.8299189580138773e-05, 0.00012142073683207855, 9.117752779275179e-05, 4.787529178429395e-05, 3.5472228773869574e-05, 0.00019932845316361636, 5.5317421356448904e-05, 6.963817668292904e-06, 4.422592246555723e-05, 9.264561231248081e-05, 2.4938033675425686e-05, 0.0002587089838925749, 0.00026409601559862494, 1.0121700142917689e-05, 0.0038431661669164896, 2.7548372599994764e-05, 3.41928462148644e-05, 7.225569424917921e-05, 1.1924025784537662e-05, 7.16273789294064e-05, 0.000851281511131674, 3.8102120015537366e-05, 8.411310773226433e-06, [output removed]</pre><p class="graf-after--pre" id="0145">OK, this worked. The response contains <strong class="markup--p-strong">257 probabilities</strong>, <strong class="markup--p-strong">one for each of the CalTech-256 categories</strong> (256 object categories plus a catch-all category). As our image represents a floppy disk (category #75), the highest probability is the 74th one. You can check if you feel like it :)</p><p id="51e7">Now, it’s time to write a <strong class="markup--p-strong">front-end web service</strong> for this endpoint.</p><h4 id="966f">A quick recap on Chalice</h4><p id="60ce">Chalice is an <strong class="markup--p-strong">AWS Open Source project</strong> that lets developers build <strong class="markup--p-strong">Python-based web services</strong> with minimal fuss. The programming model is extremely close to <a href="http://flask.pocoo.org/" target="_blank"><strong class="markup--p-strong">Flask</strong></a>, so you should feel right at home. Installation is a breeze (<em class="markup--p-em">pip install chalice</em>) and the CLI is idiot-proof (*I* can use it).</p><p id="9157">Simple services require <strong class="markup--p-strong">very little configuration</strong>, if any. Based on the boto3 calls in your code, <strong class="markup--p-strong">Chalice generates an IAM policy</strong> which will be attached to the Lambda function’s role. You’ll generally want to tweak it a bit, but it’s a nice starting point and a <strong class="markup--p-strong">great time save</strong>r. You can also bring <strong class="markup--p-strong">your own policy </strong>(which we’ll do later on).</p><p id="8458">You can add <strong class="markup--p-strong">Python dependencies</strong> by listing them in the <strong class="markup--p-strong"><em class="markup--p-em">requirements.txt</em></strong> file. Just remember that Lambda functions can’t exceed a zipped size of 50MB, so you should be conservative!</p><p id="37c8">When it comes to deployment (‘<em class="markup--p-em">chalice deploy</em>’), <strong class="markup--p-strong">Chalice automatically creates a Lambda function running your code, as well as an API in the API Gateway to trigger it</strong>. If you’d rather deploy with <a href="https://github.com/awslabs/serverless-application-model" target="_blank"><strong class="markup--p-strong">SAM</strong></a>, that’s possible too: ‘<em class="markup--p-em">chalice package</em>’ will build both the deployment package and the SAM template.</p><p id="20c8">Last but not least, you can <strong class="markup--p-strong">run your service locally</strong> (‘<em class="markup--p-em">chalice local</em>’) which obviously helps debugging.. and allows you to code on planes ;)</p><p id="5062">Alright, let’s get to it.</p><h4 id="7929">Writing an image prediction service with chalice</h4><p id="6776">As we just saw, the endpoint returns a raw prediction, which contains probably more information than we need to send back to the client. Thus, our service will <strong class="markup--p-strong">only return the top k classes and probabilities, in descending order of probability</strong>.</p><p id="b286">The <strong class="markup--p-strong">body</strong> of our POST request will contain:</p><ul class="postList"><li id="19a5">a mandatory <strong class="markup--li-strong">base64-encoded image</strong>,</li><li id="a22a">an optional <strong class="markup--li-strong">value for ‘k’</strong>. If it’s missing, the service will use the default value of 257.</li></ul><p id="f870">For more flexibility, let’s store the SageMaker <strong class="markup--p-strong">endpoint name</strong> in an <strong class="markup--p-strong">environment variable</strong> for the Lambda function.</p><p id="bafd">Here are the steps we need to take:</p><ul class="postList"><li id="a8bd">decode the base64-encoded image,</li><li id="5540">read the endpoint name from an environment variable,</li><li id="195c">invoke the endpoint using the InvokeEndpoint API in boto3,</li><li id="1b6b">read the response,</li><li id="b94e">sort categories by descending order of probability,</li><li id="f4d9">return only the top k categories and probabilities.</li></ul><p id="e280">Pretty straightforward, I think. Most of the work is actually to <strong class="markup--p-strong">convert response data</strong> into something that we process. Indeed, the response body is a byte array representing a bracketed array of comma-separated probabilities, which is inconvenient to work with.</p><p id="1a36">In order to turn it into a proper Python array, we can evaluate it as a Python expression with <em class="markup--p-em">ast.literal_eval()</em>. And voila: a Python array! Nice trick.</p><p id="97df">We can then build a <a href="http://www.numpy.org/" target="_blank"><strong class="markup--p-strong">Numpy</strong></a> array holding the <strong class="markup--p-strong">category indexes</strong> in ascending order of probability, reverse the array and take the first top k elements. The last step is to build the response body.</p><figure id="53e8"><script src="https://gist.github.com/juliensimon/c2d9441bf3febdcd9ee4d86d6f25a5a2.js"></script></figure><p id="268c">Pfeew. That was a little more Python plumbing than I originally expected, but it’s actually a good example of <strong class="markup--p-strong">post-processing raw predictions</strong>.</p><h4 id="6d37">Configuring the service</h4><p id="290b">Configuration is pretty simple and is stored in <em class="markup--p-em">.chalice/config.json:</em></p><ul class="postList"><li id="7896">an <strong class="markup--li-strong">environment variable</strong> to store the endpoint name,</li><li id="ee1f">a <strong class="markup--li-strong">custom IAM policy</strong>, allowing the Lambda function to call the InvokeEndpoint API. Once again, we could let Chalice generate it for us, but it’s good to know how to customize your policy :)</li></ul><figure id="fbf9"><script src="https://gist.github.com/juliensimon/032fdc607fdccf47be02b732db399962.js"></script><figcaption>Configuration file</figcaption></figure><figure id="9a8e"><script src="https://gist.github.com/juliensimon/f1eec360bbe6e5eb123c36903b19ebc4.js"></script><figcaption>IAM policy</figcaption></figure><p id="b4fc">Using ‘*’ as a resource selector for <em class="markup--p-em">InvokeEndpoint</em> is ok here. However, in production, I would strongly recommend using the <strong class="markup--p-strong">actual endpoint ARN</strong> instead.</p><h4 id="0618">Running the service locally</h4><p id="26ff">Let’s test the service locally by running ‘<em class="markup--p-em">chalice local</em>’ and then<em class="markup--p-em"> curl</em> to invoke it.</p><figure id="f1ad"><script src="https://gist.github.com/juliensimon/97056d600c74054737806d6470b9914b.js"></script></figure><p id="d94a">Nice. Our service seems to work :)</p><h4 id="4b8c">Deploying the service</h4><p id="921a">Now it’s time to deploy on AWS by running ‘<em class="markup--p-em">chalice deploy</em>’. Let’s run the same test.</p><figure id="4842"><script src="https://gist.github.com/juliensimon/7b9682b8f7375e5e8abb47d19a484e26.js"></script></figure><p id="428e">All good. That’s it, then: <strong class="markup--p-strong">we successfully built a serverless microservice invoking a SageMaker endpoint</strong> (<a href="https://github.com/juliensimon/aws/tree/master/lambda_frameworks/chalice/predictor" target="_blank">code and test script on Github</a>).</p><p id="19c3">This is pretty fun, so why not write another service?</p><h4 id="bb89">Bonus: an image resizer service with Chalice</h4><p id="421c">Computer vision models require <strong class="markup--p-strong">input images to have the same size as training images</strong>. I believe the SageMaker built-in algorithm handles image resizing for us, but it’s definitely something we’d have to take care of if we worked with your own custom model.</p><p id="ab6e">Here’s how you could do this with the <a href="https://opencv.org/" target="_blank"><strong class="markup--p-strong">OpenCV</strong></a> library (<a href="https://github.com/juliensimon/aws/tree/master/lambda_frameworks/chalice/resizer" target="_blank">code and test script on Github</a>).</p><figure id="c51a"><script src="https://gist.github.com/juliensimon/413e9ec9923ef29766306e4a83bef23a.js"></script></figure></div></div></section><section class="section"><div><hr/></div><div><div><p id="f81f">That’s it for today. As you can see, <strong class="markup--p-strong">it’s quite simple to invoke SageMaker endpoints. If you want to go all the way and build a web service, then Chalice is certainly an option you should consider</strong>. I can’t think of an easier way to do it!</p><p id="0847">Thanks for reading. Happy to get your feedback and answer your questions here or on <a href="https://twitter.com/julsimon" target="_blank">Twitter</a>.</p></div></div></section><section class="section"><div><hr/></div><div><div><p id="cdc0"><em class="markup--p-em">Bay Area Thrash Metal, 1988. This A bit of trivia: Paul Bostaph on drums… now in Slayer \m/</em></p><figure id="e48d"><iframe frameborder="0" height="480" scrolling="no" src="https://www.youtube.com/embed/0pTRdopfq1g?feature=oembed" width="640"></iframe></figure></div></div></section>
</section>
</article></body></html>

<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Johnny Pi, I am your father — part 8: reading, translating and more!</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="23bc">Johnny Pi, I am your father — part 8: reading, translating and more!</h3><p id="49eb">It’s been a while since <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-7-son-we-need-to-talk-5a910aa642d1" target="_blank">part 7</a>, where we added a custom Alexa skill to interact with our robot. Plenty has happened since then, so it’s time to teach Johnny some new things, namely:</p><ul class="postList"><li id="c196"><strong class="markup--li-strong">Speeding up local prediction</strong>,</li><li id="be1f"><strong class="markup--li-strong">Recognising celebrities</strong>,</li><li id="aa26"><strong class="markup--li-strong">Reading text</strong>,</li><li id="d7a0"><strong class="markup--li-strong">Detecting the language of a text</strong>,</li><li id="815e"><strong class="markup--li-strong">Translating text</strong>.</li></ul><p id="f695">As usual, all code is available on <a href="https://gitlab.com/juliensimon/johnnypi" target="_blank">Gitlab</a> and you’ll see a video demo at the end of the post. Let’s get to work.</p><figure id="f7c7"><img class="graf-image" src="image05.webp"/></figure><h3 id="d9f5">Speeding up local prediction</h3><p id="91b6">In <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-5-adding-mxnet-for-local-image-classification-bc27a5fd2c27" target="_blank">part 5</a>, we implemented <strong class="markup--p-strong">local object classification</strong> thanks to <a href="https://mxnet.incubator.apache.org/" target="_blank">Apache MXNet</a> and a pre-trained model: it worked fine, albeit a little slow due to the small CPU of the Raspberry Pi.</p><p id="b650">To speed things up, I upgraded to MXNet 1.1 and built it with <a href="https://github.com/Maratyszcza/NNPACK" target="_blank">NNPACK</a>, an <strong class="markup--p-strong">open source acceleration library</strong> (<a href="https://medium.com/@julsimon/speeding-up-apache-mxnet-with-the-nnpack-library-raspberry-pi-edition-e444b446a180" target="_blank">which we already discussed</a>).</p><blockquote class="graf--blockquote graf--hasDropCapModel" id="4c4e">Building MXNet 1.x on a Pi takes well over an hour, but you can get it done. Unfortunately, there is not enough memory to run parallel make (‘make -j’), so stick to ‘make’… and get some more tea, coffee or beer!</blockquote><p class="graf-after--blockquote" id="06f0">Thanks to this, Johnny can now predict a single image with the Inception v3 model in about one second, which is <strong class="markup--p-strong">3x-4x faster</strong> than before. This feels pretty instantaneous when asking for object detection.</p><figure id="f608"><img class="graf-image" src="image03.webp"/><figcaption>“I’m 19% sure that this is a desktop computer”: forward pass in 1.14 second (and yes, I live in a cave).</figcaption></figure><h3 id="3459">Recognising celebrities</h3><p id="6eaa">We already implemented face detection (<a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" target="_blank">part 4</a>), so let’s now handle <strong class="markup--p-strong">celebrities</strong>. This <a href="https://docs.aws.amazon.com/rekognition/latest/dg/celebrities.html" target="_blank">feature</a> was added to <a href="http://aws.amazon.com/rekognition" target="_blank"><strong class="markup--p-strong">Amazon Rekognition</strong></a> a while ago — and <a href="https://www.theverge.com/2018/5/4/17318354/royal-wedding-uk-facial-recognition-sky-news-date" target="_blank">used by Sky News at the recent royal wedding</a> :)</p><p id="a2ec">Let’s just use the <a href="https://docs.aws.amazon.com/rekognition/latest/dg/API_RecognizeCelebrities.html" target="_blank"><em class="markup--p-em">RecognizeCelebrities</em></a> API and update the function that builds the text message spoken by Johnny.</p><figure id="e780"><script src="https://gist.github.com/juliensimon/bcdc4923889216afcabfbd764e05fae6.js"></script></figure><p id="1847">No changes to the Alexa skill: it will still ask Johnny to look for faces by posting a message to the <em class="markup--p-em">JohnnyPi/see</em> topic. If Johnny detects celebrities, then they will be mentioned in the voice message and in the tweet.</p><p id="ee1d">Quick test? Sure :)</p><figure id="6fa1"><img class="graf-image" src="image06.webp"/><figcaption>We’ll always love you, Princess.</figcaption></figure><h3 id="583d">Reading text</h3><p id="b1e0">This is another <a href="https://docs.aws.amazon.com/rekognition/latest/dg/text-detecting-text-procedure.html" target="_blank">feature</a> in Amazon Rekognition. All we need to do is to call the <a href="https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectText.html" target="_blank"><em class="markup--p-em">DetectText</em></a> API and extract all lines of text. We’ll also use a new topic (<em class="markup--p-em">JohnnyPi/read</em>) to receive messages from the skill.</p><figure id="a204"><script src="https://gist.github.com/juliensimon/acc6edac4bf04e5efed6d4d54e928e96.js"></script></figure><p id="135d">Skill-side, we need a new intent (<em class="markup--p-em">ReadIntent</em>, no slot needed) and an appropriate handler in the Lambda function.</p><figure id="56c5"><script src="https://gist.github.com/juliensimon/318e5e12da1ca78491c9fed62f0df900.js"></script></figure><p id="f59c">Let’s try it.</p><figure id="dc08"><img class="graf-image" src="image02.webp"/></figure><h3 id="83a1"><strong class="markup--h3-strong">Detecting the language of a text</strong></h3><p id="c158"><a href="http://aws.amazon.com/comprehend" target="_blank"><strong class="markup--p-strong">Amazon Comprehend</strong></a> is a Natural Language Processing service launched at re:Invent 2017: one of its features is the ability to <a href="https://docs.aws.amazon.com/comprehend/latest/dg/how-languages.html" target="_blank">detect 100 different languages</a>.</p><p id="3905">Here, we’ll simply use the <a href="https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectDominantLanguage.html" target="_blank"><em class="markup--p-em">DetectDominantLanguage</em></a> API as well as<em class="markup--p-em"> </em>the <em class="markup--p-em">JohnnyPi/read</em> topic again (with a ‘<em class="markup--p-em">language</em>’ message).</p><figure id="6d8c"><script src="https://gist.github.com/juliensimon/51c12b032cfeb67fd2db8a67e68f901f.js"></script></figure><p id="9d14">Skill-side, we need to create another new intent (<em class="markup--p-em">LanguageIntent</em>, no slot needed) and implement the corresponding handler in the Lambda function.</p><figure id="a76f"><script src="https://gist.github.com/juliensimon/4248765b6635c514887281e05c11b271.js"></script></figure><p id="3c1f">Let’s try it.</p><figure id="0d5c"><img class="graf-image" src="image04.webp"/></figure><h3 id="360f"><strong class="markup--h3-strong">Translating text</strong></h3><p id="459d"><a href="http://aws.amazon.com/translate" target="_blank"><strong class="markup--p-strong">Amazon Translate</strong></a> is another service launched at re:Invent 2017. At the time of writing, it can <a href="https://docs.aws.amazon.com/translate/latest/dg/what-is.html" target="_blank">translate</a> from English to French, Spanish, Portuguese, German, Chinese (simplified) and Arabic, and vice-versa. More languages are coming soon :)</p><p id="1c22">We’ll use the <a href="https://docs.aws.amazon.com/translate/latest/dg/API_TranslateText.html" target="_blank"><em class="markup--p-em">TranslateText</em></a> API and the <em class="markup--p-em">JohnnyPi/read</em> topic again (with a ‘<em class="markup--p-em">translate DESTINATION LANGUAGE</em>’ message). We’ll support translation for any of these language pairs: English, French, Spanish, Portuguese and German. We’ll use English as a pivot language when needed.</p><blockquote class="graf--blockquote" id="f21e">Polly doesn’t yet support Arabic and Chinese, which is why I’ve left them out.</blockquote><p class="graf-after--blockquote" id="86fc">Translate supports <strong class="markup--p-strong">source language detection</strong> (you just use ‘auto’ as the source language), but we can’t use it here: we need to know what the source language is — Comprehend will tell us — in order to decide if we need to pivot or not.</p><figure id="cc59"><script src="https://gist.github.com/juliensimon/e48233cd912ba24dc7332e11bea88bf0.js"></script></figure><p id="6fc2">Skill-side, there’s a little more work this time:</p><ul class="postList"><li id="5cbe">We need a <strong class="markup--li-strong">slot</strong> for the target language. There is a convenient pre-defined <strong class="markup--li-strong">slot type</strong> named <em class="markup--li-em">AMAZON.Language</em>, which is exactly what we need!</li><li id="131d">We need to <strong class="markup--li-strong">validate</strong> the slot against the list of supported languages.</li></ul><figure id="c3ad"><script src="https://gist.github.com/juliensimon/199164b305d2912dc6bc211e4515e2eb.js"></script></figure><p id="628f">Let’s try English to German.</p><figure id="b6e9"><img class="graf-image" src="image01.webp"/></figure><p id="c614">Now what about German to Spanish?</p><figure id="e193"><img class="graf-image" src="image07.webp"/></figure><h3 id="9a56">Live testing</h3><p id="9bcc">OK, now you really want to see this live, don’t you? Of course :)</p><figure id="26da"><iframe frameborder="0" height="393" scrolling="no" src="https://www.youtube.com/embed/L51pST6Mll0?feature=oembed" width="700"></iframe></figure><p id="601b">If you’d like to know more about all these services, please take a look at this recent <a href="https://www.youtube.com/watch?v=hs1JodCIe4s" target="_blank">AWS Summit talk</a>.</p><p id="1a47">Happy to answer questions here or on <a href="https://twitter.com/julsimon" rel="noopener nofollow noopener noopener nofollow noopener noopener" target="_blank">Twitter</a>. For more content, please feel free to check out my <a href="https://www.youtube.com/juliensimonfr" rel="nofollow noopener noopener noopener nofollow noopener noopener" target="_blank">YouTube channel</a>.</p></div></div></section><section class="section"><div><hr/></div><div><div><p id="fc73">Part 0: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-0-1eb537e5a36" target="_blank">a sneak preview</a></p><p id="4525">Part 1: <a href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-1-moving-around-e09fe95bbfce" rel="noopener nofollow nofollow noopener nofollow noopener nofollow noopener nofollow noopener noopener" target="_blank">moving around</a></p><p id="58a9">Part 2: <a href="https://becominghuman.ai/johnny-pi-i-am-your-father-part-2-the-joystick-db8ac067e86" rel="nofollow noopener nofollow noopener nofollow noopener nofollow noopener nofollow noopener noopener" target="_blank">the joystick</a></p><p id="a175">Part 3: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-3-adding-cloud-based-speech-fb6e4f207c76" target="_blank">cloud-based speech</a></p><p id="7aa6">Part 4: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" target="_blank">cloud-based vision</a></p><p id="8772">Part 5: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-4-adding-cloud-based-vision-8830c2676113" target="_blank">local vision</a></p><p id="7ba1">Part 6: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-6-now-im-pushing-your-button-ha-7a591c46ab74" target="_blank">the IoT button</a></p><p id="31e2">Part 7: <a href="https://medium.com/@julsimon/johnny-pi-i-am-your-father-part-7-son-we-need-to-talk-5a910aa642d1" target="_blank">the Alexa skill</a></p></div></div></section><section class="section"><div><hr/></div><div><div><p id="98e9"><em class="markup--p-em">Be good, Johnny. I’m going to need you for a few demos :)</em></p><figure id="1473"><iframe frameborder="0" height="480" scrolling="no" src="https://www.youtube.com/embed/yAl80RTYydQ?feature=oembed" width="640"></iframe></figure></div></div></section>
</section>
</article></body></html>
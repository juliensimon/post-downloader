<!DOCTYPE html>
<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Retrieval Augmented Chatbot, part 2!</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">


<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="46be">Retrieval Augmented Chatbot, part 2! LangChain, Hugging Face, Amazon SageMaker, and Amazon OpenSearch Serverless ðŸ˜€</h3><p id="bec5">We start by deploying Mistral 7B, a cutting-edge open-source LLM, onto a SageMaker endpoint. Following this, we work with the Reuters dataset, a Hugging Face dataset comprising 20,000 news articles. We break down these articles into smaller sections and apply bge-small, a compact open-source embedding model, to them. Next, we proceed to index these sections into an Amazon OpenSearch Serverless vector index, which we then query through LangChain. Additionally, aside from the RAG demonstration, we delve into some vital yet often overlooked steps related to authentication and security for OpenSearch Serverless.</p><figure id="1d23"><iframe frameborder="0" height="393" scrolling="no" src="https://www.youtube.com/embed/x5SYNpfK4H0?feature=oembed" width="700"></iframe></figure><p id="2890">Part 1: <a href="https://youtu.be/7kDaMz3Xnkw" rel="nofollow noopener" target="_blank">https://youtu.be/7kDaMz3Xnkw</a></p></div></div></section>
</section>
</article></body></html>

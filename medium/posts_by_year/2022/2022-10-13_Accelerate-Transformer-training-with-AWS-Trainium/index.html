<!DOCTYPE html>
<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Accelerate Transformer training with AWS Trainium</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">


<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="a43f">Accelerate Transformer training with AWSÂ Trainium</h3><p id="c490">In this video, I show you how to accelerate Transformer training with AWS Trainium, a new custom chip designed by AWS.</p><p id="9f34">First, I walk you through the setup of an Amazon EC2 trn1.32xlarge instance, equipped with 16 Trainium chips. Then, I run a natural language processing job where I adapt existing Transformer training code for Trainium, accelerating a BERT model to classify the Yelp restaurant review datatset. Finally, I run the job on 1, 8, and 32 Neuron cores.</p><figure id="ef49"><iframe frameborder="0" height="393" scrolling="no" src="https://www.youtube.com/embed/HweP7OYNiIA?feature=oembed" width="700"></iframe></figure><ul class="postList"><li id="503c">AWS Trainium: <a href="https://aws.amazon.com/ec2/instance-types/trn1/" rel="noopener noreferrer nofollow noopener" target="_blank">https://aws.amazon.com/ec2/instance-types/trn1/</a></li><li id="934a">AWS Neuron SDK documentation: <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/index.html" rel="noopener noreferrer nofollow noopener" target="_blank">https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/index.html</a></li><li id="5d3e">AWS Neuron SDK samples: <a href="https://github.com/aws-neuron/aws-neuron-samples" rel="noopener noreferrer nofollow noopener" target="_blank">https://github.com/aws-neuron/aws-neuron-samples</a></li><li id="da39">Hugging Face tutorial: <a href="https://github.com/aws-neuron/aws-neuron-samples" rel="noopener noreferrer nofollow noopener" target="_blank">https://huggingface.co/docs/transformers/training</a></li><li id="f8d2">Setup steps and code: <a href="https://gitlab.com/juliensimon/huggingface-demos/-/tree/main/trainium" rel="noopener noreferrer nofollow noopener" target="_blank">https://gitlab.com/juliensimon/huggingface-demos/-/tree/main/trainium</a></li></ul></div></div></section>
</section>
</article></body></html>

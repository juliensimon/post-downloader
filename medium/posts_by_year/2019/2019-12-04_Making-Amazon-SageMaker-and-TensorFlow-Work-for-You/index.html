<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Making Amazon SageMaker and TensorFlow Work for You</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="6866">Making Amazon SageMaker and TensorFlow Work for You — Mobileye guest post</h3><p id="1373"><em class="markup--p-em">This is a guest post by </em><strong class="markup--p-strong"><em class="markup--p-em">Chaim Rand</em></strong><em class="markup--p-em">, </em><strong class="markup--p-strong"><em class="markup--p-em">Machine Learning Algorithm Developer</em></strong><em class="markup--p-em"> at </em><strong class="markup--p-strong"><em class="markup--p-em">Mobileye</em></strong><em class="markup--p-em">. It builds upon the </em><a href="https://www.youtube.com/watch?v=iW0RASdjnOk" target="_blank"><em class="markup--p-em">AIM410R session</em></a><em class="markup--p-em"> at AWS re:Invent 2019. You can also read </em><a href="https://medium.com/@julsimon/deep-dive-on-tensorflow-training-with-amazon-sagemaker-and-amazon-s3-12038828075c" target="_blank"><em class="markup--p-em">part 2</em></a><em class="markup--p-em"> and </em><a href="https://towardsdatascience.com/tensorflow-performance-analysis-314b56dceb59" target="_blank"><em class="markup--p-em">part 3</em></a><em class="markup--p-em"> for more!</em></p><figure id="f443"><iframe frameborder="0" height="393" scrolling="no" src="https://www.youtube.com/embed/iW0RASdjnOk?feature=oembed" width="700"></iframe></figure><h3 id="0cbc">Abstract</h3><p id="0181">Under the surface of <a href="https://www.mobileye.com" target="_blank">Mobileye</a>’s (officially known as “Mobileye, an <a href="https://www.intel.com" target="_blank">Intel</a> Company”) life-saving driving assistant products are cutting edge AI technologies. At any given time at Mobileye, we may be training scores of Deep Neural Networks (DNN) targeted for the next generation of <a href="https://www.mobileye.com/our-technology/adas/" target="_blank">Advanced Driving Assistant</a>, <a href="https://www.mobileye.com/future-of-mobility/history-autonomous-driving/" target="_blank">Autonomous Vehicle</a>, and <a href="https://www.mobileye.com/our-technology/rem/" target="_blank">Road Experience Management</a> products.</p><figure id="1908"><iframe frameborder="0" height="393" scrolling="no" src="https://www.youtube.com/embed/qfJbkuDY1xI?feature=oembed" width="700"></iframe></figure><p id="8d6e">This requires vast amounts infrastructure that is fast, flexible, scalable, and secure. Enter <a href="https://aws.amazon.com/sagemaker/" target="_blank">Amazon SageMaker</a>. In this post, I will share some of the details of how we adapted one of our DNNs to SageMaker’s <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode </a>and the surprising ways in which this accelerated the development cycle.</p><h3 id="00ef"><strong class="markup--h3-strong">Prelude</strong></h3><p id="c5f5">This post is about the <a href="https://aws.amazon.com/sagemaker/" target="_blank">Amazon SageMaker</a> service. It is an exciting story about how my team and I ported one of our Deep Learning (DL) training flows to <a href="https://aws.amazon.com/sagemaker/" target="_blank">Sagemaker</a>, the challenges we encountered along the way, how we overcame them, and the benefits we discovered along the way. It is a story of courage, creativity, and, above all, perseverance.</p><div class="graf--mixtapeEmbed" id="b7aa"><a class="markup--mixtapeEmbed-anchor" href="https://aws.amazon.com/blogs/aws/sagemaker/" title="https://aws.amazon.com/blogs/aws/sagemaker/"><strong class="markup--mixtapeEmbed-strong">Amazon SageMaker - Accelerating Machine Learning | Amazon Web Services</strong><br/><em class="markup--mixtapeEmbed-em">Machine Learning is a pivotal technology for many startups and enterprises. Despite decades of investment and…</em>aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="9a3fb5d024e299b2c07810edc02dcb2a" data-thumbnail-img-id="0*71VPT8lJoGP6Z38A" href="https://aws.amazon.com/blogs/aws/sagemaker/" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*71VPT8lJoGP6Z38A);"></a></div><h3 class="graf-after--mixtapeEmbed" id="93c3"><strong class="markup--h3-strong">Chapter 1: Introduction</strong></h3><p id="2319">The audience I am targeting includes:</p><ol class="postList"><li id="6f93">Developers trying to decide whether <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> is right for them or their company.</li><li id="f25d">Developers who have been tasked with porting their training code to <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> and don’t know where to begin or what to expect.</li><li id="5794">Developers who are knee deep in <a href="https://aws.amazon.com/sagemaker" target="_blank">SageMaker</a>.</li></ol><p id="a597">The message that I want to deliver to you today, whichever group you may fall into is that… <strong class="markup--p-strong">everything is going to be okay</strong>.</p><p id="f0c5">Let me start by saying that I am NOT an AWS guy. On the one hand, what that means is that I don’t speak on behalf of AWS. Any allusions that I may make regarding performance or cost are based solely on my own experience and should be verified by your own AWS representative. On the other hand, that means that I am one of <strong class="markup--p-strong">you</strong>. I am here for <strong class="markup--p-strong">you</strong>. Feel free drop me a line sharing your AWS woes, or as I like to call them… your wAWS. I promise to be supportive.</p><p id="20c2">Here are some of the things I like about <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a>:</p><ul class="postList"><li id="8a1b">It offers a <strong class="markup--li-strong">secure and scalable environment</strong> in which one can essentially spin up as many training sessions as they want.</li><li id="26b3">It enables one to freely choose between <strong class="markup--li-strong">many different types of </strong><a href="https://aws.amazon.com/sagemaker/pricing/instance-types/" target="_blank"><strong class="markup--li-strong">training instances</strong></a> with ease.</li><li id="ff49">It enables feeding one’s training data <strong class="markup--li-strong">directly from </strong><a href="https://aws.amazon.com/s3/" target="_blank"><strong class="markup--li-strong">Amazon S3</strong></a>, essentially removing any storage space constraints.</li><li id="9ce0">It enables one to <strong class="markup--li-strong">decouple the storage</strong> of their training data from the actual training execution.</li><li id="7fcd">It enables one to run their <strong class="markup--li-strong">entire development pipeline in the cloud</strong>, from data collection and creation all the way to quantization and deployment.</li></ul><p id="145e">However, as with any other new framework, adopting <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> might require some patience, resilience, and effort.</p><blockquote class="graf--pullquote" id="4128">Make no mistake, the <a class="markup--pullquote-anchor" href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> <a class="markup--pullquote-anchor" href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html" target="_blank">documentation</a> is quite good. The <a class="markup--pullquote-anchor" href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_Operations.html" target="_blank">APIs</a> are pretty straightforward and there are code samples demonstrating a wide variety of use cases.</blockquote><p class="graf-after--pullquote" id="98c7">At the end of the day, adopting our flow to <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> did not require much heavy lifting. While we did face some challenges along the way, we overcame them and gained more and more confidence that <strong class="markup--p-strong">Sagemaker could work for us</strong>. Over the next few minutes I hope to pass this confidence to you. Our story is based on using <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> with the <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a><strong class="markup--p-strong">, </strong>but I believe that most of what I have to say carries over to any solution based on <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> usage. When you are using large data sets, using <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> is the “right” way to train on <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a>. Of course, this is just my opinion… but it’s true. (Legal disclaimer, what I mean is that ‘I think it’s true’, but it really is!).</p><p id="6d3a">My story is told based on <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> version 1.13.1 and <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> version 1.23. To the best of my knowledge, my comments are correct as of today (November 2019). Naturally, things may have changed since then.</p></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="838a"><strong class="markup--h3-strong">Chapter 2: Sagemaker Pipe Mode</strong></h3><p id="b884">What is <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> and what is it good for?</p><h4 id="ae7c">An introduction to Pipe Mode</h4><p id="83fc">Pipe input mode is one of the main features offered by the <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> training environment, and it is said to enable meaningful reductions in both train time and cost. <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> is a mechanism (based on Linux pipes) for <strong class="markup--p-strong">streaming your training data directly from </strong><a href="https://aws.amazon.com/s3" target="_blank"><strong class="markup--p-strong">Amazon S3</strong></a><strong class="markup--p-strong"> storage to your training instance</strong>.</p><div class="graf--mixtapeEmbed" id="f62a"><a class="markup--mixtapeEmbed-anchor" href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" title="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/"><strong class="markup--mixtapeEmbed-strong">Accelerate model training using faster Pipe mode on Amazon SageMaker | Amazon Web Services</strong><br/><em class="markup--mixtapeEmbed-em">Amazon SageMaker now comes with a faster Pipe mode implementation, significantly accelerating the speeds at which data…</em>aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="2cf2b7cb61b2c3a6ad2c244e6494c3ed" data-thumbnail-img-id="0*MFCqvq1l_-VV6I86" href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*MFCqvq1l_-VV6I86);"></a></div><p class="graf-after--mixtapeEmbed" id="f4a6">The previous way of doing this was to download all of the data from <a href="https://aws.amazon.com/s3" target="_blank">S3</a> to the training instance. This had to be done each time you wanted to spin up a new training session. When working with large data sets,say 10s or even 100s of Terabytes, this would cause a significant delay to the training start time. You may also incur significant storage costs, again, for each training instance.</p><p id="9857"><a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> avoids this by essentially feeding the data directly to the algorithm as it is needed. This means that <strong class="markup--p-strong">training can start as soon as the pipe is opened</strong> and no local storage is required.</p><figure id="bf9e"><img class="graf-image" src="image02.webp"/></figure><p id="ae9c">In particular, this has the effect of <strong class="markup--p-strong">removing any limitations on the size of your data set</strong>. You can store all of your data on <a href="https://aws.amazon.com/s3" target="_blank">S3</a>, with its virtually limitless storage capacity, and not have to worry about local storage constraints or costs.</p><blockquote class="graf--pullquote" id="6691">This means that your <strong class="markup--pullquote-strong">data storage and training environment are now decoupled</strong>. You can spin up as many training instances as you’d like and have them all point to same data storage location in <a class="markup--pullquote-anchor" href="https://aws.amazon.com/s3" target="_blank">S3</a>.</blockquote><pre class="graf--pre graf-after--pullquote" id="9ceb">from sagemaker.tensorflow import TensorFlow</pre><pre class="graf--pre graf-after--pre" id="8070">tensorflow = TensorFlow(<br/> entry_point=’myscript.py’, <br/> input_mode=’Pipe’,<br/> …)</pre><pre class="graf--pre graf-after--pre" id="9a3e">train_data = ‘s3://sagemaker-path-to-train-data’</pre><pre class="graf--pre graf-after--pre" id="f233">tensorflow.fit({‘train’:train_data})</pre><p class="graf-after--pre" id="9a57">There is one significant drawback to <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a>. In our pre-<a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> work flow, we were accustomed to random access control over our data set. In other words, we were able to freely access any sample within our data set, and we counted on this ability in order to control how data was fed to the training pipeline; to control appropriate shuffling of the input data, enable boosting of certain subsets of data, and more. In the next chapters I will go into this in more detail and describe how we solved this.</p><p id="beac">Lest you should be thinking to yourself, “<em class="markup--p-em">Linux pipes? Come on… Now I have to manage those?!!</em>”.</p><blockquote class="graf--pullquote" id="f76b"><a class="markup--pullquote-anchor" href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> comes with an implementation of the <a class="markup--pullquote-anchor" href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> <a class="markup--pullquote-anchor" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" target="_blank"><em class="markup--pullquote-em">Dataset</em></a> interface that essentially hides all the low level from you.</blockquote><p class="graf-after--pullquote" id="78ed">This provides support for all the <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> operations (preprocessing, boosting, shuffling, etc.) that your heart may desire, and feeds directly into the training pipeline. Nirvana…</p><pre class="graf--pre" id="ae25">def parse(record):</pre><pre class="graf--pre graf-after--pre" id="5e10">feature = {‘label’: tf.FixedLenSequenceFeature([], tf.int64, allow_missing=True),</pre><pre class="graf--pre graf--startsWithSingleQuote graf-after--pre" id="090b">‘image_raw’: tf.FixedLenFeature([], tf.string)}</pre><pre class="graf--pre graf-after--pre" id="83bf">features = tf.parse_single_example(record, feature)</pre><pre class="graf--pre graf-after--pre" id="c23e">image = tf.decode_raw(features[‘image_raw’], tf.uint8)</pre><pre class="graf--pre graf-after--pre" id="c777">label = features[‘label’]</pre><pre class="graf--pre graf-after--pre" id="276e">return {“image”: image}, label # This is what will be fed into your model</pre><pre class="graf--pre graf-after--pre" id="4ed7">ds = PipeModeDataset(“train”, record_format=’TFRecord’)</pre><pre class="graf--pre graf-after--pre" id="c4c8">ds = ds.apply(map_and_batch(parse, batch_size=32, num_parallel_batches=2))</pre><pre class="graf--pre graf-after--pre" id="c03e">return ds</pre><h4 class="graf-after--pre" id="3021">Picking a file format</h4><p id="27d0">But there was a catch. A fairly significant one. The catch was that we would need to transform all of our training data into one of the data formats supported by <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a>, which include: <a href="https://www.tensorflow.org/tutorials/tensorflow_text/intro" target="_blank">text</a> records, <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> and <a href="https://github.com/protocolbuffers/protobuf" target="_blank">Protobuf</a>. Of course, we could choose to use <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> with our existing data format, but to enjoy the goodness of <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a>, and save ourselves the headache of implementing the pipe management ourselves, we would need to adopt one of the above formats.</p><p id="f035">We chose <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a>, (really not for any other reason than the abundance of sample code available). For those wary of adopting a new data format, I will mention that <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> is <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a>’s binary storage format and that converting your data to <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> should be fairly simple (examples are abundant online).</p><p id="a95d">For us, the need to transform our data set format actually turned out to be a <strong class="markup--p-strong">huge blessing in disguise</strong>. Faced with the need to modify our data creation flow, we embarked on a quest to port this stage of the workflow to AWS as well.</p><blockquote class="graf--pullquote" id="d9f6">This ultimately led to an <strong class="markup--pullquote-strong">enormous acceleration in our data creation time</strong> (from several days to a couple of hours) and thus to our overall development time.</blockquote></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="58fd"><strong class="markup--h3-strong">Chapter 3: Data Preparation… in the Cloud</strong></h3><p id="0d93">Having adopted <a href="https://aws.amazon.com/sagemaker/" target="_blank">Sagemaker</a> pipe input mode and the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> format, you now need to ensure that your training data is prepared accordingly. Let’s go over what that means.</p><h4 id="6181">Splitting the data set</h4><p id="a7ba">In the standard usage of pipe input mode, we set up a pipe by providing an <a href="https://aws.amazon.com/s3" target="_blank">S3</a> prefix. When the pipe is opened, all of the files that match the given prefix are fed one by one into the pipe. The size of the files may impact the performance of the pipe. File sizes that are too small or too big will almost certainly slow down your training cycle. After a bit of experimentation (and consulting our trusted AWS rep), we settled on a target file size of <strong class="markup--p-strong">100 Megabytes</strong>. Thus our first requirement was that the training data be broken down into <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> files of roughly 100 Megabytes each.</p><h4 id="349e">Shuffling the data set</h4><p id="6681">A common practice in the world of Machine Learning (ML) is to shuffle your data before training. In the past, we relied on our ability to randomly access any sample in our data set to ensure appropriate shuffling. However, given the sequential nature of pipe input mode, we could no longer rely on this. Thus, our second requirement was that the training data be appropriately shuffled during preparation.</p><p id="6e16">When you have massive amounts of data, as we do, the task of preparing your data can be quite daunting and time consuming.</p><blockquote class="graf--pullquote" id="a16a">Fortunately, we were able to leverage the nearly infinite scale opportunities offered by the <a class="markup--pullquote-anchor" href="https://aws.amazon.com/batch/" target="_blank">AWS Batch</a> service in order to accomplish this in a highly parallel and very efficient manner.</blockquote><p class="graf-after--pullquote" id="9fde">To ensure a sufficiently random shuffling, we employed a two step process. The first step performed the initial parsing and recording of the data records, and the second step grouped the records into 100 Megabyte <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> files in a random fashion. I will not dive any further into the details, as they are pretty use case specific. I will only note that the pay-per-second and spot fleet support that <a href="https://aws.amazon.com/batch/" target="_blank">AWS Batch</a> offers can help in reaching cost efficiency.</p><figure id="dc3f"><img class="graf-image" src="image03.webp"/></figure><p id="ffb4">You will likely need to separate your data into different groups, for example train and test. This is done by using a different prefix for the train and test data and then setting up corresponding pipes in the <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> start up script.</p></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="fa0d"><strong class="markup--h3-strong">Chapter 4: Data Shuffling</strong></h3><p id="be19">We have ensured that the data in <a href="https://aws.amazon.com/s3" target="_blank">S3</a> is shuffled, but in some cases, we want to reshuffle the data before each data traversal (epoch). This can be accomplished quite trivially when you have access to your full data set, but when it comes to pipe mode with its inherently sequential nature, the solution for this is not immediate.</p><p id="18aa">In order to address this need, we can use <a href="https://aws.amazon.com/sagemaker/" target="_blank">Sagemaker</a>’s <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_ShuffleConfig.html" target="_blank"><em class="markup--p-em">ShuffleConfig</em></a> class to set up each pipe such that before each data traversal, <strong class="markup--p-strong">the order in which the files are fed into the pipe is shuffled</strong>. We chose to add an additional level of shuffling, that would include <strong class="markup--p-strong">shuffling at the training batch level</strong>, using the <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" target="_blank"><em class="markup--p-em">Dataset</em></a> shuffle function. This function, which is applied to the <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a>, receives a shuffle window size that causes each successive record to be randomly chosen from the next “window size” elements on the pipe. The window size we chose was dictated by the number of records in each file while taking care not to add too much memory overload on the application.</p><pre class="graf--pre" id="1b26">train_data = s3_input(<br/>   ‘s3://sagemaker-path-to-train-data‘,<br/>   shuffle_config=ShuffleConfig(seed)<br/>)</pre><p class="graf-after--pre" id="a033">The solution above does not give us the same degree of shuffling that we used to have. For example, two records that appear in the same <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> file are more likely to appear in close vicinity of one another than at two opposite ends of the data stream. But the three levels of shuffling that I have described (during data creation, <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_ShuffleConfig.html" target="_blank"><em class="markup--p-em">ShuffleConfig</em></a> and <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> shuffle) were more than sufficient for our purposes.</p></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="ca3f"><strong class="markup--h3-strong">Chapter 5: Managing Your Training Data</strong></h3><p id="8bbb">Now may be a good time to mention that there is a limitation to the number of pipes you can set up. As of this writing, this limitation stands at 20 pipe channels. You might be asking yourself: “<em class="markup--p-em">Why the heck would I need any more than twenty? Why would anyone need more than two</em>“. There are often times where we want to separate our data into different subsets and manipulate the data differently during train time.</p><h4 id="02ee">Using pipes to boost under-represented classes</h4><p id="c27f">Let me attempt to demonstrate this via the following (made-up) example.</p><p id="01a4">Suppose you are tasked with creating a DNN that identifies cars on the road. You are given 100,000 marked frames and have transformed these into <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> files as described above. Now suppose you run a few rounds of training and find that your resultant network now succeeds in identifying most cars pretty well, but consistently fails to identify pink cars. You go back to your training data and realize that there is no wonder that you are failing to learn pink cars as you only have 10 training records with pink cars. The solution that you want to attempt is to “boost” the pink cars in your input pipe, meaning, during each epoch, you will feed the 10 records with pink cars twice. If you had free access to your entire data set that would be a fairly simple task. But how do you do it using pipes?</p><figure id="aa2e"><img class="graf-image" src="image01.webp"/><figcaption>We need more pink cars!</figcaption></figure><p id="6431">A terrible solution (again… only my opinion… but unequivocally true) would be to duplicate the ten records in your data set in <a href="https://aws.amazon.com/s3" target="_blank">S3</a>:</p><ol class="postList"><li id="2241">This approach could potentially and needlessly blow up the size of your data set.</li><li id="7b26">I can almost guarantee that one day later you will decide that the correct boost rate is 3 not 2. Or is it 5?</li></ol><p id="b84c">An alternative solution is to <strong class="markup--p-strong">create a dedicated training pipe</strong> for pink cars and then in the preprocessing phase of the training interleave between the <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a> corresponding to the pink cars and the <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a> corresponding to the rest of the train records, with their corresponding appropriate weights, before feeding them to the network. (One way to do this is using the <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord" target="_blank"><em class="markup--p-em">TFRecord</em></a> <a href="https://www.tensorflow.org/api_docs/python/tf/data/experimental/sample_from_datasets" target="_blank"><em class="markup--p-em">sample_from_datasets</em></a> routine.)</p><pre class="graf--pre" id="e019">ds = tf.contrib.data.sample_from_datasets(datasets, weights)</pre><p class="graf-after--pre" id="cb8c">Now you might say to yourself : “<em class="markup--p-em">Great! I have a bunch of free pipes, I’ll use one of them for pink cars</em>”. But a few days later, you realize that you need a different boost parameter for pink trucks, and a different one for black cars at night… and before you know it you have hit the limit.</p><p id="dae3">Before I get into some of the ways that we addressed this issue, I would like to give another example where having multiple pipes can be very useful.</p><h4 id="4aec">Using pipes for data augmentation</h4><p id="7ee5">A common practice in ML is to artificially increase your training data set by performing data augmentations. In the olden days, we would apply each one of a fixed set of augmentations to each data record and feed it to the network while ensuring appropriate shuffling. Again, we relied on our access to the full data set, which we did not have when moving to <a href="https://aws.amazon.com/sagemaker/" target="_blank">Sagemaker</a> <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a>.</p><p id="f357">One appealing solution was to randomize the augmentation for each input record. However, some networks required us to fix the augmentation type and ensure that each augmentation was applied to each of the records. Another solution could have been to create all of the different augmentations ahead of time. But, once again, this would have been very wasteful and would not have enabled us to play with the augmentation parameters.</p><p id="4955">We chose to address this requirement by creating N parallel training pipes, where N was the number of different augmentation types. Each corresponding <a href="https://github.com/aws/sagemaker-tensorflow-extensions" target="_blank"><em class="markup--p-em">PipeModeDataset</em></a> was implemented with the corresponding augmentation function, following which all of the pipes were interleaved together before being fed to the network. In this case, it was extremely important to use the <a href="http://ShuffleConfig" target="_blank"><em class="markup--p-em">ShuffleConfig</em></a> object we discussed above, to increase the likelihood that the different augmentations of a given record would be spread out rather than bunched together.</p><h4 id="6a51">Keeping pipes under control</h4><p id="0caa">Now that you are convinced that there may be situations in which we need more pipes than we are allotted, I will describe one solution we used for decreasing the number of pipes.</p><p id="8952">One of the alternatives to configuring pipes with an <a href="https://aws.amazon.com/s3" target="_blank">S3</a> prefix (as described above), is to create and point to a <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/augmented-manifest.html" target="_blank">manifest file</a>.</p><div class="graf--mixtapeEmbed" id="6f87"><a class="markup--mixtapeEmbed-anchor" href="https://docs.aws.amazon.com/sagemaker/latest/dg/augmented-manifest.html" title="https://docs.aws.amazon.com/sagemaker/latest/dg/augmented-manifest.html"><strong class="markup--mixtapeEmbed-strong">Provide Dataset Metadata to Training Jobs with an Augmented Manifest File</strong><br/><em class="markup--mixtapeEmbed-em">To classify data into different groupings, you train a model by using a dataset and metadata that act as labels. To…</em>docs.aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="1b0b628a39d3b932e389553a3a00bdab" data-thumbnail-img-id="0*4fmSwSNVYBpyt16z" href="https://docs.aws.amazon.com/sagemaker/latest/dg/augmented-manifest.html" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*4fmSwSNVYBpyt16z);"></a></div><p class="graf-after--mixtapeEmbed" id="d2be">In a manifest file, you explicitly point to the list of files that you want to feed into the network. In particular, if there are certain files that you want to be traversed twice, you can simply write them in the manifest file twice. This is a very useful solution for use cases in which we have more boost rates than allotted pipes. It does not solve the multiple pipes needed for augmentations.</p><pre class="graf--pre" id="373b">data = s3_input(<br/>   ‘s3://path-to-manifest-file‘, <br/>   s3_data_type=’ManifestFile‘, <br/>   shuffle_config=ShuffleConfig(seed)<br/>)</pre><p class="graf-after--pre" id="82e1">Let me summarize some of the tips we covered:</p><ul class="postList"><li id="99ba">Try to group your data so that you will not need more that the maximum number of pipes. If you can’t, consider using manifest files.</li><li id="4c77">Use the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_ShuffleConfig.html" target="_blank"><em class="markup--li-em">ShuffleConfig</em></a> setting to shuffle the order of the input files before each traversal.</li><li id="bd5e">Use the <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> shuffle for additional shuffling at the file level.</li></ul><p id="56b1">Obviously, the details of you own implementation, and whether any of the tips above apply, will depend on the specifics of your use case.</p></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="a7b2"><strong class="markup--h3-strong">Chapter 6: Multi-GPU training</strong></h3><p id="a6bf">One of the advantages to using <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> is our ability to freely choose a training instance to match our current training job.</p><div class="graf--mixtapeEmbed" id="265d"><a class="markup--mixtapeEmbed-anchor" href="https://aws.amazon.com/sagemaker/pricing/instance-types/" title="https://aws.amazon.com/sagemaker/pricing/instance-types/"><strong class="markup--mixtapeEmbed-strong">Amazon SageMaker Instance Types - Amazon Web Services (AWS)</strong><br/><em class="markup--mixtapeEmbed-em">Amazon SageMaker provides a selection of instance types optimized to fit different machine learning (ML) use cases…</em>aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="f599b7f9607d35f703ada24bd4b266c6" data-thumbnail-img-id="0*qnEGbrpxuKATl61u" href="https://aws.amazon.com/sagemaker/pricing/instance-types/" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*qnEGbrpxuKATl61u);"></a></div><p class="graf-after--mixtapeEmbed" id="097a">In particular, we can choose one or more machines with one or more GPUs. There is no shortage of documentation on the different methods and strategies for using multiple GPUs to speed up training. There are multiple considerations that one should take into account when choosing the ideal training instance. (If you aren’t already, you should start by using the <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-overview.html" target="_blank">metrics</a> to view the GPU, CPU and memory utilizations.) There are also multiple ways of adjusting one’s code to multi-GPU training. I wish only to briefly demonstrate how one’s decision to use the <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> framework, and, in particular, <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> pipe input mode, may bear on some of the decisions regarding multi-GPU implementation.</p><h4 id="4636">Setting up multi-GPU training</h4><p id="69b5">For some of our training jobs, we found it appropriate to perform <strong class="markup--p-strong">data parallelization over multiple GPUs on a single instance</strong>, to speed up training. There were two primary libraries we considered for implementing this.</p><div class="graf--mixtapeEmbed" id="e77a"><a class="markup--mixtapeEmbed-anchor" href="https://aws.amazon.com/blogs/machine-learning/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/" title="https://aws.amazon.com/blogs/machine-learning/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/"><strong class="markup--mixtapeEmbed-strong">Launching TensorFlow distributed training easily with Horovod or Parameter Servers in Amazon…</strong><br/><em class="markup--mixtapeEmbed-em">Amazon SageMaker supports all the popular deep learning frameworks, including TensorFlow. Over 85% of TensorFlow…</em>aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="74be6099f0a921172007b9460c1c9f9a" data-thumbnail-img-id="0*ifFgBBQUwzknGH8L" href="https://aws.amazon.com/blogs/machine-learning/launching-tensorflow-distributed-training-easily-with-horovod-or-parameter-servers-in-amazon-sagemaker/" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*ifFgBBQUwzknGH8L);"></a></div><ul class="postList"><li class="graf-after--mixtapeEmbed" id="d8a3">Built-in multi-GPU <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> support: If you are using <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> estimators, then this is a very attractive option as it boils down to just adding a few lines of code, setting the appropriate strategy in a <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig" target="_blank"><em class="markup--li-em">tf.estimator.RunConfig</em></a>.</li><li id="a73a">The <a href="https://github.com/horovod/horovod" target="_blank">Horovod</a> distributed training framework: <a href="https://github.com/horovod/horovod" target="_blank">Horovod</a> enables you to easily add a wrapping layer to your training code, that controls the number of training instances threads and ensures appropriate data sharing (gradient sharing) between them. <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> supports <a href="https://github.com/horovod/horovod" target="_blank">Horovod</a> configuration directly.</li></ul><div class="graf--mixtapeEmbed" id="b7cc"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/aws-samples/sagemaker-horovod-distributed-training" title="https://github.com/aws-samples/sagemaker-horovod-distributed-training"><strong class="markup--mixtapeEmbed-strong">aws-samples/sagemaker-horovod-distributed-training</strong><br/><em class="markup--mixtapeEmbed-em">This lab demonstrates two concepts on a simple MNIST dataset and a TensorFlow deep learning framework: SageMaker…</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="660b64fe7a834c26dbae7994b0f63530" data-thumbnail-img-id="0*NkgrHMHH2Pf4e5Lb" href="https://github.com/aws-samples/sagemaker-horovod-distributed-training" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*NkgrHMHH2Pf4e5Lb);"></a></div><h4 class="graf-after--mixtapeEmbed" id="f7c6">Multi-GPU and Pipe Mode</h4><p id="2dc4">There is one significant difference in the way these two solutions work. While <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> opens a single input stream which is shared by all GPUs, <a href="https://github.com/horovod/horovod" target="_blank">Horovod</a> wraps the entire training script, including the data input flow. This means that if you are using <a href="https://github.com/horovod/horovod" target="_blank">Horovod</a> to train on an instance with 8 GPUs, you will need to <strong class="markup--p-strong">configure 8 times as many pipes</strong> as on a single GPU job. Given the limitation on pipes that we mentioned above, you could see how using Horovod may incur some limitations.</p><p id="2854">Naturally, performance should be the number one consideration when deciding which path to choose (and as we saw, we can sometimes work around the pipe limitation). We found the performance of both frameworks on our DNN to be comparable, and we chose the <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> option due to the pipe limitation.</p><h4 id="658d"><strong class="markup--h4-strong">Optimizing training times</strong></h4><p id="494f">One last tip regarding multi-GPU training before we move on. It is quite common to run training with multiple GPUs, and to run evaluation on a single GPU. Now suppose that your evaluation takes an hour. If you are running evaluation intermittently during training, you will find yourself spending hours utilizing only one GPU on your multi-GPU instance. This is an unforgivable waste of resources, not to mention a huge waste of money.</p><p id="03b4">Consider the following instead. Each time you want to run evaluation, <strong class="markup--p-strong">spin up a new single GPU instance on </strong><a href="https://aws.amazon.com/ec2" target="_blank"><strong class="markup--p-strong">Amazon EC2</strong></a><strong class="markup--p-strong"> from within your training session and launch the evaluation there</strong>. Yes, this works, provided that you have installed the <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> SDK, which surprisingly is not there by default.</p><p id="9b8d">This has the added benefit of <strong class="markup--p-strong">reducing the delay to your training</strong> (which doesn’t have to wait for evaluation to complete before resuming), and it might be a good idea even in the single GPU case.</p></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="4577"><strong class="markup--h3-strong">Chapter 7: Debugging on Sagemaker</strong></h3><p id="ed70">I wish I could tell you, dear reader, that once you have transformed your data, configured your training, ensured appropriate shuffling session, and overcome any pipe number limitations, everything will work perfectly. But, alas, as with most everything in life, certainly in the world of SW development such is not the case.</p><p id="8561">As always, you are likely to experience crashes, exceptions, training failures and other woes. Just, that now, the usual difficulties of debugging and solving such issues are compounded by the fact that your are running on a remote environment.</p><p id="8ee6">So, here is golden rule number one… and if you take nothing away from this blog but this, my time will have been well spent.</p><blockquote class="graf--pullquote" id="ae2a"><strong class="markup--pullquote-strong">Always start by running your training session in your local environment</strong></blockquote><p class="graf-after--pullquote" id="e317">You can stick to a very small subset of your data — even just one or two batches before running on <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a>. This will save you lots of time (and money). It’s as simple as that.</p><div class="graf--mixtapeEmbed" id="cc9a"><a class="markup--mixtapeEmbed-anchor" href="https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/" title="https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/"><strong class="markup--mixtapeEmbed-strong">Use the Amazon SageMaker local mode to train on your notebook instance | Amazon Web Services</strong><br/><em class="markup--mixtapeEmbed-em">Amazon SageMaker recently launched support for local training using the pre-built TensorFlow and MXNet containers…</em>aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="18a70fb45760b38ccab52c89bb97f893" data-thumbnail-img-id="0*Mo14PMCM-oNxNKoD" href="https://aws.amazon.com/blogs/machine-learning/use-the-amazon-sagemaker-local-mode-to-train-on-your-notebook-instance/" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*Mo14PMCM-oNxNKoD);"></a></div><p class="graf-after--mixtapeEmbed" id="5b6e">The problem is that not all issues can be reproduced this way. Some issues are environment specific, other issues are related to <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a>, which (as of now) cannot be run locally, and yet other issues (such as lack of loss convergence), only come up when training on a large amount of data. Here are some pointers that you might find helpful:</p><ol class="postList"><li id="5395">The <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> logs (which can be accessed from the console) is probably the first thing to check. There you will get an initial indication if something went wrong, and if so, what.</li><li id="4e6d">If you suspect you may be facing an issue with <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> (e.g. low throughput), the first thing you should do is open a ticket to AWS support. You could try to add <a href="https://www.tensorflow.org/api_docs/python/tf/print" target="_blank"><em class="markup--li-em">tf.print</em></a> and what not to try and find the root cause, but the <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a> mechanism is a feature that we do not have much visibility into.</li><li id="febf">Use <a href="https://www.tensorflow.org/tensorboard" target="_blank">TensorBoard</a> to track the performance of your training. You can configure <a href="https://www.tensorflow.org/tensorboard" target="_blank">TensorBoard</a> (from the command line) to point directly to the <a href="https://aws.amazon.com/s3" target="_blank">S3</a> model directory, or (if you have many events) download the event file periodically and run locally.</li><li id="ad7e">Use the console to track CPU and GPU utilization metrics. Advanced users can add custom metrics (such as training loss), trigger alarms and apply other <a href="https://aws.amazon.com/cloudwatch" target="_blank">CloudWatch</a> techniques.</li><li id="d9b2">If you think of additional debugging features that would help you and the community at large, don’t hesitate to submit a feature request!</li></ol></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="ae1f"><strong class="markup--h3-strong">Chapter 8: Using Spot Instances on Sagemaker</strong></h3><p id="c00f">Recently, AWS announced support for training in <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> on Spot Instances.</p><div class="graf--mixtapeEmbed" id="4d3b"><a class="markup--mixtapeEmbed-anchor" href="https://aws.amazon.com/blogs/aws/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs/" title="https://aws.amazon.com/blogs/aws/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs/"><strong class="markup--mixtapeEmbed-strong">Managed Spot Training: Save Up to 90% On Your Amazon SageMaker Training Jobs | Amazon Web Services</strong><br/><em class="markup--mixtapeEmbed-em">is a fully-managed, modular machine learning (ML) service that enables developers and data scientists to easily build…</em>aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="968d229035a164d0d2a86adb3a67b5b1" data-thumbnail-img-id="0*EbhZZHYfu105xThI" href="https://aws.amazon.com/blogs/aws/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs/" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*EbhZZHYfu105xThI);"></a></div><p class="graf-after--mixtapeEmbed" id="b574">Spot Instances let you take advantage of unused compute capacity in the cloud, allowing you to significantly reduce cost. The catch, of course, is that if the machine is suddenly needed by a customer willing to pay the full price, your compute (in our case your training session) will be terminated midway and your training instance will be taken away from you. The good news is that <a href="https://aws.amazon.com/sagemaker/" target="_blank">SageMaker</a> will <strong class="markup--p-strong">restart your training session</strong> as soon as a new Spot Instance is available. Of course, there is no guarantee how long that might take.</p><blockquote class="graf--pullquote" id="bc3c">The opportunity to reduce cost is quite compelling.</blockquote><p class="graf-after--pullquote" id="68bc">Still, imagine training for a day or two or three, only to have your instance terminated on your last epoch!! Imagine the gut-wrenching, blood-curling despair.</p><p id="fc49">Of course, there is an easy solution for that, and that is to <strong class="markup--p-strong">periodically store checkpoints of your model during training</strong>.</p><blockquote class="graf--pullquote" id="9d50">If your training algorithm is halted midway, the job simply resumes from the latest stored checkpoint.</blockquote><p class="graf-after--pullquote" id="12d8">This is extremely straightforward when using <a href="https://www.tensorflow.org/" target="_blank">TensorFlow</a> estimators, which automatically searches for an existing checkpoint in your model directory when it starts up. All that is left for you to do, is to decide on the frequency at which you want to store checkpoints.</p><div class="graf--mixtapeEmbed" id="7be6"><a class="markup--mixtapeEmbed-anchor" href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html" title="https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html"><strong class="markup--mixtapeEmbed-strong">Using Checkpoints in Amazon SageMaker</strong><br/><em class="markup--mixtapeEmbed-em">A checkpoint is a snapshot of the state of the model. They can be used with Managed Spot Training. If a training job is…</em>docs.aws.amazon.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="6b30c7319cacbba72f85d7bbd4ef8849" data-thumbnail-img-id="0*HtQjVBhZErH7D7OM" href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*HtQjVBhZErH7D7OM);"></a></div><p class="graf-after--mixtapeEmbed" id="6908">But there is another, somewhat more delicate thing to consider. Suppose, you have the wild misfortune of having your Spot Instance terminated ten consecutive times, right after you have traversed precisely the first fifth of your data. The net effect is that you have trained your network (for ten epochs) on precisely a fifth of your data. You have not seen the rest of the data at all. You could see why that would be a problem as your model will biased towards the data it has seen.</p><p id="8ce3">Ideally, you would like to return to the exact location you were at before you were terminated (or more accurately, the location where the last checkpoint was saved), but this is not possible (today) in <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-model-training-using-faster-pipe-mode-on-amazon-sagemaker/" target="_blank">Pipe Mode</a>.</p><p id="52a5">This problem is alleviated when you use the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/API_ShuffleConfig.html" target="_blank"><em class="markup--p-em">ShuffleConfig</em></a> class as we described above. This will ensure that each time the training restarts, it will <strong class="markup--p-strong">start from a different location and on a different ordering of the data</strong>. This is likely to prevent the danger of developing a bias towards a subset of your data.</p><p id="92c9">My non-binding advice would be to definitely take advantage of Spot Instances to reduce cost, but perhaps consider keeping your critical sessions on regular (non-spot) instances.</p></div></div></section><section class="section"><div><hr/></div><div><div><h3 id="4aeb"><strong class="markup--h3-strong">Chapter 9: Summary</strong></h3><p id="1f47">With that, I have come to the end of my story; the story of how we made <a href="https://aws.amazon.com/sagemaker/" target="_blank"><strong class="markup--p-strong">SageMaker</strong></a><strong class="markup--p-strong"> work for us.</strong></p><p id="224b">Yes, as with the adoption of any new development environment, we had to go through some hoops and hurdles, especially given the scale at which we operate. We got some unexpected benefits, and I hope I have convinced you that <a href="https://aws.amazon.com/sagemaker/" target="_blank"><strong class="markup--p-strong">SageMaker</strong></a><strong class="markup--p-strong"> can work for you too!</strong></p></div></div></section>
</section>
</article></body></html>
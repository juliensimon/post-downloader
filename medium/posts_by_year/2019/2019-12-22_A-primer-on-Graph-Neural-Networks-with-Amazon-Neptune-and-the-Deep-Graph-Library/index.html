<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>A primer on Graph Neural Networks with Amazon Neptune and the Deep Graph Library</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="bd10">A primer on Graph Neural Networks with Amazon Neptune and the Deep Graph Library</h3><p id="f9c9">In this post, I’d like to introduce you to <strong class="markup--p-strong">Graph Neural Networks</strong> (GNN), one of the most exciting developments in Machine Learning (ML) today. Indeed, lots of datasets have an intrinsic graph structure (social networks, fraud detection, cybersecurity, etc.). Flattening them and feeding them to traditional neural network architectures doesn’t feel like the best option. Enter GNNs!</p><p id="32cc">Instead of simply running a sample notebook, let’s throw a few extra ingredients into the mix. In a real life scenario, your graph data would be stored in a <strong class="markup--p-strong">graph database</strong>, such as <a href="https://aws.amazon.com/neptune/" target="_blank"><strong class="markup--p-strong">Amazon Neptune</strong></a>. You’d pull some data from that database, load it in a notebook, and experiment with an <strong class="markup--p-strong">ML library specialized for GNNs</strong>, such as the <a href="https://www.dgl.ai" target="_blank"><strong class="markup--p-strong">Deep Graph Library</strong></a>. Then, once you’d have figured out which algorithm to use, you’d probably train on the full dataset using a <strong class="markup--p-strong">ML service</strong> such as <a href="https://aws.amazon.com/sagemaker" target="_blank"><strong class="markup--p-strong">Amazon SageMaker</strong></a><strong class="markup--p-strong">.</strong></p><p id="8b2d">So how about I show you all of that? Let’s get to</p><h3 id="5346">Creating a graph database</h3><p id="5cec"><a href="https://aws.amazon.com/neptune" target="_blank">Amazon Neptune</a> is a fully managed graph database service.It supports two query languages, Apache TinkerPop Gremlin and W3C’s SPARQL.</p><p id="4b85">Creating a Neptune database is extremely similar to setting up <a href="https://aws.amazon.com/rds" target="_blank">RDS</a>. The simplest way is to use <a href="https://docs.aws.amazon.com/neptune/latest/userguide/get-started-create-cluster.html" target="_blank">this</a> AWS CloudFormation <a href="https://docs.aws.amazon.com/neptune/latest/userguide/get-started-create-cluster.html" target="_blank">template</a>. If you want to use the AWS console, the <a href="https://docs.aws.amazon.com/neptune/latest/userguide/manage-console-launch.html" target="_blank">procedure</a> is straightforward.</p><p id="0113">After a few minutes, my Neptune database is up, and we’re ready to load data.</p><figure id="816b"><img class="graf-image" src="image07.webp"/></figure><h3 id="868b">Picking a data set</h3><p id="8aae">Let’s use the proverbial <a href="http://konect.cc/networks/ucidata-zachary/" target="_blank">Zachary Karate Club</a> data set. It contains 34 vertices and 78 bidirectional edges.</p><figure id="1169"><img class="graf-image" src="image02.webp"/></figure><p id="77a5">As the story goes, edges represents ties between <strong class="markup--p-strong">students</strong> and <strong class="markup--p-strong">two teachers</strong> (nodes 0 and 33). Unfortunately, after an argument between the teachers, the group needs to be split in two. That’s the problem we’re going to solve with a GNN: more on this in a few minutes!</p><figure id="4f0c"><img class="graf-image" src="image04.webp"/><figcaption>All along, this was a machine learning story. Who would have thought?</figcaption></figure><h3 id="0440">Formatting the data set</h3><p id="b50e">Neptune accepts different <a href="https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-tutorial-format.html" target="_blank">file formats</a>. I’ll go with the <a href="https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-tutorial-format-gremlin.html" target="_blank">Gremlin format</a>:</p><ul class="postList"><li id="9e16"><strong class="markup--li-strong">Two CSV files</strong>: one for vertices, one for edges.</li><li id="4601"><strong class="markup--li-strong">Vertex file</strong>: id (mandatory), plus a name property (optional).</li><li id="691f"><strong class="markup--li-strong">Edge file</strong>: id, source vertex, destination vertex (all three are mandatory).</li></ul><blockquote class="graf--blockquote graf--hasDropCapModel" id="fbab">Vertex is just a fancy word for node.</blockquote><p class="graf-after--blockquote" id="b2ab">Of course, you can (and should) add many more properties in both files.</p><p id="9e6d">Here are the two files in Gremlin format.</p><figure id="44cf"><script src="https://gist.github.com/juliensimon/cfcbc15e3e98475851c7c4a913c46c41.js"></script></figure><figure id="6c59"><script src="https://gist.github.com/juliensimon/d323d16296db6090accb0696832f0a52.js"></script></figure><h3 id="461d">Loading the data set in Neptune</h3><p id="4190">Neptune is a little peculiar when it comes to loading data:</p><ol class="postList"><li id="ca80"><strong class="markup--li-strong">A database is only accessible inside og the VPC hosting it. </strong>For exemple, you could load data using an EC2 instance or a Lambda function living in that same VPC.</li><li id="f822"><strong class="markup--li-strong">Neptune requires a VPC Endpoint for S3 in the VPC</strong>. This allows Neptune to access S3 directly without using public endpoints. <a href="https://docs.aws.amazon.com/neptune/latest/userguide/bulk-load-data.html#bulk-load-prereqs-s3" target="_blank">Creating the endpoint</a> takes a few seconds, and you only need to do it once per VPC.</li><li id="eb3b"><strong class="markup--li-strong">Data loading is initiated by a </strong><a href="https://curl.haxx.se/" target="_blank"><strong class="markup--li-strong"><em class="markup--li-em">curl</em></strong></a><strong class="markup--li-strong"> call</strong>. Nothing weird, just pay attention to the parameters.</li></ol><p id="e7be">Ok, with this out of the way, let’s load data. First, I’m copying my two files in an S3 bucket hosted in the same region as my Neptune cluster.</p><pre class="graf--pre" id="8337">$ aws s3 cp edges.csv s3://jsimon-neptune-useast-1/dgl/<br/>$ aws s3 cp nodes.csv s3://jsimon-neptune-useast-1/dgl/</pre><p class="graf-after--pre" id="4867">Then, it’s time for that <em class="markup--p-em">curl</em> call, using the <strong class="markup--p-strong">cluster endpoint</strong> visible in the AWS console, or in the output of the CloudFormation template. I’m using the us-east-1 region, you should of course change this if you use a different region.</p><pre class="graf--pre" id="a0e5">$ curl -X POST \<br/> -H ‘Content-Type: application/json’ \<br/> <a class="markup--pre-anchor" href="https://neptune-instance-1.c0n7pykyhnp4.us-east-1.neptune.amazonaws.com:8182/loader" rel="nofollow noopener noopener" target="_blank">https://ENDPOINT:PORT/loader</a> -d ‘<br/> {<br/> “source” : “s3://jsimon-neptune-useast-1/dgl/”,<br/> “format” : “csv”,<br/> “iamRoleArn” : “arn:aws:iam::123456789012:role/NeptuneRoleForS3”,<br/> “region” : “us-east-1”,<br/> “failOnError” : “FALSE”,<br/> “parallelism” : “MEDIUM”,<br/> “updateSingleCardinalityProperties” : “FALSE”<br/> }’</pre><p class="graf-after--pre" id="654f">If everything is set right, this returns a 200 HTTP status and a job id: I can use it to check if data loading worked ok.</p><pre class="graf--pre" id="95ce">$ curl -G ‘<a class="markup--pre-anchor" href="https://neptune-instance-1.c0n7pykyhnp4.us-east-1.neptune.amazonaws.com:8182/loader/8af0f90a-9b72-4835-ab55-2de58918aa81%27" rel="nofollow noopener noopener" target="_blank">https://ENDPOINT:PORT/loader/8af0f90a-9b72-4835-ab55-2de58918aa81'</a><br/>{<br/> “status” : “200 OK”,<br/> “payload” : {<br/> “feedCount” : [<br/> {<br/> “LOAD_COMPLETED” : 2<br/> }<br/> ],<br/> “overallStatus” : {<br/>   “fullUri” : “s3://jsimon-neptune-useast-1/dgl/”,<br/>   “runNumber” : 1,<br/>   “retryNumber” : 0,<br/>   “status” : “LOAD_COMPLETED”,<br/>   “totalTimeSpent” : 6,<br/>   “startTime” : 1576847947,<br/>   “totalRecords” : 146,<br/>   “totalDuplicates” : 0,<br/>   “parsingErrors” : 0,<br/>   “datatypeMismatchErrors” : 0,<br/>   “insertErrors” : 0<br/> }<br/> }</pre><blockquote class="graf--blockquote graf--hasDropCapModel graf-after--pre" id="b594">Things to check (in this order) if you’re having issues: are you in the same VPC? Are you using the correct endpoint and port for Neptune? Is the Security Group for Neptune OK? Is the IAM Role for Neptune OK? Does the S3 Endpoint exist, and does it allow access (endpoint policy) ? Does the S3 bucket exist, and does it allow access (bucket policy)? Do files exist and have the right format? If you still can’t figure it out, the <a class="markup--blockquote-anchor" href="https://forums.aws.amazon.com/forum.jspa?forumID=253" target="_blank">AWS Forum for Neptune</a> is waiting for you ;)</blockquote><p class="graf-after--blockquote" id="8a57">Now let’s connect to Neptune, and explore out data a bit.</p><h3 id="5046">Exploring graph data with Gremlin</h3><p id="0562">You can query a Neptune using <a href="https://docs.aws.amazon.com/neptune/latest/userguide/access-graph-gremlin.html" target="_blank">different languages</a>. I’ll use Python with the <a href="https://pypi.org/project/gremlinpython/" target="_blank"><em class="markup--p-em">gremlinpython</em></a> library.</p><pre class="graf--pre" id="dcda">$ pip3 install <a class="markup--pre-anchor" href="https://pypi.org/project/gremlinpython/" target="_blank">gremlinpython</a> --user</pre><p class="graf-after--pre" id="e3fd">Connecting to the Neptune database only requires its endpoint and its port.</p><blockquote class="graf--blockquote graf--hasDropCapModel" id="f6bd">Remember that this code must be run inside the appropriate VPC!</blockquote><figure class="graf-after--blockquote" id="59d2"><script src="https://gist.github.com/juliensimon/6fbe10cd9f532eb06908afecac6c981a.js"></script></figure><p id="c930">Now, I can explore the graph with the <a href="https://tinkerpop.apache.org/gremlin.html" target="_blank">Gremlin</a> query language. Here are some examples.</p><figure id="c41e"><script src="https://gist.github.com/juliensimon/cb01a263caa17e2ba012c73135003e0f.js"></script></figure><p id="e6d8">There’s <a href="https://tinkerpop.apache.org/gremlin.html" target="_blank">much much more</a> to this, but I’ll stop there. Actually, the only thing that I need to build the graph in my Deep Graph Library script is a <strong class="markup--p-strong">list of all edges</strong>.</p><p id="01b0">Let’s grab that, and save it to a <a href="https://docs.python.org/3/library/pickle.html" target="_blank"><em class="markup--p-em">pickle</em></a> file.</p><figure id="a6be"><script src="https://gist.github.com/juliensimon/bf403673ab3c4a691f86cb1f0ac70cad.js"></script></figure><p id="a036">We’re done with data processing. Let’s now train a GNN!</p><h3 id="2612">Training our first GNN with the Deep Graph Library</h3><p id="ce46">The <a href="https://dgl.ai" target="_blank">Deep Graph Library</a> (DGL) is an open source project that simplifies working with GNN models. It’s implemented in Python, and supports <a href="https://mxnet.apache.org" target="_blank">Apache MXNet</a> and <a href="https://pytorch.org" target="_blank">PyTorch</a>.</p><pre class="graf--pre" id="d8b1">$ pip3 install dgl --user</pre><p class="graf-after--pre" id="d08c">In the next sections, I’m using a modified version on this <a href="https://docs.dgl.ai/tutorials/basics/1_first.html" target="_blank">tutorial</a>. As usual, the notebook is available on <a href="https://gitlab.com/juliensimon/dlnotebooks/tree/master/dgl/01_karate_club" target="_blank">Github</a>.</p><p id="cac5">I also recorded a video where I go through the notebook, and explain every line of code in more detail that you probably care for ;)</p><figure id="8b16"><iframe frameborder="0" height="393" scrolling="no" src="https://www.youtube.com/embed/2bfxnj1J00A?feature=oembed" width="700"></iframe></figure><h4 id="5557">Building the graph</h4><p id="4176">First things first: we need to load the list of edges, and build our graph.</p><figure id="6090"><script src="https://gist.github.com/juliensimon/5bb079d9eea91e0f79ddab3729a536e6.js"></script></figure><h4 id="a386">Defining the problem</h4><p id="347b">Let’s think about our initial problem for a minute. For each node (student), we want to figure out if it should be grouped with node 0 (the first teacher) or with node 33 (the second teacher).</p><p id="a897">We can formulate this as a <strong class="markup--p-strong">semi-supervised binary classification problem</strong>:</p><ul class="postList"><li id="40b5">Let’s label node 0 with class 0,</li><li id="70ff">Let’s label node 33 with class 1,</li><li id="ba65">All other nodes are unlabeled, and the purpose of the training job will be to learn their correct class.</li></ul><h4 id="bdf4">Building the GNN</h4><p id="5d6b">Now let’s build the GNN itself. We’ll use a <strong class="markup--p-strong">Graph Convolutional Network</strong> (GCN), with the following structure:</p><ul class="postList"><li id="ceff"><strong class="markup--li-strong">Two GCN layers</strong> (which we’ll define in a minute). Their purpose is to <strong class="markup--li-strong">learn parameters</strong> that will help us compute classes for all nodes. In the process, they also gradually <strong class="markup--li-strong">shrink the feature space</strong> to two dimensions (one for each class).</li><li id="e27e"><strong class="markup--li-strong">A built-in softmax layer</strong>, in order to output probabilities for the two classes.</li></ul><figure id="de7d"><script src="https://gist.github.com/juliensimon/54be78df11515fe1cada9fd5cc912425.js"></script></figure><p id="fc70"><strong class="markup--p-strong">Forward propagation</strong> for a GCN layer looks like this:</p><ul class="postList"><li id="7775">Set input features for all nodes,</li><li id="bed5">Ask each node to <strong class="markup--li-strong">send its features</strong> across all its edges,</li><li id="186c">At each destination node, <strong class="markup--li-strong">update features to the sum of source node features</strong> (this is the secret sauce in GCNs),</li><li id="eef8">Apply a linear transformation (think Y=WX+B… with matrices) to <strong class="markup--li-strong">reduce dimensionality</strong>.</li></ul><p id="f110">As you can see in the code below, DGL provides simple <strong class="markup--p-strong">message passing semantics</strong> to handle node communication.</p><figure id="4383"><script src="https://gist.github.com/juliensimon/fb07ea736fd34bd863decd2c70b3c48e.js"></script></figure><p id="d4a1">Let me repeat the central idea in GCNs: <strong class="markup--p-strong">the features of each node will be repeatedly updated by summing the features of adjacent nodes</strong>. This is similar to the <a href="http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html" target="_blank">convolution</a> operation implemented in Convolution Neural Networks (which sums adjacent pixel values), hence the GCN name.</p><blockquote class="graf--blockquote" id="0d09">Why this works is beyond the scope of this post. If you’re curious about GCN theory, this excellent <a class="markup--blockquote-anchor" href="https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780" target="_blank">2-part post</a> is the best I’ve found. Of course, you can also read the <a class="markup--blockquote-anchor" href="https://arxiv.org/abs/1609.02907" target="_blank">research paper</a>.</blockquote><h4 class="graf-after--blockquote" id="5d38">Training the GNN</h4><p id="903f">Input features are stored in a matrix <em class="markup--p-em">(number_of_nodes</em> lines and <em class="markup--p-em">number_of_features</em> columns).</p><p id="5c86">Here, the only feature for each node is a <strong class="markup--p-strong">one-hot encoded vector representing the node id</strong>. Stacking all node vectors, we get an identity matrix of size <em class="markup--p-em">node_count</em>, which we can easily build with <a href="https://pytorch.org/docs/stable/torch.html" target="_blank"><em class="markup--p-em">torch.eye()</em></a>.</p><p id="0e85">DGL makes it easy to assign node features. In the code above, <em class="markup--p-em">g.ndata[‘h’] = inputs </em>creates a feature named ‘h’ on each node, and sets it to the appropriate row in the <em class="markup--p-em">inputs</em> matrix.</p><blockquote class="graf--blockquote" id="a9e0">In a real-life scenario, we would use more features, probably extracted or computed from the graph database, e.g. node properties, distance to nodes 0 and 33, etc.</blockquote><p class="graf-after--blockquote" id="154f">We also need to <strong class="markup--p-strong">define labels</strong>: we only label nodes 0 and 33, respectively with class 0 and 1.</p><figure id="81e6"><script src="https://gist.github.com/juliensimon/374b47b5559299c00ae390dfd2220864.js"></script></figure><p id="9f00">The training loop itself is PyTorch business as usual:</p><ul class="postList"><li id="b3e6">Run <strong class="markup--li-strong">forward propagation </strong>on the graph and its inputs,</li><li id="a96e">Compute the <strong class="markup--li-strong">loss</strong> between predictions and labels (only for labeled nodes),</li><li id="63bf">Run <strong class="markup--li-strong">backpropagation,</strong> and update layer weights.</li></ul><figure id="4d05"><script src="https://gist.github.com/juliensimon/d30307dd71c68f11c6ece0aa86315b4f.js"></script></figure><p id="2813">Let’s try to put this in plain English: <strong class="markup--p-strong">by learning from two labeled nodes, we update layer parameters that let us compute class probabilities for all other nodes</strong>.</p><h4 id="80e7">Visualizing results</h4><p id="7e99">Once training is complete, we can easily find the class of all nodes by looking at the epoch outputs.</p><figure id="a9fb"><script src="https://gist.github.com/juliensimon/791fea21ec401b318f9458b300e61e26.js"></script></figure><p id="6ce2">A picture is worth a thousand words!</p><figure id="4dc7"><img class="graf-image" src="image05.webp"/><figcaption>Epoch 10</figcaption></figure><figure id="fdee"><img class="graf-image" src="image06.webp"/><figcaption>Epoch 20</figcaption></figure><figure id="f43c"><img class="graf-image" src="image03.webp"/><figcaption>Last epoch</figcaption></figure><p id="58ec">Pretty cool! This looks like a reasonable split, doesn’t it?</p><h3 id="794e">Training at scale with Amazon SageMaker</h3><p id="1a5f">DGL is available in the <a href="https://docs.aws.amazon.com/dlami/latest/devguide/deep-learning-containers-images.html" target="_blank">AWS Deep Learning Containers</a>, which you can easily train on EC2, container services, and of course on <a href="https://aws.amazon.com/sagemaker$" target="_blank">Amazon SageMaker</a>.</p><figure id="09ba"><img class="graf-image" src="image01.webp"/></figure><p id="9c91">If you’d like to know more about combining DGL and SageMaker, here are some resources:</p><ul class="postList"><li id="8029"><a href="https://aws.amazon.com/blogs/aws/now-available-on-amazon-sagemaker-the-deep-graph-library/" target="_blank">Blog post,</a></li><li id="12f9">AWS <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/deep-graph-library.html" target="_blank">documentation,</a></li><li id="36c1">Sample <a href="https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker-python-sdk" target="_blank">notebooks</a>.</li></ul><h3 id="de21">Conclusion</h3><p id="cd99">That’s it for today. I hope you now have a basic understanding of GNNs, and how to get started with them on AWS.</p><p id="d8a3">As always, thank you for reading. Happy to answer questions here or on <a href="https://twitter.com/julsimon" target="_blank">Twitter</a>.</p></div></div></section>
</section>
</article></body></html>

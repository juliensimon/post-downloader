<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>AWS re:Invent 2021 — A first look at SageMaker Canvas</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="ef31">AWS re:Invent 2021 — A first look at SageMaker Canvas</h3><p id="006c">Last night, AWS launched <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/canvas.html" target="_blank">SageMaker Canvas</a>, “<em class="markup--p-em">a visual, no-code interface to build accurate machine learning models</em>”. Let’s have at it, then.</p><pre class="graf--pre" id="52a8">December 3rd update: here’s the second look, with a different data set: <a class="markup--pre-anchor" href="https://youtu.be/_qgNMirKq6A" rel="nofollow noopener" target="_blank">https://youtu.be/_qgNMirKq6A</a>. Read the blog post first :)</pre><h3 class="graf-after--pre" id="daf6">Once upon a time…</h3><p id="aef5">Some of you may remember <a href="https://aws.amazon.com/blogs/aws/amazon-machine-learning-make-data-driven-decisions-at-scale/" target="_blank">Amazon Machine Learning</a>, AWS’ first attempt at no-code machine learning. Launched in April 2015, the service let users pull tabular data from S3 or Redshift, in order to train and deploy models on managed infrastructure. Supported task types included binary classification, multi-class classification and linear regression models.</p><p id="1954">I reviewed it in depth at the time (<a href="http://blog.julien.org/2015/04/test-drive-aws-machine-learning-redshift.html" target="_blank">part 1</a>, <a href="http://blog.julien.org/2015/04/test-drive-real-time-prediction-with.html" target="_blank">part 2</a>, <a href="http://blog.julien.org/2015/04/test-drive-real-time-prediction-in-java.html" target="_blank">part 3</a>), and actually liked it. Unfortunately, almost everyone else disagreed. Adoption was awful, and the service was quietly <a href="https://forums.aws.amazon.com/thread.jspa?threadID=301990" target="_blank">deprecated</a> in early 2019, a very rare event in AWS land. Why it failed is up for debate. Too simplistic for ML-savvy users, too fancy for business users, wrong timing, too expensive, etc. Oh well.</p><p id="8564">Licking their wounds, AWS went back to the drawing board, and launched <a href="http://aws.amazon.com/sagemaker" target="_blank">SageMaker</a> in late 2017. Targeted at data scientists and ML engineers, this new service did arguably much better, thanks to a handy SDK that leverages managed infrastructure and powerful ML capabilities.</p><p id="324a">Of course, it was only a matter of time until the “ML for business users” discussion would pop up again. SageMaker Canvas, then.</p><h3 id="c292">Unboxing SageMaker Canvas</h3><p id="7342">You can access Canvas from the SageMaker Studio console, and launch it just like you would launch SageMaker Studio. After a few minutes of initial setup, the Canvas UI pops up.</p><p id="27d8">We’re greeted by a short intro that introduces the Canvas workflow. +1 for usability.</p><figure id="0f15"><img class="graf-image" src="image19.webp"/></figure><h4 id="9868">Selecting data</h4><p id="2e12">Basic users can upload files from:</p><ul class="postList"><li id="6227">Their local machine, although this option was greyed out for me (“<em class="markup--li-em">Contact your administrator</em>”: huh?).</li><li id="27f1">An S3 bucket.</li></ul><p id="9e15">The documentation fails to list supported file types. Apparently, CSV is the only option for now. On the positive side, joins are supported using a drag and drop interface, without the need for any SQL code.</p><p id="e4d7">Alternatively, more advanced users are able to connect to a <a href="http://aws.amazon.com/redshift" target="_blank">Redshift</a> or a <a href="https://www.snowflake.com" target="_blank">Snowflake</a> database. They can then run their own SQL code to pull and join data.</p><p id="5181">Here, I’ll simply import the <a href="https://www.kaggle.com/c/titanic" target="_blank">Titanic survivor</a> dataset from an S3 bucket. It only takes a couple of clicks.</p><figure id="d2aa"><img class="graf-image" src="image17.webp"/></figure><h4 id="5118">Building a model</h4><p id="1fe3">Creating a new model, I first select the dataset that I just imported.</p><figure id="7bdd"><img class="graf-image" src="image15.webp"/></figure><p id="6015">Next, I pick the column I’d like to predict (<code class="markup--code markup--p-code">Survived</code>).</p><figure id="f1f9"><img class="graf-image" src="image05.webp"/></figure><p id="4173">The model type is automatically inferred from the target column, which is fine. I could also set it myself if I wanted. Now, <strong class="markup--p-strong">why on earth would you say “2 category” instead of “binary classification”, “3+ category” instead of multi-class classification, or “number” instead of linear regression? This sounds weird (even a bit silly), and it will only confuse everyone</strong>. Industry standard terms, please!</p><figure id="4af8"><img class="graf-image" src="image02.webp"/><figcaption>No, no, no, hell no</figcaption></figure><p id="de9b">I also see basic statistics and visualizations on the dataset. Good stuff, although I’d have preferred to get them right after uploading the dataset, without having to create a model.</p><figure id="99ec"><img class="graf-image" src="image09.webp"/></figure><p id="2187">Clicking on a column shows a summary.</p><figure id="e19a"><img class="graf-image" src="image01.webp"/></figure><p id="2f2e">I could also untick columns that I don’t want to include for training. Keeping all columns, I click on “Quick Build” to… build a quick model, I guess. Training fails almost immediately, and I get the following error message:</p><figure id="3bec"><img class="graf-image" src="image03.webp"/><figcaption><em class="markup--figure-em">Spoiler: the </em><code class="markup--code markup--figure-code"><em class="markup--figure-em">'Cabin'</em></code><em class="markup--figure-em"> column is responsible. It’s 77.1% empty</em></figcaption></figure><p id="5e99">This is likely to frustrate and confuse your average business user:</p><ul class="postList"><li id="e913">SHAP values? Whatever they are, I wasn’t told about them earlier.</li><li id="4571">If my dataset has too many missing values, why wasn’t I told earlier? The offending column(s) should have been highlighted at the basic stats stage.</li><li id="0ee4">If SHAP values can’t be computed, why not proceed without them and add a mention in the model summary?</li></ul><p id="74fa">Deleting the failed model (why can’t I retry right away?), I create a new one, select the dataset, and unselect the offending column.</p><figure id="9dc6"><img class="graf-image" src="image13.webp"/></figure><p id="410a">Then, I run a quick build again.</p><figure id="159d"><img class="graf-image" src="image12.webp"/></figure><h4 id="ec1e">Analyzing results</h4><p id="2757">Results are available after a couple of minutes. This is way too fast for a regular SageMaker job. Maybe this ran in place, similar to the “<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler-analyses.html" target="_blank">Quick Model</a>” feature in SageMaker Data Wrangler?</p><p id="e1eb">Model accuracy is not great, but it’s high enough to justify launching a full training later on. Feature importance (aka “column impact”) is nicely graphed using box plots and scatter plots, although I’m missing zooming capabilities.</p><figure id="35da"><img class="graf-image" src="image14.webp"/></figure><p id="567c">I also get a fancy representation of the confusion matrix.</p><figure id="8a9b"><img class="graf-image" src="image06.webp"/></figure><p id="f002">… as well proper ML metrics.</p><figure id="96e4"><img class="graf-image" src="image04.webp"/></figure><p id="7573">Creating another model (why can’t I reuse the quick build?), I launch a full training job which runs for a few hours (<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-automate-model-development.html" target="_blank">SageMaker AutoPilot</a> **cough cough**).</p><p id="f427">Metrics are significantly better.</p><figure id="1309"><img class="graf-image" src="image08.webp"/></figure><p id="c370">Apparently, I could <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-collaborate.html" target="_blank">share</a> the model in SageMaker Studio. The feature didn’t work for me.</p><figure id="faf0"><img class="graf-image" src="image18.webp"/></figure><h4 id="36f4">Generating predictions</h4><p id="2464">I can use my model to predict new data, either in batch mode or in single prediction mode. For simplicity, I’ll use the training set.</p><p id="6b4b">First, I launch batch prediction in a couple of clicks.</p><figure id="d005"><img class="graf-image" src="image11.webp"/></figure><p id="fe5d">After a few seconds, results are available, and I can download them to a CSV file.</p><figure id="38e6"><img class="graf-image" src="image07.webp"/></figure><p id="a7a6">Predictions are archived for future use. I was unable to delete them, as the button was greyed out.</p><figure id="2f60"><img class="graf-image" src="image10.webp"/></figure><p id="1043">I also couldn’t test single predictions. Hmm.</p><figure id="a442"><img class="graf-image" src="image16.webp"/></figure><h3 id="4842">Summing things up</h3><p id="e540">So do I like Canvas or what? Here goes nothing.</p><h4 id="d99e">The good</h4><ul class="postList"><li id="63a6"><strong class="markup--li-strong">SageMaker Canvas does what it says on the tin</strong>: zero-code ML for the most popular ML problems in the enterprise (classification, regression and time-series).</li><li id="1575"><strong class="markup--li-strong">The UI is reasonably clear and friendly</strong>, although I’d like to be able to resize panels (a long lasting plague of many AWS consoles), and to zoom on visualizations.</li><li id="78a8"><strong class="markup--li-strong">I would expect Canvas jobs to be as accurate as code-based jobs</strong>. Indeed, it’s safe to assume that model training is based on SageMaker AutoPilot and <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-set-up-forecast.html" target="_blank">Forecast</a>, which support built-in feature engineering, model tuning, etc.</li><li id="d9eb"><strong class="markup--li-strong">Batch predicting with Canvas models is simple enough</strong>, without having to deal with any inference-time muck (the one thing I dislike the most about SageMaker in general).</li></ul><h4 id="8246">The bad</h4><ul class="postList"><li id="5b61"><strong class="markup--li-strong">Canvas only supports tabular data</strong> (categorical, numeric, text, datetime), and input file formats seem to be limited to uncompressed CSV (we won’t know for sure until the <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-importing-data.html" target="_blank">doc</a> actually says something useful). Users with slightly more complex data will have to deal with data preparation, and…</li><li id="5f48"><strong class="markup--li-strong">Canvas is not integrated with data preparation tools</strong>. If you have a pristine CSV file, lucky you. What if you need to transform it or clean it a bit? UI integration with <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/data-wrangler.html" target="_blank">SageMaker Data Wrangler</a> or <a href="https://docs.aws.amazon.com/databrew/latest/dg/what-is.html" target="_blank">Glue Data Brew</a> would go a long way in building a seamless experience. No-code ML needs no-code data preparation.</li><li id="1433"><strong class="markup--li-strong">Prediction cannot be automated</strong>. Imagine that I need to predict a new CSV file every day. Do I need to manually upload it to S3 and use the Canvas console to predict it? Is there a path to automation? Maybe that’s the model sharing capability in Studio, but I couldn’t test it.</li><li id="3e11"><strong class="markup--li-strong">Canvas looks </strong><a href="https://aws.amazon.com/sagemaker/canvas/pricing/" target="_blank"><strong class="markup--li-strong">expensive</strong></a>. $1.9 per hour for the console? $30 for a one-million cell training job? I could train the same dataset (50K rows with 20 features) on an ml.m5.large spot instance for a <strong class="markup--li-strong">fraction</strong> of that, and write 50 lines of Python to automate it for my business users… Am I missing something here?</li></ul><h4 id="df71">The ugly</h4><p id="b2e5">I know all too well how the pressure of lauching services at re:Invent, but…</p><ul class="postList"><li id="59c4"><strong class="markup--li-strong">Documentation is as minimal as it could be</strong>.</li><li id="275c"><strong class="markup--li-strong">Too many features are broken at launch.</strong></li></ul><h3 id="4c54">Conclusion</h3><p id="8729">So where does that leave me? Honestly, I’m not sure. Canvas works (transient bugs aside), but it’s not groundbreaking in any way. The feature set is pretty much the same as Amazon Machine Learning in 2015. On the ML timescale, that’s a <strong class="markup--p-strong">century</strong> ago. What about computer vision, natural language processing, multi-modal datasets, ensembling, Transformers, etc.? And yes, enterprise customers use these. I talk to them every day.</p><p id="b947">Is Canvas on the right side of the MVP border, and will it generate enough excitement to encourage AWS to iterate quickly on it?</p><p id="3b64">Or is it too little too late?</p><p id="6dec">I’m cautiously leaning towards the former, but it’s too early to tell.</p></div></div></section>
</section>
</article></body></html>

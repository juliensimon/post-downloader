<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>A hands-on look at the Amazon Rekognition API</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="9a7e">A hands-on look at the Amazon Rekognition API</h3><p id="efe6">Amazon Rekognition is a Deep Learning based image analysis service. Don’t worry though, you won’t have to wade through Machine Learning / Deep Learning mumbo jumbo to work with Recognition. Quite the contrary, as Rekognition provides a very easy-to-use API. <br/> <br/> It allows developers to:</p><ul class="postList"><li id="6f09">detect thousands of objects and scenes;</li><li id="ec7f">analyze faces;</li><li id="27f7">compare two faces to measure similarity;</li><li id="49b1">build face collections and match faces against these collections.</li></ul><p id="3276">As usual, this service can be used with the <a href="https://github.com/aws/aws-cli" target="_blank">AWS CLI</a> (as in ‘<em class="markup--p-em">aws rekognition</em>’ ), or with one of our language SDKs. I’ll show you some CLI examples first and then we’ll use the popular Python SDK, aka <a href="https://github.com/boto/boto3" target="_blank">boto3</a>.</p><p id="1bf1">First things first: how do we send images for processing? Two options: send the image as a byte blob or put it in S3. I suspect the most of use will use the second option, so that’s what I’ll use. Time to play!</p><figure id="6c39"><img class="graf-image" src="image03.webp"/></figure><p id="c458"><code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ aws rekognition detect-faces --image "S3Object={Bucket="jsimon-public", Name="<a href="https://jsimon-public.s3.amazonaws.com/julien1.jpg" target="_blank">julien1.jpg</a>"}" </code><br/> <code class="markup--code markup--p-code"><br/></code> <code class="markup--code markup--p-code">{ "FaceDetails": [ { "BoundingBox": { "Width": 0.3883333206176758, "Top": 0.12222222238779068, "Left": 0.33666667342185974, "Height": 0.2588889002799988 }, "Landmarks": [ { "Y": 0.23426248133182526, "X": 0.46131378412246704, "Type": "eyeLeft" }, { "Y": 0.22791674733161926, "X": 0.5936729311943054, "Type": "eyeRight" }, { "Y": 0.27828338742256165, "X": 0.5404868721961975, "Type": "nose" }, { "Y": 0.3229646682739258, "X": 0.48395034670829773, "Type": "mouthLeft" }, { "Y": 0.31654009222984314, "X": 0.5957114696502686, "Type": "mouthRight" } ], "Pose": { "Yaw": 4.216298580169678, "Roll": -4.777482509613037, "Pitch": -2.406636953353882 }, "Quality": { "Sharpness": 70.0, "Brightness": 65.17163848876953 }, "Confidence": 99.99468231201172 } ], "OrientationCorrection": "ROTATE_0" }</code></p><p id="05a3">JSON, the cornerstone of any nutritious service. So, what do we have here? A face has been found with 99.99+% confidence. It’s delimited by the <em class="markup--p-em">BoundingBox</em> coordinates (top left corner, face width, face height): these are fractional values with respect to the total height and width of the image. Eyes, nose and mouth have been located too (that’s reassuring).</p><p id="2408">Now, let’s see what Rekognition can tell us about this second picture.</p><p id="245d"><code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ aws rekognition detect-labels --image '{"S3Object":{"Bucket":"jsimon-public","Name":"<a href="http://julien2.jpghttps//jsimon-public.s3.amazonaws.com/julien2.jpg" target="_blank">julien2.jpg</a>"}}'</code></p><figure id="0646"><img class="graf-image" src="image06.webp"/></figure><p id="d3d4"><code class="markup--code markup--p-code">{ "Labels": [ { "Confidence": 99.29261779785156, "Name": "Human" }, { "Confidence": 99.2958984375, "Name": "People" }, { "Confidence": 99.2958984375, "Name": "Person" }, { "Confidence": 99.2667007446289, "Name": "Book" }, { "Confidence": 99.2667007446289, "Name": "Text" }, { "Confidence": 71.22590637207031, "Name": "Bookcase" }, { "Confidence": 71.22590637207031, "Name": "Furniture" }, { "Confidence": 71.22590637207031, "Name": "Shelf" }, { "Confidence": 52.00172805786133, "Name": "Portrait" }, { "Confidence": 52.00172805786133, "Name": "Selfie" } ] }</code></p><p id="49d8">With a very good level of confidence, this is the picture of a human with books on a bookshelf, possibly a portrait. A pretty good summary. Let's compare the two previous pictures. Is this truly the same person? Spoiler: yes, although I look 15 years older on the first one. Note to self: no more promo shots after 36 sleepless hours :D</p><p id="02e3"><code class="markup--code markup--p-code">$ aws rekognition compare-faces --source-image '{"S3Object":{"Bucket":"jsimon-public","Name":"julien1.jpg"}}' --target-image '{"S3Object":{"Bucket":"jsimon-public","Name":"julien2.jpg"}}</code></p><p id="0e6d"><code class="markup--code markup--p-code">{ "FaceMatches": [ { "Face": { "BoundingBox": { "Width": 0.5596370100975037, "Top": 0.1318063884973526, "Left": 0.3889369070529938, "Height": 0.5596370100975037 }, "Confidence": 99.98912811279297 }, "Similarity": 98.0 } ], "SourceImageFace": { "BoundingBox": { "Width": 0.3883333206176758, "Top": 0.12222222238779068, "Left": 0.33666667342185974, "Height": 0.2588889002799988 }, "Confidence": 99.99468231201172 } }</code></p><p id="b736">Similarity is 98%. Jet lag or not, I'm always the same me. See how simple this service is? I don't see how they could have made it easier. How long would it take to design, build and *train* something like this on your own? I have really no idea and to I don't intend to find out!</p><p id="745c">Enough CLI, let’s switch to Python and run more visual examples. For this purpose, I’ve written a couple of scripts (<a href="https://github.com/juliensimon/aws/tree/master/rekognition" target="_blank">available here</a>), using boto3 and the <a href="https://github.com/python-pillow/Pillow" target="_blank">Pillow</a> image processing library.</p><p id="36a0">In a nutshell:</p><ul class="postList"><li id="a1c9"><em class="markup--li-em">rekognitionDetect.py bucket_name image [copy | nocopy ] </em>: try to detect faces inside an image. If faces are found, each of them will be highlighted by a box and an updated image will be saved. The script will also report image labels and face information (gender, beard, glasses, etc.). Maximum number of labels and default confidence are respectively set to 10 and 75% by default.</li><li id="55e1"><em class="markup--li-em">rekognitionCompare.py bucket_name sourceImage targetImage [copy | nocopy ]</em>: try to match a reference face to another image. If the face is found, it will be highlighted by a box and an updated image will be saved.</li></ul><p id="91bf">All images must be present with the same name both locally and in S3 . The last parameter for both scripts allows you to skip the copy to S3 if the file is already there. Hopefully, the code reads like well-written prose (hi Uncle Bob). If not, blame jet lag (yes, it’s the root of all evil). Anyway, there’s nothing complicated here, I’m sure you’ll figure it out in no time. Let’s play some more!</p><figure id="28cc"><img class="graf-image" src="image04.webp"/></figure><p id="b27d"><code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionDetect.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/booth1.jpg" target="_blank">booth1.jpg</a> nocopy</code></p><p id="6147"><code class="markup--code markup--p-code">Label Human, confidence: 99.3180236816 </code><br/> <code class="markup--code markup--p-code">Label People, confidence: 99.3190917969 </code><br/> <code class="markup--code markup--p-code">Label Person, confidence: 99.3190917969 </code><br/> <code class="markup--code markup--p-code">Label Clothing, confidence: 92.1037216187 </code><br/> <code class="markup--code markup--p-code">Label Overcoat, confidence: 92.1037216187 </code><br/> <code class="markup--code markup--p-code">Label Suit, confidence: 92.1037216187 </code><br/> <code class="markup--code markup--p-code">Label Computer, confidence: 76.0058441162 </code><br/> <code class="markup--code markup--p-code">Label Electronics, confidence: 76.0058441162 </code><br/> <code class="markup--code markup--p-code">Label LCD Screen, confidence: 76.0058441162 </code><br/> <code class="markup--code markup--p-code">Label Laptop, confidence: 76.0058441162 </code><br/> <code class="markup--code markup--p-code">*** Face 0 detected, confidence: 99.999671936 Gender: Male HAPPY 96.4477920532 CALM 8.28260231018 CONFUSED 1.53788328171 </code><br/> <code class="markup--code markup--p-code">*** Face 1 detected, confidence: 99.9654922485 Gender: Male Beard Mustache HAPPY 98.5274353027 ANGRY 5.03668212891 CONFUSED 2.61067152023 </code><br/> <code class="markup--code markup--p-code">*** Face 2 detected, confidence: 99.9955444336 Gender: Male Eyeglasses HAPPY 97.6237945557 ANGRY 1.31589770317 CALM 0.939458608627 </code><br/> <code class="markup--code markup--p-code">*** Face 3 detected, confidence: 99.9996109009 Gender: Male Eyeglasses HAPPY 98.9962310791 SAD 11.4119710922 CONFUSED 1.69576406479</code></p><p id="42f5">Say hi to Romain, Cédric and Damian, my friendly AWS colleagues. Rekognition sees 4 males, 1 with a beard, 2 with eyeglasses, all of them very happy... and I'm the calmest of the bunch, how about that. Amazingly, Rekognition manages to catch my hardly visible laptop (left edge of the picture, on the table).</p><figure id="f431"><img class="graf-image" src="image07.webp"/></figure><p id="79d2">Here’s a tougher one (Hallo to my German friends).</p><p id="69b9"><code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionDetect.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/oktoberfest.jpg" target="_blank">oktoberfest.jpg</a> nocopy</code></p><p id="060a"><code class="markup--code markup--p-code"><a href="https://jsimon-public.s3.amazonaws.com/reko_oktoberfest.jpg" target="_blank"><em class="markup--p-em">output file</em></a></code><br/> <code class="markup--code markup--p-code"><br/></code> <code class="markup--code markup--p-code">Label People, confidence: 99.0898742676 </code><br/> <code class="markup--code markup--p-code">Label Person, confidence: 99.0898971558 </code><br/> <code class="markup--code markup--p-code">Label Human, confidence: 99.0639343262 </code><br/> <code class="markup--code markup--p-code">Label Alcohol, confidence: 88.8537063599 </code><br/> <code class="markup--code markup--p-code">Label Beverage, confidence: 88.8537063599 </code><br/> <code class="markup--code markup--p-code">Label Drink, confidence: 88.8537063599 </code><br/> <code class="markup--code markup--p-code">Label Crowd, confidence: 84.0972671509 </code><br/> <code class="markup--code markup--p-code">Label Female, confidence: 84.0796279907 </code><br/> <code class="markup--code markup--p-code">Label Girl, confidence: 84.0796279907 </code><br/> <code class="markup--code markup--p-code">*** Face 0 detected, confidence: 99.9854202271 Gender: Male HAPPY 60.5386123657 ANGRY 12.2481765747 DISGUSTED 2.10083723068 </code><br/> <code class="markup--code markup--p-code">*** Face 1 detected, confidence: 99.9825744629 Gender: Female HAPPY 98.0062866211 SURPRISED 10.8561573029 SAD 0.810676813126 </code><br/> <code class="markup--code markup--p-code">*** Face 2 detected, confidence: 99.9904937744 Gender: Female HAPPY 84.5134887695 SURPRISED 8.68589305878 ANGRY 1.35719180107 </code><br/> <code class="markup--code markup--p-code">*** Face 3 detected, confidence: 99.9073257446 Gender: Male Beard Mustache HAPPY 80.5190963745 SURPRISED 23.9800624847 ANGRY 1.17569565773 </code><br/> <code class="markup--code markup--p-code">*** Face 4 detected, confidence: 99.9972229004 Gender: Male Mustache HAPPY 75.2949371338 CONFUSED 10.9511556625 DISGUSTED 1.91761255264 </code><br/> <code class="markup--code markup--p-code">*** Face 5 detected, confidence: 99.9999771118 Gender: Male HAPPY 35.9886474609 SURPRISED 3.75992059708 ANGRY 2.48707532883 </code><br/> <code class="markup--code markup--p-code">*** Face 6 detected, confidence: 99.9915084839 Gender: Female HAPPY 99.4766082764 CALM 0.791561603546 ANGRY 0.620931386948 </code><br/> <code class="markup--code markup--p-code">*** Face 7 detected, confidence: 99.9998931885 Gender: Female HAPPY 99.8826293945 SAD 7.21873044968 DISGUSTED 5.48685789108 </code><br/> <code class="markup--code markup--p-code">*** Face 8 detected, confidence: 83.6580963135 Gender: Male Eyeglasses SAD 94.9213943481 SURPRISED 76.9153442383 HAPPY 8.52976131439 </code><br/> <code class="markup--code markup--p-code">*** Face 9 detected, confidence: 99.9944610596 Gender: Male HAPPY 27.327457428 DISGUSTED 26.6790218353 ANGRY 12.1302127838 </code><br/> <code class="markup--code markup--p-code">*** Face 10 detected, confidence: 99.9998855591 Gender: Male SURPRISED 99.2624435425 HAPPY 22.0922241211 SAD 6.69546127319 </code><br/> <code class="markup--code markup--p-code">*** Face 11 detected, confidence: 99.9861831665 Gender: Male SURPRISED 60.7816810608 SAD 7.07310438156 HAPPY 3.66672611237 </code><br/> <code class="markup--code markup--p-code">*** Face 12 detected, confidence: 99.9990692139 Gender: Male HAPPY 48.0631027222 SURPRISED 2.61369943619 CONFUSED 2.40399837494 </code><br/> <code class="markup--code markup--p-code">*** Face 13 detected, confidence: 87.6368408203 Gender: Male HAPPY 16.2307357788 SAD 14.2565965652 ANGRY 12.3210906982 </code><br/> <code class="markup--code markup--p-code">*** Face 14 detected, confidence: 99.9553375244 Gender: Male HAPPY 54.3005943298 DISGUSTED 5.99133396149 SURPRISED 3.63597273827</code></p><p id="b322">Wow, 15 people, including partial faces. All genders are correct. Emotions are mostly ok, but we definitely need to add 'DRUNK' to the list ;) The labels are spot on: a crowd of men and women drinking alcohol. Let's try another one. Low res, low quality.</p><figure id="bc05"><img class="graf-image" src="image01.webp"/></figure><p id="1402"><code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionDetect.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/maradona.jpg" target="_blank">maradona.jpg</a> nocopy </code><br/> <code class="markup--code markup--p-code"><br/></code> <code class="markup--code markup--p-code">Label People, confidence: 99.2043991089 </code><br/> <code class="markup--code markup--p-code">Label Person, confidence: 99.2043991089 </code><br/> <code class="markup--code markup--p-code">Label Human, confidence: 99.1917037964 </code><br/> <code class="markup--code markup--p-code">Label Football, confidence: 97.2220993042 </code><br/> <code class="markup--code markup--p-code">Label Soccer, confidence: 97.2220993042 </code><br/> <code class="markup--code markup--p-code">Label Sport, confidence: 97.2220993042 </code><br/> <code class="markup--code markup--p-code">Label American Football, confidence: 83.3328475952 </code><br/> <code class="markup--code markup--p-code">Label Athlete, confidence: 78.3234786987 </code><br/> <code class="markup--code markup--p-code">*** Face 0 detected, confidence: 99.963470459 Gender: Male Mustache SURPRISED 21.8802871704 CALM 17.4065952301 SAD 11.6566238403 </code><br/> <code class="markup--code markup--p-code">*** Face 1 detected, confidence: 99.9813308716 Gender: Male Eyeglasses HAPPY 38.6969680786 ANGRY 6.79734945297 SURPRISED 2.61010527611 </code><br/> <code class="markup--code markup--p-code">*** Face 2 detected, confidence: 99.9385604858 Gender: Male SURPRISED 36.6970825195 SAD 7.66330337524 ANGRY 6.10639476776 </code><br/> <code class="markup--code markup--p-code">*** Face 3 detected, confidence: 99.9514923096 Gender: Male SAD 32.6836242676 DISGUSTED 4.55095767975 HAPPY 4.19711828232 </code><br/> <code class="markup--code markup--p-code">*** Face 4 detected, confidence: 99.8046951294 Gender: Male Beard Mustache SAD 46.0139579773 HAPPY 4.15547084808 DISGUSTED 0.981283187866 </code><br/> <code class="markup--code markup--p-code">*** Face 5 detected, confidence: 99.2888412476 Gender: Male SAD 90.2270889282 CALM 5.9303817749 HAPPY 3.26179981232</code></p><p id="001f">Labels are fine, except for 'American Football'. 83%??? Gimme a break, the training set needs more Soccer images! In addition, I don't think number 4 is wearing eyeglasses, but again this is a low res picture. Apart from this, Rekognition correctly picked up all faces and funny enough, the expressions make sense too: "sad" and "surprised" are definitely how these guys must have felt against the legendary Diego! A last one for the road: how about this complex abstract-ish nighttime picture of Shinjuku?</p><figure id="4547"><img class="graf-image" src="image05.webp"/></figure><p id="67f0"><code class="markup--code markup--p-code">$ rekognitionDetect.py jsimon-public shinjuku.jpg nocopy</code></p><p id="9b85"><code class="markup--code markup--p-code">Label City, confidence: 88.4259796143 Label Downtown, confidence: 88.4259796143 </code><br/> <code class="markup--code markup--p-code">Label Metropolis, confidence: 84.8462677002 </code><br/> <code class="markup--code markup--p-code">Label Urban, confidence: 84.8462677002 </code><br/> <code class="markup--code markup--p-code">Label Night, confidence: 69.7816467285 </code><br/> <code class="markup--code markup--p-code">Label Outdoors, confidence: 69.7816467285 </code><br/> <code class="markup--code markup--p-code">Label Shop, confidence: 68.228477478 </code><br/> <code class="markup--code markup--p-code">Label Flyer, confidence: 60.3522796631 </code><br/> <code class="markup--code markup--p-code">Label Poster, confidence: 60.3522796631 </code><br/> <code class="markup--code markup--p-code">Label Neighborhood, confidence: 55.3994293213 </code><br/> <code class="markup--code markup--p-code">*** Face 0 detected, confidence: 97.9367828369 </code><br/> <code class="markup--code markup--p-code">Gender: Female SAD 46.1420478821 ANGRY 7.63346576691 HAPPY 6.28939962387</code></p><p id="d521">Note that I lowered the confidence threshold from 75% to 50% get more labels. Still, Rekognition does a good job. It also gets the girl's face and yes, she does look quite sad. The Anime face isn't detected but I guess this is the desired behavior. Alright, enough detection. Let's now try to match faces, using some of the previous pictures as well as some new ones.</p><figure id="c6d0"><img class="graf-image" src="image02.webp"/></figure><p id="6839"><code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionCompare.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/julien1.jpg" target="_blank">julien1.jpg</a> <a href="https://jsimon-public.s3.amazonaws.com/julien2.jpg" target="_blank">julien2.jpg</a> nocopy </code><br/> <code class="markup--code markup--p-code">Face match, confidence=99.9891281128, similarity=98.0 </code><br/> <code class="markup--code markup--p-code"><br/></code> <code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionCompare.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/julien1.jpg" target="_blank">julien1.jpg</a> <a href="https://jsimon-public.s3.amazonaws.com/booth1.jpg" target="_blank">booth1.jpg</a> nocopy </code><br/> <code class="markup--code markup--p-code">Face match, confidence=99.999671936, similarity=96.0 </code><br/> <code class="markup--code markup--p-code"><br/></code> <code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionCompare.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/julien1.jpg" target="_blank">julien1.jpg</a> <a href="https://jsimon-public.s3.amazonaws.com/booth2.jpg" target="_blank">booth2.jpg</a> nocopy </code><br/> <code class="markup--code markup--p-code">Face match, confidence=99.9991455078, similarity=84.0 </code><br/> <code class="markup--code markup--p-code"><br/></code> <code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">$ rekognitionCompare.py jsimon-public <a href="https://jsimon-public.s3.amazonaws.com/julien1.jpg" target="_blank">julien1.jpg</a> <a href="https://jsimon-public.s3.amazonaws.com/keynote.jpg" target="_blank">keynote.jp</a>g no copy </code><br/> <code class="markup--code markup--p-code">Face match, confidence=99.9932250977, similarity=82.0</code></p><p id="9744">Quite good! The last one is particularly nice, given the distance, the angle and the poor lighting (see actual picture above). These are just a few examples and I'm sure you can't wait to try your own. Hopefully this post has given you a visual, hands-on overview of the Recognition service and how user-friendly it is. I didn't cover face collections, but the API is pretty much what you'd expect (create, delete, etc.).</p><p id="6313">Feel free to explore and experiment. Until we meet again, keep rockin’.</p></div></div></section><section class="section"><div><hr/></div><div><div><p id="9346"><em class="markup--p-em">Originally published at </em><a href="http://blog.julien.org/2016/11/a-hands-on-look-at-amazon-rekognition.html" target="_blank"><em class="markup--p-em">blog.julien.org</em></a><em class="markup--p-em"> on November 30, 2016.</em></p></div></div></section>
</section>
</article></body></html>

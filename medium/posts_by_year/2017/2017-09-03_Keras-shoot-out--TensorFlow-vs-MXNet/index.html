<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Keras shoot-out: TensorFlow vs MXNet</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="0511">Keras shoot-out: TensorFlow vs MXNet</h3><p id="9378">A few months, we took an <a href="https://medium.com/@julsimon/apache-mxnet-support-in-keras-83de7dec46e5" target="_blank">early look</a> at running <a href="http://keras.io" target="_blank">Keras</a> with <a href="http://mxnet.io" target="_blank">Apache MXNet</a> as its backend. Things were pretty beta at the time, but a lot of progress has since been made. It’s time to reevaluate… and benchmark MXNet against <a href="https://www.tensorflow.org/" target="_blank">Tensorflow</a>.</p><figure id="0268"><img class="graf-image" src="image01.webp"/><figcaption>In this world, there’s two kinds of people, my friend. Those with GPUs and those who wait for days. You wait.</figcaption></figure><h4 id="5d90">The story so far</h4><p id="c4f4">The good folks at DMLC have <a href="https://github.com/dmlc/keras/" target="_blank">forked</a> Keras 1.2 in order to implement MXNet support, multi-GPU included. In parallel, they’ve moved the projet to the Apache Incubator and are currently putting the finishing touches to <a href="https://github.com/apache/incubator-mxnet" target="_blank">MXNet 0.11</a>. This is pretty impressive work in such a short time frame!</p><p id="19fb">In addition to the Keras and MXNet codebases, here’s what we’re going to use today:</p><ul class="postList"><li id="57c8"><a href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" target="_blank">The Deep Learning AMI</a> (Ubuntu version), which already includes Tensorflow 1.2.</li><li id="8e54">A <a href="https://aws.amazon.com/blogs/aws/new-p2-instance-type-for-amazon-ec2-up-to-16-gpus/" target="_blank">p2.8xlarge</a> EC2 instance, powered by 8 K80 NVIDIA GPUs</li><li id="c4c8">The <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">CIFAR-10</a> dataset, which we covered in detail in <a href="https://becominghuman.ai/training-mxnet-part-2-cifar-10-c7b0b729c33c" target="_blank">previous posts</a></li><li id="ce35">The famous <a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank">RESNET-50</a> network.</li></ul><p id="fdc8">Let’s ride.</p><h4 id="176b">Installing MXNet and Keras</h4><p id="5ae4">Once the instance is running, we first have to update MXNet to the latest version (0.11.0-rc3 at the time of writing). Here, we’re obviously going for GPU support.</p><figure id="e1a3"><script src="https://gist.github.com/juliensimon/fb4b6b5f703b0e53d75f48ec8b3460a6.js"></script></figure><p id="e0b4">Updating Keras is quite simple too.</p><figure id="6a70"><script src="https://gist.github.com/juliensimon/2111c2819d170ddcbec58858904f6c9e.js"></script></figure><p id="4165">Let’s check that we have the correct versions.</p><figure id="bcfb"><script src="https://gist.github.com/juliensimon/41f2c266a70b8667b6048c914d132a5f.js"></script></figure><p id="2f9a">Ok, looks good. Let’s move on to training.</p><h4 id="9850">Keras backends</h4><p id="f1c7">Keras supports multiple backends for training and it’s very easy to switch from one to the other. Here are the two file versions for Tensorflow and MXNet.</p><blockquote class="graf--blockquote" id="d82a">All it takes is one line in the <em class="markup--blockquote-em">~/.keras/keras.json</em> file.</blockquote><figure class="graf-after--blockquote" id="6858"><script src="https://gist.github.com/juliensimon/dfd25cb4317ca563c9798994b4e0f182.js"></script></figure><h4 id="c6fc">Learning CIFAR-10 with Tensorflow</h4><p id="faf8">Keras provides plenty of nice examples in <em class="markup--p-em">~/keras/examples</em>. We can use <em class="markup--p-em">cifar10_resnet50.py </em>pretty much as is. Since we’re going to be using all 8 GPUs, let’s just update the batch size to 256, the number of epochs to 100 and disable data augmentation.</p><figure id="eee4"><script src="https://gist.github.com/juliensimon/f1577bc971aa50941cb6de51b03ff235.js"></script></figure><p id="87f3">Time to train.</p><figure id="6333"><script src="https://gist.github.com/juliensimon/f32eb3c8c71381f2698e4f8c7813f793.js"></script></figure><p id="1ef3">Here’s what memory usage looks like, as reported by <em class="markup--p-em">nvidia-smi</em>.</p><figure id="6edb"><script src="https://gist.github.com/juliensimon/d64fd836a2270563d56acb36a34769ee.js"></script></figure><p id="cb58">As we can see, TensorFlow is a bit of a memory hog, pretty much eating up 100% of available GPU memory . Not really a problem here, but I’m wondering if a much more complex model would still be able to fit in memory. To be tested in a future post, I suppose :)</p><p id="f55e">After a while, here’s the result (full log <a href="https://gist.github.com/juliensimon/0559f4fb852a630023097f881d506c61" target="_blank">here</a>).</p><figure id="455a"><script src="https://gist.github.com/juliensimon/24b2eb46857bccb67811d69d7a547b95.js"></script></figure><p id="4140">All right. Now let’s move on to MXNet.</p><h4 id="098f">Learning CIFAR-10 with MXNet</h4><p id="49e5">At the moment, auto-detection of GPUs is not implemented for MXNet in Keras, so we need to pass the list of available GPUs to the <em class="markup--p-em">compile</em>() API</p><blockquote class="graf--blockquote" id="95bc">Just replace the call to <em class="markup--blockquote-em">model.compile</em>() in <em class="markup--blockquote-em">cifar10_resnet.py</em> with this snippet.</blockquote><figure class="graf-after--blockquote" id="b0a4"><script src="https://gist.github.com/juliensimon/7906db1a7112247aecbfbf3cf22e3c1e.js"></script></figure><p id="322e">Time to train.</p><figure id="ed01"><script src="https://gist.github.com/juliensimon/ebecfb6e291b65e3219c2e0eb99f0916.js"></script></figure><p id="7ca6">Holy moly! MXNet is <strong class="markup--p-strong">60% faster</strong>: 25 seconds per epoch instead of 61. Very nice. In the same time frame, this would definitely allow us to try more things, like different model architectures or different hyper parameters. Definitely an advantage when you’re experimenting.</p><p id="8391">What about memory usage? As we can see, MXNet uses over <strong class="markup--p-strong">90% less RAM</strong> and there is plenty left for other jobs.</p><figure id="8753"><script src="https://gist.github.com/juliensimon/36f5dbab924f02541792433d2e3bbf09.js"></script></figure><p id="9ab1">Here’s the result after 100 epochs (full log <a href="https://gist.github.com/juliensimon/29165dc7293e2602a6203255f65264b1" target="_blank">here</a>): <strong class="markup--p-strong">43 minutes</strong>, <strong class="markup--p-strong">99.4%</strong> training accuracy, <strong class="markup--p-strong">62%</strong> test accuracy.</p><figure id="5463"><script src="https://gist.github.com/juliensimon/55f7e3649746586f2bbec2fa2905e138.js"></script></figure><h4 id="ef82">Conclusion</h4><p id="28a5">Granted, this is a single example and no hasty conclusion should be drawn. Still, with 8 GPUs and a well-known data set, MXNet is <strong class="markup--p-strong">significantly faster, much more memory-efficient </strong>and<strong class="markup--p-strong"> more accurate </strong>than Tensorflow.</p><blockquote class="graf--blockquote" id="d55f">It seems to me every Deep Learning practitioner ought to check MXNet out, especially now that it’s properly integrated with Keras: changing a line of configuration is all it takes :)</blockquote><p class="graf-after--blockquote" id="c591">If you’d like to dive a bit more into MXNet, may I recommend the following resources?</p><figure id="031e"><iframe frameborder="0" height="145" scrolling="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F331248651&amp;show_artwork=true" width="700"></iframe></figure><div class="graf--mixtapeEmbed" id="1089"><a class="markup--mixtapeEmbed-anchor" href="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab" title="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab"><strong class="markup--mixtapeEmbed-strong">An introduction to the MXNet API — part 1</strong><br/><em class="markup--mixtapeEmbed-em">Update August 1st, 2017: <br/>this series is now available in Japanese, Chinese and Korean.</em>becominghuman.ai</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="c6e0f983acb27726baf2816fb01f2357" data-thumbnail-img-id="1*H0-jFUWPK6TQIXeNqTnaUg.png" href="https://becominghuman.ai/an-introduction-to-the-mxnet-api-part-1-848febdcf8ab" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*H0-jFUWPK6TQIXeNqTnaUg.png);"></a></div><div class="graf--mixtapeEmbed graf-after--mixtapeEmbed" id="7920"><a class="markup--mixtapeEmbed-anchor" href="http://mxnet.io" title="http://mxnet.io"><strong class="markup--mixtapeEmbed-strong">MXNet: A Scalable Deep Learning Framework</strong><br/><em class="markup--mixtapeEmbed-em">Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache…</em>mxnet.io</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="fa85189b90a1a8ed2814ed4435ec1942" data-thumbnail-img-id="0*oNXghWP1DvYh5Fkf." href="http://mxnet.io" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*oNXghWP1DvYh5Fkf.);"></a></div><p class="graf-after--mixtapeEmbed" id="e9fb"><a href="https://medium.com/@julsimon/keras-shoot-out-part-2-a-deeper-look-at-memory-usage-8a2dd997de81" target="_blank">In part 2</a>, I’m taking a deeper look at memory usage in Tensorflow and how to optimise it.</p><p id="4414"><a href="https://medium.com/@julsimon/keras-shoot-out-part-3-fine-tuning-7d1548c51a41" target="_blank">In part 3</a>, we’ll learn how to fine-tune the models for improved accuracy.</p><p id="00e4">Thank you for reading :)</p></div></div></section><section class="section"><div><hr/></div><div><div><p id="03ed"><em class="markup--p-em">This post was written while blasting classics by Whitesnake, Rainbow and Dio. Fortunately, no neighbour was injured in the process.</em></p></div></div></section>
</section>
</article></body></html>
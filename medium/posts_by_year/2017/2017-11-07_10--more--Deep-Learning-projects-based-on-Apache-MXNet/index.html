<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>10 (more) Deep Learning projects based on Apache MXNet</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="8e0e">10 (more) Deep Learning projects based on Apache MXNet</h3><p id="2fb3">In a previous article, I listed <a href="https://medium.com/@julsimon/10-deep-learning-projects-based-on-apache-mxnet-8231109f3f64" target="_blank">10 cool Deep Learning projects</a> based on <a href="https://mxnet.incubator.apache.org" target="_blank">Apache MXNet</a>. Well, here are 10 more, a nice mix of model implementations and applications.</p><p id="f077">If you have an MXNet project that I haven’t listed to far, please get in touch!</p><h3 id="e303">Model implementations</h3><h4 id="100a">#1 — DenseNet</h4><div class="graf--mixtapeEmbed" id="8470"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/bruinxiong/densenet.mxnet" title="https://github.com/bruinxiong/densenet.mxnet"><strong class="markup--mixtapeEmbed-strong">bruinxiong/densenet.mxnet</strong><br/><em class="markup--mixtapeEmbed-em">densenet.mxnet - A MXNet implementation of DenseNet (with BC structure)</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="e13aa9ce330b429e60e8e6949449c416" data-thumbnail-img-id="0*G5xLp7g0QmyCiGC5." href="https://github.com/bruinxiong/densenet.mxnet" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*G5xLp7g0QmyCiGC5.);"></a></div><p class="graf-after--mixtapeEmbed" id="ec77">This is an implementation of the DenseNet-BC architecture as described in the <a href="https://arxiv.org/pdf/1608.06993v3.pdf" target="_blank">Densely Connected Convolutional Networks</a>, by by Gao Huang, Zhuang Liu, Kilian Q. Weinberger and Laurens van der Maaten.</p><p id="0fd5">This architecture contains shorter connections between layers close to the input and those close to the output. They help models train more efficiently and predict more accurately.</p><figure id="673e"><img class="graf-image" src="image01.webp"/></figure><h4 id="7d8c">#2 — Binary Neural Networks</h4><div class="graf--mixtapeEmbed" id="b091"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/hpi-xnor/BMXNet" title="https://github.com/hpi-xnor/BMXNet"><strong class="markup--mixtapeEmbed-strong">hpi-xnor/BMXNet</strong><br/><em class="markup--mixtapeEmbed-em">Contribute to BMXNet development by creating an account on GitHub.</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="4d6e1b422e7681975ecf558372af6674" data-thumbnail-img-id="0*K5baPtVPwj1qA5NM." href="https://github.com/hpi-xnor/BMXNet" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*K5baPtVPwj1qA5NM.);"></a></div><p class="graf-after--mixtapeEmbed" id="ca34">This project implement Binary Neural Networks, as described in <a href="https://arxiv.org/abs/1705.09864" target="_blank"><em class="markup--p-em">BMXNet: An Open-Source Binary Neural Network Implementation Based on MXNet</em></a><em class="markup--p-em"> by </em>Haojin Yang, Martin Fritzsche, Christian Bartz and Christoph Meinel.</p><p id="ba0b">These networks use weights are binary values! At the cost of minimal accuracy loss, these networks are both much smaller and much faster than their floating-point counterparts.</p><h4 id="819f">#3 — Mask R-CNN (image segmentation)</h4><div class="graf--mixtapeEmbed" id="1bd0"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/TuSimple/mx-maskrcnn" title="https://github.com/TuSimple/mx-maskrcnn"><strong class="markup--mixtapeEmbed-strong">TuSimple/mx-maskrcnn</strong><br/><em class="markup--mixtapeEmbed-em">mx-maskrcnn - An MXNet implementation of Mask R-CNN</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="64beb0e560d121c4d743da6142bf767a" data-thumbnail-img-id="0*vN3buzqUWChQc-5o." href="https://github.com/TuSimple/mx-maskrcnn" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*vN3buzqUWChQc-5o.);"></a></div><p class="graf-after--mixtapeEmbed" id="414a">This is an implementation of the Mask R-CNN architecture, based on <a href="https://arxiv.org/abs/1703.06870" target="_blank">the self-titled paper</a> by Kaiming He, Georgia Gkioxari, Piotr Dollár and Ross Girshick</p><p id="f76c">This architecture is an evolution of Fast R-CNN and does a very good job at object segmentation. If case you didn’t know, TuSimple build <a href="https://www.oreilly.com/ideas/self-driving-trucks-enter-the-fast-lane-using-deep-learning" target="_blank">autonomous driving systems</a> :)</p><figure id="d07f"><img class="graf-image" src="image03.webp"/></figure><h4 id="8402">#4 — YOLO9000 (object detection)</h4><div class="graf--mixtapeEmbed" id="081d"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/zhreshold/mxnet-yolo" title="https://github.com/zhreshold/mxnet-yolo"><strong class="markup--mixtapeEmbed-strong">zhreshold/mxnet-yolo</strong><br/><em class="markup--mixtapeEmbed-em">mxnet-yolo — YOLO: You only look once real-time object detector</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="40436fda37e7aef9e8ae170033832745" data-thumbnail-img-id="0*jxmMkjTni22X3UTP." href="https://github.com/zhreshold/mxnet-yolo" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*jxmMkjTni22X3UTP.);"></a></div><p class="graf-after--mixtapeEmbed" id="0144">This project performs object detection based on the <a href="https://arxiv.org/pdf/1612.08242.pdf" target="_blank"><em class="markup--p-em">YOLO9000: Better, Faster, Stronger</em></a> research paper by Joseph Redmon and Ali Farhadi.</p><p id="fc67">At 40 frames per second, YOLOv2 gets 78.6 mean average precision, “outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster”.</p><figure id="04b1"><img class="graf-image" src="image02.webp"/></figure><h4 id="0fda">#5— STN-OCR (text detection and text recognition)</h4><div class="graf--mixtapeEmbed" id="c02e"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/Bartzi/stn-ocr" title="https://github.com/Bartzi/stn-ocr"><strong class="markup--mixtapeEmbed-strong">Bartzi/stn-ocr</strong><br/><em class="markup--mixtapeEmbed-em">stn-ocr — Code for the paper STN-OCR: A single Neural Network for Text Detection and Text Recognition</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="f988cb672bc31dbacdaca2beb05f3910" data-thumbnail-img-id="0*53cTo31eGtYjBpbI." href="https://github.com/Bartzi/stn-ocr" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*53cTo31eGtYjBpbI.);"></a></div><p class="graf-after--mixtapeEmbed" id="1a59">This project implements the model described in <a href="https://arxiv.org/abs/1707.08831" target="_blank"><em class="markup--p-em">STN-OCR: A single Neural Network for Text Detection and Text Recognition</em></a>, by Christian Bartz, Haojin Yang and Christoph Meinel.</p><figure id="2040"><img class="graf-image" src="image06.webp"/></figure><h3 id="2d0d">Applications</h3><h4 id="c7fb">#6— Head pose estimation</h4><div class="graf--mixtapeEmbed" id="f5a4"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/laodar/cnn_head_pose_estimator" title="https://github.com/laodar/cnn_head_pose_estimator"><strong class="markup--mixtapeEmbed-strong">laodar/cnn_head_pose_estimator</strong><br/><em class="markup--mixtapeEmbed-em">cnn_head_pose_estimator - a simple and fast mxnet version CNN based head pose estimator</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="d366919883feca451b5ba87f9fb84327" data-thumbnail-img-id="0*8OzPhnUyY4Fij7OW." href="https://github.com/laodar/cnn_head_pose_estimator" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*8OzPhnUyY4Fij7OW.);"></a></div><p class="graf-after--mixtapeEmbed" id="e83c">This model is a simple CNN that does a good job at detecting head poses.</p><figure id="cbf2"><img class="graf-image" src="image05.webp"/></figure><h4 id="a26a">#7 — Realtime multi-person pose estimation</h4><div class="graf--mixtapeEmbed" id="6de3"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/dragonfly90/mxnet_Realtime_Multi-Person_Pose_Estimation" title="https://github.com/dragonfly90/mxnet_Realtime_Multi-Person_Pose_Estimation"><strong class="markup--mixtapeEmbed-strong">dragonfly90/mxnet_Realtime_Multi-Person_Pose_Estimation</strong><br/><em class="markup--mixtapeEmbed-em">mxnet_Realtime_Multi-Person_Pose_Estimation - This is a mxnet version of Realtime_Multi-Person_Pose_Estimation, origin…</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="2dd7904a3f88682c2fa5bc0028551653" data-thumbnail-img-id="0*siObHdYqIyt0nwQS." href="https://github.com/dragonfly90/mxnet_Realtime_Multi-Person_Pose_Estimation" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*siObHdYqIyt0nwQS.);"></a></div><p class="graf-after--mixtapeEmbed" id="c626">This project implements an MXNet version of the model described in <a href="https://arxiv.org/abs/1611.08050" target="_blank"><em class="markup--p-em">Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</em></a><em class="markup--p-em"> </em>by Zhe Cao, Tomas Simon, Shih-En Wei and Yaser Sheikh.</p><p id="170e">This is AMAZING.</p><figure id="85f5"><img class="graf-image" src="image07.webp"/></figure><h4 id="5be0">#8 — Sentiment analysis</h4><div class="graf--mixtapeEmbed" id="240f"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/sookinoby/sentiment-analysis2" title="https://github.com/sookinoby/sentiment-analysis2"><strong class="markup--mixtapeEmbed-strong">sookinoby/sentiment-analysis2</strong><br/><em class="markup--mixtapeEmbed-em">sentiment-analysis2 - Sentiment ananlysis in keras and mxnet</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="c6f419f6241a5ad492bc83e1ce3b5841" data-thumbnail-img-id="0*LxFIPCpqEgCMp-dH." href="https://github.com/sookinoby/sentiment-analysis2" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*LxFIPCpqEgCMp-dH.);"></a></div><p class="graf-after--mixtapeEmbed" id="8d1c">This tutorial shows you how to build a sentiment analysis model , based on <a href="https://arxiv.org/abs/1408.5882" target="_blank"><em class="markup--p-em">Convolutional Neural Networks for Sentence Classification</em></a> by Yoon Kim. The author provides clear notebooks using both Keras and MXNet. Very nicely done!</p><figure id="5d98"><img class="graf-image" src="image08.webp"/></figure><h4 id="c9fe">#9 &amp; #10 —Image detection on mobile</h4><div class="graf--mixtapeEmbed" id="6dad"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/Leliana/WhatsThis" title="https://github.com/Leliana/WhatsThis"><strong class="markup--mixtapeEmbed-strong">Leliana/WhatsThis</strong><br/><em class="markup--mixtapeEmbed-em">Contribute to WhatsThis development by creating an account on GitHub.</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="60670c8f7a5758d0e36829d824660737" data-thumbnail-img-id="0*SxjxG_50LkIwUK2d." href="https://github.com/Leliana/WhatsThis" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*SxjxG_50LkIwUK2d.);"></a></div><div class="graf--mixtapeEmbed graf-after--mixtapeEmbed" id="cac4"><a class="markup--mixtapeEmbed-anchor" href="https://github.com/pppoe/WhatsThis-iOS" title="https://github.com/pppoe/WhatsThis-iOS"><strong class="markup--mixtapeEmbed-strong">pppoe/WhatsThis-iOS</strong><br/><em class="markup--mixtapeEmbed-em">WhatsThis-iOS - MXNet WhatThis Example for iOS</em>github.com</a><a class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="cbb7657a7088ee60942d8fbb718fe280" data-thumbnail-img-id="0*-txgoPvZoKAbRU8O." href="https://github.com/pppoe/WhatsThis-iOS" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*-txgoPvZoKAbRU8O.);"></a></div><p class="graf-after--mixtapeEmbed" id="54ae">Let’s not forget mobile application developers. These twin projects show you how to use an MXNet model in Android and iOS apps.</p><figure id="c415"><img class="graf-image" src="image04.webp"/></figure><p id="26d2">That’s it for today. Thanks for reading.</p></div></div></section><section class="section"><div><hr/></div><div><div><p id="caf4"><em class="markup--p-em">This article was written while overdosing on Rainbow albums. A Light in the Black… you can’t top this.</em></p><figure id="c3ac"><iframe frameborder="0" height="480" scrolling="no" src="https://www.youtube.com/embed/zBYh0t36fT8?feature=oembed" width="640"></iframe></figure></div></div></section>
</section>
</article></body></html>
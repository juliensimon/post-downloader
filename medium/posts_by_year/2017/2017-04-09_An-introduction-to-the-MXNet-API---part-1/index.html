<!DOCTYPE html>

<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>An introduction to the MXNet API — part 1</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<section class="e-content" data-field="body">
<section class="section"><div><hr/></div><div><div><h3 id="9c85">An introduction to the MXNet API — part 1</h3><figure id="94ac"><img class="graf-image" src="image03.webp"/><figcaption>MXNet Tutorial</figcaption></figure><blockquote class="graf--blockquote" id="c166">Update August 1st, 2017: <br/>this series is now available in <a class="markup--blockquote-anchor" href="http://postd.cc/an-introduction-to-the-mxnet-api-part-1/" target="_blank">Japanese</a>, <a class="markup--blockquote-anchor" href="http://www.infoq.com/cn/articles/an-introduction-to-the-mxnet-api-part01" target="_blank">Chinese</a> and <a class="markup--blockquote-anchor" href="http://blog.creation.net/mxnet-part-1-ndarrays-api" target="_blank">Korean</a>.</blockquote><p class="graf-after--blockquote" id="e6a3">In this series, I will try to give you an overview of the <a href="http://mxnet.io/" target="_blank">MXnet</a> Deep Learning library: we’ll look at its main features and its Python API (which I suspect will be the #1 choice). Later on, we’ll explore some of the MXNet tutorials and notebooks available online, and we’ll hopefully manage to understand every single line of code!</p><p id="e25a">If you’d like learn more about the rationale and the architecture of MXNet, you should read this <a href="https://arxiv.org/abs/1512.01274" target="_blank">paper</a>, named “<em class="markup--p-em">MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems</em>”. We’ll cover most of the concepts presented in the paper, but hopefully in a more accessible way.</p><p id="85ea">I’ll go as slow and explain as much as I need to. Expect minimal math and minimal jargon, but no (intentional) dumbing down. You won’t become an expert — I ain’t one anyway— but I hope you’ll learn enough to understand how you can add Deep Learning capabilities to your own applications.</p><h4 id="312a">Running MXNet locally</h4><p id="b8e0">First things first: let’s install MXNet. You’ll find the official instructions <a href="http://mxnet.io/get_started/index.html" target="_blank">here</a>, but here are some additional tips.</p><p id="b9e4">One of the cool features of MXNet is that <strong class="markup--p-strong">it can run identically on CPU and GPU</strong> (we’ll see later how to pick one or the other for our computations). This means that even if your computer doesn’t have an Nvidia GPU (just like my MacBook), you can still write and run MXNet code which you’ll use later on GPU-enabled systems.</p><p id="529b">If your computer has such a GPU, that’s great but you need to install the <a href="https://developer.nvidia.com/cuda-toolkit" target="_blank">CUDA</a> and <a href="https://developer.nvidia.com/cudnn" target="_blank">cuDNN</a> toolkits, which tends to turn into a <strong class="markup--p-strong">nightmare</strong> more often than not. At the slightest incompatibility between the MXNet binary and the Nvidia tools, your setup will be broken and you won’t be able to work.</p><p id="6741">For this reason, I would <strong class="markup--p-strong">strongly</strong> advise you to use the Docker images provided on the MXNet website: one for CPU environments, one for GPU environments (which requires <a href="https://github.com/NVIDIA/nvidia-docker" target="_blank">nvidia-docker</a>). These images come pre-installed with everything you need and allow you to get started in minutes.</p><pre class="graf--pre" id="3154">sudo -H pip install mxnet  --upgrade<br/>python<br/>&gt;&gt;&gt; import mxnet as mx<br/>&gt;&gt;&gt; mx.__version__<br/>'0.9.3a3'</pre><p class="graf-after--pre" id="4826">For what it’s worth, the Docker images also seem to be <strong class="markup--p-strong">more up to date</strong> than the Python package available through ‘pip’.</p><pre class="graf--pre" id="d81a">docker run -it  mxnet/python<br/>root@88a5fe9c8def:/# python<br/>&gt;&gt;&gt; import mxnet as mx<br/>&gt;&gt;&gt; mx.__version__<br/>'0.9.5'</pre><h4 class="graf-after--pre" id="4b00">Running MXNet on AWS</h4><p id="4634">AWS provides you with the <strong class="markup--p-strong">Deep Learning AMI</strong>, available both for <a href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" target="_blank">Linux</a> and <a href="https://aws.amazon.com/marketplace/pp/B06VSPXKDX" target="_blank">Ubuntu</a>. This AMI comes pre-installed with many Deep Learning frameworks (MXNet included), as well as all the Nvidia tools and more. <strong class="markup--p-strong">No plumbing needed</strong>.</p><pre class="graf--pre" id="093a">====================================================================<br/>       __|  __|_  )<br/>       _|  (     /   Deep Learning AMI for Amazon Linux<br/>      ___|\___|___|<br/>====================================================================</pre><pre class="graf--pre graf-after--pre" id="4c80">[ec2-user@ip-172-31-42-173 ~]$ nvidia-smi -L<br/>GPU 0: GRID K520 (UUID: GPU-d470337d-b59b-ca2a-fe6d-718f0faf2153)</pre><pre class="graf--pre graf-after--pre" id="aa7b">[ec2-user@ip-172-31-42-173 ~]$ python<br/>&gt;&gt;&gt; import mxnet as mx<br/>&gt;&gt;&gt; mx.__version__<br/>'0.9.3'</pre><p class="graf-after--pre" id="6e1f">You can run this AMI either on a regular instance or on a GPU instance. If your computer doesn’t have an Nvidia GPU, this might come in handy later when we start training networks: your most inexpensive option will be to use a <strong class="markup--p-strong">g2.2xlarge</strong> instance at $0.65 per hour.</p><p id="ceee">For now, a good old-fashioned CPU is all we need! Let’s get started.</p><h4 id="1f5d">Why NDArrays are important</h4><p id="2545">The first part of the MXNet API we’re going to look at in the <strong class="markup--p-strong">NDArray API</strong>. An NDArray is an <strong class="markup--p-strong">n-dimensional array, containing items of identical type and size</strong> (32-bit floats, 32-bit integers, etc).</p><p id="9224">Why are these arrays important? As explained in a <a href="https://medium.com/towards-data-science/fascinating-tales-of-a-strange-tomorrow-72048639e754" target="_blank">previous article</a>, training and running neural networks involve a lot of math operations. Multi-dimensional arrays is how we’ll store our data.</p><blockquote class="graf--blockquote" id="5a96">Input data, neuron weights and output data are stored in vectors and matrices, so it’s quite natural to have this kind of construct available.</blockquote><p class="graf-after--blockquote" id="7b8b">Let’s take a simple example: categorizing images. The image below represents an handwritten ‘8’, 18x18 pixels.</p><figure id="f927"><img class="graf-image" src="image04.webp"/><figcaption>The number 8, 18x18 pixels</figcaption></figure><p id="48c3">This image represents the same image as an 18x18 matrix, with each cell holding the greyscale value for the corresponding pixel: ‘0’ for white, ‘255’ for black and values in between for 254 shades of grey. This matrix representation is what we’ll run through a neural network to train it in categorizing digits from 0 to 9.</p><figure id="4e5b"><img class="graf-image" src="image02.webp"/><figcaption>An 18x18 matrix, holding greyscale values for the image above</figcaption></figure><p id="cb37">Now imagine that we use colour images instead of greyscale images. Each image would now be described using 3 matrices, one for each colour, so our input data is now a little more complicated.</p><p id="578f">Let’s go one step further. Imagine we’re doing real time image recognition for autonomous driving: in order to make decisions on quality up-to-date data, we’re using 1000 x 1000-pixel RGB images at 30 frames per second. Every second, we’ll have to handle 90 1000 x 1000 matrices (30 frames x 3 colours). If each pixel is represented as a 32-bit value, that’s 90 x 1000 x 1000 x 4 bytes, more or less 343 Megabytes. If you have multiple cameras, things add up pretty quick.</p><p id="22b3">That’s a lot of data to pump through a neural network: for maximal performance (i.e. minimal latency), GPUs don’t process images one by one: instead, they process them in batches. If we use a batch size of 8, our neural network will process input data in chunks of 1000 x 1000 x 24, i.e. a 3-dimensional array holding 8 1000 x 1000 images in 3 colours.</p><blockquote class="graf--blockquote graf--hasDropCapModel" id="c467">Bottom line: you need to understand NDArrays :) They’re the bread and butter of neural networks, as they will be used to store pretty much all of our data.</blockquote><h4 class="graf-after--blockquote" id="d9b2">The NDArray API</h4><p id="fa67">Now that we know why NDArrays are important, let’s look at how they work (yeah, code at last!). If you’ve worked with the <a href="http://www.numpy.org/" target="_blank">numpy</a> Python library, good news: NDArrays are extremely similar and you probably know most of the API, which is fully documented <a href="http://mxnet.io/api/python/ndarray.html" target="_blank">here</a>.</p><p id="a30b">Let’s start with the basics. No explanation needed, I suppose :)</p><pre class="graf--pre" id="14c7">&gt;&gt;&gt; a = mx.nd.array([[1,2,3], [4,5,6]])<br/>&gt;&gt;&gt; a.size<br/>6<br/>&gt;&gt;&gt; a.shape<br/>(2L, 3L)<br/>&gt;&gt;&gt; a.dtype<br/>&lt;type 'numpy.float32'&gt;<br/><br/></pre><p class="graf-after--pre" id="35b7">By default, an NDArray holds 32-bit floats, but we can customize that.</p><pre class="graf--pre" id="64e0">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; b = mx.nd.array([[1,2,3], [2,3,4]], dtype=np.int32)<br/>&gt;&gt;&gt; b.dtype</pre><p class="graf-after--pre" id="fed4">Printing an NDArray is as easy as this.</p><pre class="graf--pre" id="2423">&gt;&gt;&gt; b.asnumpy()<br/>array([[1, 2, 3],<br/>       [2, 3, 4]], dtype=int32)</pre><p class="graf-after--pre" id="3920">All the math operators you’d expect are available. Let’s try an element-wise matrix multiplication.</p><pre class="graf--pre" id="d515">&gt;&gt;&gt; a = mx.nd.array([[1,2,3], [4,5,6]])<br/>&gt;&gt;&gt; b = a*a<br/>&gt;&gt;&gt; b.asnumpy()<br/>array([[  1.,   4.,   9.],<br/>       [ 16.,  25.,  36.]], dtype=float32)</pre><p class="graf-after--pre" id="2054">How about an proper matrix multiplication (aka ‘dot product’)?</p><pre class="graf--pre" id="2885">&gt;&gt;&gt; a = mx.nd.array([[1,2,3], [4,5,6]])<br/>&gt;&gt;&gt; a.shape<br/>(2L, 3L)<br/>&gt;&gt;&gt; a.asnumpy()<br/>array([[ 1.,  2.,  3.],<br/>       [ 4.,  5.,  6.]], dtype=float32)</pre><pre class="graf--pre graf-after--pre" id="9418">&gt;&gt;&gt; b = a.T<br/>&gt;&gt;&gt; b.shape<br/>(3L, 2L)<br/>&gt;&gt;&gt; b.asnumpy()<br/>array([[ 1.,  4.],<br/>       [ 2.,  5.],<br/>       [ 3.,  6.]], dtype=float32)</pre><pre class="graf--pre graf-after--pre" id="4e13">&gt;&gt;&gt; c = mx.nd.dot(a,b)<br/>&gt;&gt;&gt; c.shape<br/>(2L, 2L)<br/>&gt;&gt;&gt; c.asnumpy()<br/>array([[ 14.,  32.],<br/>       [ 32.,  77.]], dtype=float32)</pre><p class="graf-after--pre" id="e2ac">Let’s try something a little more complicated:</p><ul class="postList"><li id="a7b7">initialize a 1000 x 1000 matrix with a uniform distribution, stored on GPU#0 (I’m using a g2 instance here).</li><li id="f1c1">initialize another 1000 x 1000 matrix with a normal distribution (mean of 1 and standard deviation of 2), also on GPU#0.</li></ul><pre class="graf--pre" id="9637">&gt;&gt;&gt; c = mx.nd.uniform(low=0, high=1, shape=(1000,1000), ctx="gpu(0)")<br/>&gt;&gt;&gt; d = mx.nd.normal(loc=1, scale=2, shape=(1000,1000), ctx="gpu(0)")<br/>&gt;&gt;&gt; e = mx.nd.dot(c,d)</pre><blockquote class="graf--blockquote graf--hasDropCapModel graf-after--pre" id="f978">Remember that MXNet can run identically on CPU and GPU. This is an example of this: just replace “gpu(0)” by “cpu(0)” in the previous example and now the dot product will run on the CPU.</blockquote><p class="graf-after--blockquote" id="2c88">You should now know enough to start playing with NDArrays. There are also higher level functions to build neural networks (<em class="markup--p-em">FullyConnected</em>, etc.) but we’ll study them when we start looking at actual networks.</p><p id="d73d">That’s it for today. In the next post, we’ll look at the Symbol API, which allows us to define data flows, which is pretty much what neural networks are all about. Thanks for reading and stay tuned.</p></div></div></section><section class="section"><div><hr/></div><div><div><p id="6565">Next :</p><ul class="postList"><li id="e655"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-2-ce761513124e" target="_blank">Part 2</a>: the Symbol API</li><li id="de6c"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-3-1803112ba3a8" target="_blank">Part 3</a>: the Module API</li><li id="8171"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-4-df22560b83fe" target="_blank">Part 4</a>: Using a pre-trained model for image classification (Inception v3)</li><li id="061d"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-5-9e78534096db" target="_blank">Part 5</a>: More pre-trained models (VGG16 and ResNet-152)</li><li id="6b93"><a href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-6-fcdd7521ae87" target="_blank">Part 6</a>: Real-time object detection on a Raspberry Pi (and it speaks, too!)</li></ul><figure id="724a"><iframe frameborder="0" height="350" scrolling="no" src="https://upscri.be/8f5f8b?as_embed=true" width="700"></iframe></figure></div><div><figure id="af7c"><img class="graf-image" src="image01.webp"/></figure></div><div><figure id="654d" style="width: 33.333%;"><a href="https://medium.com/becoming-human/artificial-intelligence-communities-c305f28e674c"><img class="graf-image" src="image07.webp"/></a></figure><figure class="graf--layoutOutsetRowContinue" id="65ee" style="width: 33.333%;"><a href="https://upscri.be/8f5f8b" target="_blank"><img class="graf-image" src="image05.webp"/></a></figure><figure class="graf--layoutOutsetRowContinue" id="dd1b" style="width: 33.333%;"><a href="https://medium.com/becoming-human/write-for-us-48270209de63"><img class="graf-image" src="image06.webp"/></a></figure></div></div></section>
</section>
</article></body></html>
